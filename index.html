<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"fatefrank.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Seif Zheng&#39;s blog">
<meta property="og:url" content="http://fatefrank.github.io/index.html">
<meta property="og:site_name" content="Seif Zheng&#39;s blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Seif Zheng">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://fatefrank.github.io/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>Seif Zheng's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Seif Zheng's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">日积月累，水滴石穿</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/fatefrank" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fatefrank.github.io/2020/08/10/%E7%B2%BE%E5%B0%BD%20Nginx%20%E9%9D%A2%E8%AF%95%E9%A2%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Seif Zheng">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Seif Zheng's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/10/%E7%B2%BE%E5%B0%BD%20Nginx%20%E9%9D%A2%E8%AF%95%E9%A2%98/" class="post-title-link" itemprop="url">nginx 面试题</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-08-10 00:00:00 / 修改时间：14:14:46" itemprop="dateCreated datePublished" datetime="2020-08-10T00:00:00+08:00">2020-08-10</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="请解释一下什么是-Nginx-？"><a href="#请解释一下什么是-Nginx-？" class="headerlink" title="请解释一下什么是 Nginx ？"></a>请解释一下什么是 Nginx ？</h3><p>Nginx ，是一个 Web 服务器和反向代理服务器，用于 HTTP、HTTPS、SMTP、POP3 和 IMAP 协议。</p>
<p>目前使用的最多的 Web 服务器或者代理服务器，像淘宝、新浪、网易、迅雷等都在使用。</p>
<p>Nginx 的主要功能如下：</p>
<ul>
<li><p>作为 http server (代替 Apache ，对 PHP 需要 FastCGI 处理器支持)</p>
<blockquote>
<p>FastCGI：Nginx 本身不支持 PHP 等语言，但是它可以通过 FastCGI 来将请求扔给某些语言或框架处理。</p>
</blockquote>
</li>
<li><p>反向代理服务器</p>
</li>
<li><p>实现负载均衡</p>
</li>
<li><p>虚拟主机</p>
</li>
</ul>
<p>🦅 <strong>fastcgi 与 cgi 的区别？</strong></p>
<p>1）cgi</p>
<blockquote>
<p>web 服务器会根据请求的内容，然后会 fork 一个新进程来运行外部 c 程序（或 perl 脚本…）， 这个进程会把处理完的数据返回给 web 服务器，最后 web 服务器把内容发送给用户，刚才 fork 的进程也随之退出。</p>
<p>如果下次用户还请求改动态脚本，那么 web 服务器又再次 fork 一个新进程，周而复始的进行。</p>
</blockquote>
<p>2）fastcgi</p>
<blockquote>
<p>web 服务器收到一个请求时，他不会重新 fork 一个进程（因为这个进程在 web 服务器启动时就开启了，而且不会退出），web 服务器直接把内容传递给这个进程（进程间通信，但 fastcgi 使用了别的方式，tcp 方式通信），这个进程收到请求后进行处理，把结果返回给 web 服务器，最后自己接着等待下一个请求的到来，而不是退出。</p>
</blockquote>
<p>🚀 综上，差别在于是否重复 fork 进程，处理请求。</p>
<p>关于 Nginx 和 fastcgi 是如何运行的，可以看看 <a target="_blank" rel="noopener" href="https://www.linuxba.com/archives/7682">《Nginx + FastCGI运行原理》</a> 。</p>
<p>同样，关于 cgi 可能也会存在 <a target="_blank" rel="noopener" href="https://phperzh.com/articles/7297">《php 面试题五之 nginx 如何调用 php 和 php-fpm 的作用和工作原理》</a> 问题。</p>
<h3 id="Nginx-常用命令？"><a href="#Nginx-常用命令？" class="headerlink" title="Nginx 常用命令？"></a>Nginx 常用命令？</h3><ul>
<li>启动 <code>nginx</code> 。</li>
<li>停止 <code>nginx -s stop</code> 或 <code>nginx -s quit</code> 。</li>
<li>重载配置 <code>./sbin/nginx -s reload(平滑重启)</code> 或 <code>service nginx reload</code> 。</li>
<li>重载指定配置文件 <code>.nginx -c /usr/local/nginx/conf/nginx.conf</code> 。</li>
<li>查看 nginx 版本 <code>nginx -v</code> 。</li>
<li>检查配置文件是否正确 <code>nginx -t</code> 。</li>
<li>显示帮助信息 <code>nginx -h</code> 。</li>
</ul>
<h3 id="Nginx-常用配置？"><a href="#Nginx-常用配置？" class="headerlink" title="Nginx 常用配置？"></a>Nginx 常用配置？</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">worker_processes  8;         # 工作进程个数</span><br><span class="line">worker_connections  65535;     # 每个工作进程能并发处理（发起）的最大连接数（包含所有连接数）</span><br><span class="line">error_log         /data/logs/nginx/error.log;     # 错误日志打印地址</span><br><span class="line">access_log      /data/logs/nginx/access.log;     # 进入日志打印地址</span><br><span class="line">log_format  main  &#x27;$remote_addr&quot;$request&quot; &#x27;&#x27;$status $upstream_addr &quot;$request_time&quot;&#x27;; # 进入日志格式</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 如果未使用 fastcgi 功能的，可以无视</span></span></span><br><span class="line">fastcgi_connect_timeout=300;     # 连接到后端 fastcgi 超时时间</span><br><span class="line">fastcgi_send_timeout=300;         # 向 fastcgi 请求超时时间(这个指定值已经完成两次握手后向fastcgi传送请求的超时时间)</span><br><span class="line">fastcgi_rend_timeout=300;         # 接收 fastcgi 应答超时时间，同理也是2次握手后</span><br><span class="line">fastcgi_buffer_size=64k;         # 读取 fastcgi 应答第一部分需要多大缓冲区，该值表示使用1个64kb的缓冲区读取应答第一部分(应答头),可以设置为fastcgi_buffers选项缓冲区大小</span><br><span class="line">fastcgi_buffers 4 64k;             # 指定本地需要多少和多大的缓冲区来缓冲fastcgi应答请求，假设一个php或java脚本所产生页面大小为256kb,那么会为其分配4个64kb的缓冲来缓存</span><br><span class="line">fastcgi_cache TEST;             # 开启fastcgi缓存并为其指定为TEST名称，降低cpu负载,防止502错误发生</span><br><span class="line"></span><br><span class="line">listen       80;                         # 监听端口</span><br><span class="line">server_name  rrc.test.jiedaibao.com;     # 允许域名</span><br><span class="line">root  /data/release/rrc/web;             # 项目根目录</span><br><span class="line">index  index.php index.html index.htm;     # 访问根文件</span><br></pre></td></tr></table></figure>

<p>🦅 <strong>Nginx 日志格式中的 <code>$time_local</code> 表示的是什么时间？请求开始的时间？请求结束的时间？其次，当我们从前到后观察日志中的 <code>$time_local</code> 时间时，有时候会发现时间顺序前后错乱的现象，请说明原因？</strong></p>
<p><code>$time_local</code> ：在服务器里请求开始写入本地的时间。</p>
<p>因为请求发生时间有前有后，所以会时间顺序前后错乱。</p>
<h3 id="Nginx-有哪些优点？"><a href="#Nginx-有哪些优点？" class="headerlink" title="Nginx 有哪些优点？"></a>Nginx 有哪些优点？</h3><ul>
<li><p>跨平台、配置简单。</p>
</li>
<li><p>非阻塞、高并发连接</p>
<blockquote>
<p>处理 2-3 万并发连接数，官方监测能支持 5 万并发。</p>
</blockquote>
</li>
<li><p>内存消耗小</p>
<blockquote>
<p>开启 10 个 Nginx 才占 150M 内存。</p>
</blockquote>
</li>
<li><p>成本低廉，且开源。</p>
</li>
<li><p>稳定性高，宕机的概率非常小。</p>
</li>
</ul>
<h3 id="使用“反向代理服务器”的优点是什么？"><a href="#使用“反向代理服务器”的优点是什么？" class="headerlink" title="使用“反向代理服务器”的优点是什么？"></a>使用“反向代理服务器”的优点是什么？</h3><p>反向代理服务器可以隐藏源服务器的存在和特征。它充当互联网云和 Web 服务器之间的中间层。这对于安全方面来说是很好的，特别是当我们使用 Web 托管服务时。</p>
<blockquote>
<p>这里，先不考虑负载均衡。</p>
</blockquote>
<p>🦅 <strong>什么是正向代理？</strong></p>
<p>一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。</p>
<ul>
<li>客户端才能使用正向代理。</li>
<li>正向代理总结就一句话：代理端代理的是客户端。例如说：😈 我们使用的翻墙软件，OpenVPN 等等。</li>
</ul>
<p>🦅 <strong>什么是反向代理？</strong></p>
<p>反向代理（Reverse Proxy）方式，是指以代理服务器来接受 Internet上的连接请求，然后将请求，发给内部网络上的服务器并将从服务器上得到的结果返回给 Internet 上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。</p>
<p>反向代理总结就一句话：代理端代理的是服务端。</p>
<p>🦅 <strong>请列举 Nginx 和 Apache 之间的不同点？</strong></p>
<p><a target="_blank" rel="noopener" href="http://static2.iocoder.cn/7bdf14ce3d607e5765e37750cc49d65f"><img src="http://static2.iocoder.cn/7bdf14ce3d607e5765e37750cc49d65f" alt="对比图"></a>对比图</p>
<ul>
<li>轻量级，同样起 web 服务，Nginx 比 Apache 占用更少的内存及资源。</li>
<li>抗并发，Nginx 处理请求是异步非阻塞的，而 Apache 则是阻塞型的，在高并发下 Nginx 能保持低资源低消耗高性能。</li>
<li>最核心的区别在于 Apache 是同步多进程模型，一个连接对应一个进程；Nginx 是异步的，多个连接（万级别）可以对应一个进程。</li>
<li>Nginx 高度模块化的设计，编写模块相对简单。</li>
</ul>
<p>🦅 <strong>LVS、Nginx、HAproxy 有什么区别？</strong></p>
<ul>
<li><p>LVS ：是基于四层的转发。</p>
</li>
<li><p>HAproxy ： 是基于四层和七层的转发，是专业的代理服务器。</p>
</li>
<li><p>Nginx ：是 WEB 服务器，缓存服务器，又是反向代理服务器，可以做七层的转发。</p>
<blockquote>
<p>Nginx 引入 <a target="_blank" rel="noopener" href="https://docs.nginx.com/nginx/admin-guide/load-balancer/tcp-udp-load-balancer/">TCP 插件</a>之后，也可以支持四层的转发。</p>
</blockquote>
</li>
</ul>
<p>🚀 区别</p>
<p>LVS 由于是基于四层的转发所以只能做端口的转发，而基于 URL 的、基于目录的这种转发 LVS 就做不了。</p>
<p>🚀 工作选择：</p>
<p>HAproxy 和 Nginx 由于可以做七层的转发，所以 URL 和目录的转发都可以做，在很大并发量的时候我们就要选择 LVS ，像中小型公司的话并发量没那么大选择 HAproxy 或者 Nginx 足已。</p>
<p>由于 HAproxy 由是专业的代理服务器配置简单，所以中小型企业推荐使用HAproxy 。</p>
<blockquote>
<p>有些使用，使用 HAproxy 还是 Nginx ，也和公司运维对哪个技术栈的掌控程度。掌控 OK ，选择 Nginx 会更加不错。</p>
<p>另外，LVS + Nginx 和 LVS + HAProxy 也是比较常见的选型组合。</p>
</blockquote>
<p>更多更详细的对比，感兴趣的胖友，可以看看 <a target="_blank" rel="noopener" href="https://blog.csdn.net/gzh0222/article/details/8540604">《LVS、HAProxy、Nginx 负载均衡的比较分析》</a> 。</p>
<p>🦅 <strong>Squid、Varinsh、Nginx 有什么区别？</strong></p>
<p>三者都实现缓存服务器的作用。所以，本问题所有的视角，都是在作为缓存服务器下来聊。</p>
<ul>
<li><p>1、Nginx本来是反向代理/web服务器，用了插件可以做做这个副业(缓存服务器)。</p>
<blockquote>
<p>但是本身不支持特性挺多，只能缓存静态文件。</p>
</blockquote>
</li>
<li><p>2、从这些功能上，Varinsh 和 Squid 是专业的 Cache 服务，而Nginx 这些是第三方模块完成。</p>
</li>
<li><p>3、Varnish 本身的技术上优势要高于 Squid ，它采用了可视化页面缓存技术。</p>
<blockquote>
<ul>
<li>在内存的利用上，Varnis h比 Squid 具有优势，性能要比 Squid 高。</li>
<li>还有强大的通过 Varnish 管理端口，可以使用正则表达式快速、批量地清除部分缓存</li>
<li>Varnish 是内存缓存，速度一流，但是内存缓存也限制了其容量，缓存页面和图片一般是挺好的。</li>
</ul>
</blockquote>
</li>
<li><p>4、Squid 的优势在于完整的庞大的 cache 技术资料，和很多的应用生产环境。</p>
</li>
</ul>
<p>🚀 工作选择：</p>
<p>要做 cache 服务的话，我们肯定是要选择专业的 cache 服务，优先选择Squid 或者 Varnish 。</p>
<h3 id="请解释-Nginx-如何处理-HTTP-请求？"><a href="#请解释-Nginx-如何处理-HTTP-请求？" class="headerlink" title="请解释 Nginx 如何处理 HTTP 请求？"></a>请解释 Nginx 如何处理 HTTP 请求？</h3><ul>
<li><p>首先，Nginx 在启动时，会解析配置文件，得到需要监听的端口与 IP 地址，然后在 Nginx 的 Master 进程里面先初始化好这个监控的Socket(创建 S ocket，设置 addr、reuse 等选项，绑定到指定的 ip 地址端口，再 listen 监听)。</p>
</li>
<li><p>然后，再 fork(一个现有进程可以调用 fork 函数创建一个新进程。由 fork 创建的新进程被称为子进程 )出多个子进程出来。</p>
</li>
<li><p>之后，子进程会竞争 accept 新的连接。此时，客户端就可以向 nginx 发起连接了。当客户端与nginx进行三次握手，与 nginx 建立好一个连接后。此时，某一个子进程会 accept 成功，得到这个建立好的连接的 Socket ，然后创建 nginx 对连接的封装，即 ngx_connection_t 结构体。</p>
</li>
<li><p>接着，设置读写事件处理函数，并添加读写事件来与客户端进行数据的交换。</p>
<blockquote>
<p>这里，还是有一些逻辑，继续在 <a target="_blank" rel="noopener" href="http://svip.iocoder.cn/Nginx/Interview/#">「Nginx 是如何实现高并发的？」</a> 问题中来看。</p>
</blockquote>
</li>
<li><p>最后，Nginx 或客户端来主动关掉连接，到此，一个连接就寿终正寝了。</p>
</li>
</ul>
<p>🦅 <strong>Nginx 是如何实现高并发的？</strong></p>
<p>如果一个 server 采用一个进程(或者线程)负责一个request的方式，那么进程数就是并发数。那么显而易见的，就是会有很多进程在等待中。等什么？最多的应该是等待网络传输。其缺点胖友应该也感觉到了，此处不述。</p>
<blockquote>
<p>思考下，Java 的 NIO 和 BIO 的对比哟。</p>
</blockquote>
<p>而 Nginx 的异步非阻塞工作方式正是利用了这点等待的时间。在需要等待的时候，这些进程就空闲出来待命了。因此表现为少数几个进程就解决了大量的并发问题。</p>
<p>Nginx是如何利用的呢，简单来说：同样的 4 个进程，如果采用一个进程负责一个 request 的方式，那么，同时进来 4 个 request 之后，每个进程就负责其中一个，直至会话关闭。期间，如果有第 5 个request进来了。就无法及时反应了，因为 4 个进程都没干完活呢，因此，一般有个调度进程，每当新进来了一个 request ，就新开个进程来处理。</p>
<blockquote>
<p>回想下，BIO 是不是存在酱紫的问题？嘻嘻。</p>
</blockquote>
<p>Nginx 不这样，每进来一个 request ，会有一个 worker 进程去处理。但不是全程的处理，处理到什么程度呢？处理到可能发生阻塞的地方，比如向上游（后端）服务器转发 request ，并等待请求返回。那么，这个处理的 worker 不会这么傻等着，他会在发送完请求后，注册一个事件：“如果 upstream 返回了，告诉我一声，我再接着干”。于是他就休息去了。此时，如果再有 request 进来，他就可以很快再按这种方式处理。而一旦上游服务器返回了，就会触发这个事件，worker 才会来接手，这个 request 才会接着往下走。</p>
<blockquote>
<p>这就是为什么说，Nginx 基于事件模型。</p>
</blockquote>
<p>由于 web server 的工作性质决定了每个 request 的大部份生命都是在网络传输中，实际上花费在 server 机器上的时间片不多。这是几个进程就解决高并发的秘密所在。即：</p>
<blockquote>
<p>webserver 刚好属于网络 IO 密集型应用，不算是计算密集型。</p>
</blockquote>
<p>而正如叔度所说的</p>
<blockquote>
<p>异步，非阻塞，使用 epoll ，和大量细节处的优化。</p>
</blockquote>
<p>也正是 Nginx 之所以然的技术基石。</p>
<p>🦅 <strong>为什么 Nginx 不使用多线程？</strong></p>
<p>Apache: 创建多个进程或线程，而每个进程或线程都会为其分配 cpu 和内存（线程要比进程小的多，所以 worker 支持比 perfork 高的并发），并发过大会榨干服务器资源。</p>
<p>Nginx: 采用单线程来异步非阻塞处理请求（管理员可以配置 Nginx 主进程的工作进程的数量）(epoll)，不会为每个请求分配 cpu 和内存资源，节省了大量资源，同时也减少了大量的 CPU 的上下文切换。所以才使得 Nginx 支持更高的并发。</p>
<blockquote>
<p>Netty、Redis 基本采用相同思路。</p>
</blockquote>
<h3 id="什么是动态资源、静态资源分离？"><a href="#什么是动态资源、静态资源分离？" class="headerlink" title="什么是动态资源、静态资源分离？"></a>什么是动态资源、静态资源分离？</h3><p>动态资源、静态资源分离，是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来，动静资源做好了拆分以后我们就可以根据静态资源的特点将其做缓存操作，这就是网站静态化处理的核心思路。</p>
<p>动态资源、静态资源分离简单的概括是：动态文件与静态文件的分离。</p>
<p>🦅 <strong>为什么要做动、静分离？</strong></p>
<p>在我们的软件开发中，有些请求是需要后台处理的（如：<code>.jsp</code>,<code>.do</code> 等等），有些请求是不需要经过后台处理的（如：css、html、jpg、js 等等文件），这些不需要经过后台处理的文件称为静态文件，否则动态文件。</p>
<p>因此我们后台处理忽略静态文件。这会有人又说那我后台忽略静态文件不就完了吗？当然这是可以的，但是这样后台的请求次数就明显增多了。在我们对资源的响应速度有要求的时候，我们应该使用这种动静分离的策略去解决动、静分离将网站静态资源（HTML，JavaScript，CSS，img等文件）与后台应用分开部署，提高用户访问静态代码的速度，降低对后台应用访问</p>
<p>这里我们将静态资源放到 Nginx 中，动态资源转发到 Tomcat 服务器中去。</p>
<p>😈 当然，因为现在七牛、阿里云等 CDN 服务已经很成熟，主流的做法，是把静态资源缓存到 CDN 服务中，从而提升访问速度。</p>
<ul>
<li>相比本地的 Nginx 来说，CDN 服务器由于在国内有更多的节点，可以实现用户的就近访问。</li>
<li>并且，CDN 服务可以提供更大的带宽，不像我们自己的应用服务，提供的带宽是有限的。</li>
</ul>
<p>🦅 <strong>什么叫 CDN 服务？</strong></p>
<p>CDN ，即内容分发网络。</p>
<p>其目的是，通过在现有的 Internet中 增加一层新的网络架构，将网站的内容发布到最接近用户的网络边缘，使用户可就近取得所需的内容，提高用户访问网站的速度。</p>
<p>一般来说，因为现在 CDN 服务比较大众，所以基本所有公司都会使用 CDN 服务。</p>
<h3 id="Nginx-有哪些负载均衡策略？"><a href="#Nginx-有哪些负载均衡策略？" class="headerlink" title="Nginx 有哪些负载均衡策略？"></a>Nginx 有哪些负载均衡策略？</h3><p>负载均衡，即是代理服务器将接收的请求均衡的分发到各服务器中。</p>
<p>Nginx 默认提供了 3 种负载均衡策略：</p>
<ul>
<li><p>1、轮询（默认）round_robin</p>
<blockquote>
<p>每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器 down 掉，能自动剔除。</p>
</blockquote>
</li>
<li><p>2、IP 哈希 ip_hash</p>
<blockquote>
<p>每个请求按访问 ip 的 hash 结果分配，这样每个访客固定访问一个后端服务器，可以解决 session 共享的问题。</p>
<p>当然，实际场景下，一般不考虑使用 ip_hash 解决 session 共享。</p>
</blockquote>
</li>
<li><p>3、最少连接 least_conn</p>
<blockquote>
<p>下一个请求将被分派到活动连接数量最少的服务器</p>
</blockquote>
</li>
</ul>
<p>通过 Nginx 插件，我们还可以引入 fair、url_hash 等负载均衡策略。</p>
<p>另外，我们还可以配置每一个后端节点在负载均衡时的其它配置：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">weight=1;             # (weight 默认为1.weight越大，负载的权重就越大)</span><br><span class="line">down;                 # (down 表示单前的server暂时不参与负载)</span><br><span class="line">backup;             # (其它所有的非backup机器down或者忙的时候，请求backup机器)</span><br><span class="line">max_fails=1;         # 允许请求失败的次数默认为 1 。当超过最大次数时，返回 proxy_next_upstream 模块定义的错误</span><br><span class="line">fail_timeout=30;     # max_fails 次失败后，暂停的时间</span><br></pre></td></tr></table></figure>

<p>详细的，可以再看看 <a target="_blank" rel="noopener" href="http://ifeve.com/nginx-http/">《Nginx 官方文档 —— 使用 Nginx 作为 HTTP 负载均衡》</a> 文章。</p>
<h3 id="Nginx-如何实现后端服务的健康检查？"><a href="#Nginx-如何实现后端服务的健康检查？" class="headerlink" title="Nginx 如何实现后端服务的健康检查？"></a>Nginx 如何实现后端服务的健康检查？</h3><p>参见 <a target="_blank" rel="noopener" href="https://www.cnblogs.com/kevingrace/p/6685698.html">《Nginx 负载均衡中后端节点服务器健康检查的操作梳理》</a> 文章。</p>
<ul>
<li><p>方式一，利用 nginx 自带模块 ngx_http_proxy_module 和 ngx_http_upstream_module 对后端节点做健康检查。</p>
</li>
<li><p>方式二，利用 nginx_upstream_check_module 模块对后端节点做健康检查。</p>
<blockquote>
<p>推荐使用。</p>
</blockquote>
</li>
</ul>
<h3 id="Nginx-如何开启压缩？"><a href="#Nginx-如何开启压缩？" class="headerlink" title="Nginx 如何开启压缩？"></a>Nginx 如何开启压缩？</h3><p>参见 <a target="_blank" rel="noopener" href="https://www.daixiaorui.com/read/251.html">《Nginx 开启 gzip 压缩的配置详解和压缩效果对比》</a> 文章。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fatefrank.github.io/2020/08/10/%E7%B2%BE%E5%B0%BD%E3%80%90%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E3%80%91%E9%9D%A2%E8%AF%95%E9%A2%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Seif Zheng">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Seif Zheng's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/10/%E7%B2%BE%E5%B0%BD%E3%80%90%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E3%80%91%E9%9D%A2%E8%AF%95%E9%A2%98/" class="post-title-link" itemprop="url">分布式事务 面试题</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-08-10 00:00:00 / 修改时间：15:31:04" itemprop="dateCreated datePublished" datetime="2020-08-10T00:00:00+08:00">2020-08-10</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="什么是分布式事务？"><a href="#什么是分布式事务？" class="headerlink" title="什么是分布式事务？"></a>什么是分布式事务？</h2><p>分布式事务就是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。简单的说，就是一次大的操作由不同的小操作组成，这些小的操作分布在不同的服务器上，且属于不同的应用，分布式事务需要保证这些小操作要么全部成功，要么全部失败。本质上来说，分布式事务就是为了保证不同数据库的数据一致性。</p>
<p>或者，在换一句话说，分布式事务 = n 个本地事务。通过事务管理器，达到 n 个本地事务要么全部成功，要么全部失败。</p>
<h2 id="为什么会有分布式事务？"><a href="#为什么会有分布式事务？" class="headerlink" title="为什么会有分布式事务？"></a>为什么会有分布式事务？</h2><p>从本地事务来看，我们可以看为两块，一个是 service 产生多个节点，另一个是 resource 产生多个节点。</p>
<p>可能会有人说，我们就是一个单体应用，不存在这样的情况。OK ，没问题，那么我们回过头来想想用户下单完成，我们需要给用户发短信。如果发送短信失败，可能是网络抖动的原因，我们是不应该去回滚本地事务，那么此时也可以认为是一个分布式事务。</p>
<p>1）service 多个节点</p>
<p>随着互联网快速发展，微服务，SOA等服务架构模式正在被大规模的使用，举个简单的例子，一个公司之内，用户的资产可能分为好多个部分，比如余额，积分，优惠券等等。在公司内部有可能积分功能由一个微服务团队维护，优惠券又是另外的团队维护。</p>
<p>这样的话就无法保证积分扣减了之后，优惠券能否扣减成功。</p>
<p>2）resource 多个节点</p>
<p>同样的，互联网发展得太快了，我们的Mysql一般来说装千万级的数据就得进行分库分表，对于一个支付宝的转账业务来说，你给的朋友转钱，有可能你的数据库是在北京，而你的朋友的钱是存在上海，所以我们依然无法保证他们能同时成功。</p>
<p><img src="http://static2.iocoder.cn/d25d3a43ddbcbc256913e4b6622d88a3" alt="img"></p>
<p>可能会有人说，我们数据没做分库分表，不存在这样的情况。OK，没问题，那么我们回过头来想想最常见的场景，系统里引入了 Redis 做缓存，那么 DB 和 Redis 的一致性问题，就是一种分布式事务的场景。</p>
<p>🦅 <strong>是否真的要分布式事务？</strong></p>
<p>在说分布式事务的方案之前，首先你一定要明确你是否真的需要分布式事务？</p>
<p>上面说过出现分布式事务的两个原因，其中有个原因是因为微服务过多。我见过太多团队一个人维护几个微服务，太多团队过度设计，搞得所有人疲劳不堪，而微服务过多就会引出分布式事务，这个时候我不会建议你去采用分布式事务的方案，而是请把需要事务的微服务聚合成一个单机服务，使用数据库的本地事务。因为不论任何一种方案都会增加你系统的复杂度，这样的成本实在是太高了，千万不要因为追求某些设计，而引入不必要的成本和复杂度。</p>
<p>当然，如果你是个人的练习 Demo 项目，请使劲的造，拼命的玩。甚至说，我建议你能读完所使用的分布式事务的方案的原理和源码。因为，一旦上了生产，出了问题，你很有可能无从下手~</p>
<p>所以，想清楚你是否需要分布式事务，你是否能够 hold 住分布式事务的解决方案。</p>
<h2 id="分布式事务的基础？"><a href="#分布式事务的基础？" class="headerlink" title="分布式事务的基础？"></a>分布式事务的基础？</h2><p>数据库的 ACID 满足了数据库本地事务的基础，但是它无法满足分布式事务，这个时候衍生了 CAP 和 BASE 两个经典理论。</p>
<p>🦅 <strong>CAP 理论</strong></p>
<p>CAP 定理，又被叫作布鲁尔定理。对于设计分布式系统来说(不仅仅是分布式事务)的架构师来说，CAP 就是你的入门理论。</p>
<ul>
<li>C (一致性)：在分布式系统中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访问同一份最新的数据副本）</li>
<li>A (可用性)：在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。（对数据更新具备高可用性）</li>
<li>P (分区容错性)：以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在 C 和 A 之间做出选择。</li>
</ul>
<p>高可用、数据一致性是很多系统设计的目标，但是分区又是不可避免的事情。我们来看一看分别拥有 CA、CP 和 AP 的情况。</p>
<ul>
<li>CA without P：如果不要求 P（不允许分区），则 C（强一致性）和A（可用性）是可以保证的。但其实分区不是你想不想的问题，而是始终会存在，因此 CA 的系统更多的是允许分区后各子系统依然保持 CA 。</li>
<li>CP without A：如果不要求 A（可用），相当于每个请求都需要在 Server 之间强一致，而 P（分区）会导致同步时间无限延长，如此 CP 也是可以保证的。很多传统的数据库分布式事务都属于这种模式。</li>
<li>AP wihtout C：要高可用并允许分区，则需放弃一致性。一旦分区发生，节点之间可能会失去联系，为了高可用，每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。现在众多的NoSQL都属于此类。</li>
</ul>
<p>可能胖友看完之后，会一脸懵逼，可以看看 <a target="_blank" rel="noopener" href="https://my.oschina.net/lhztt/blog/915533">《分布式系统理论（一）：CAP 定理》</a> 文章提供的示例：</p>
<ul>
<li>MySQL 主从异步复制是 AP 系统。</li>
<li>MySQL 主从半同步复制是 CP 系统。</li>
<li>Zookeeper 是 CP 系统。</li>
<li>Redis 主从同步是 AP 系统。</li>
<li>Eureka 主从同步是 AP 系统。</li>
</ul>
<p>从上的示例中，<strong>“三选二”是一个伪命题</strong>。不是为了 P（分区容忍性），要在 A 和 C 之间选择一个。分区很少出现，CAP 在大多数时候允许完美的 C 和 A 。但当分区存在或可感知其影响的情况下，就要预备一种策略去探知分区并显式处理其影响。</p>
<blockquote>
<p>艿艿，如果关于<strong>“三选二”是一个伪命题</strong>无法理解，可以回过头在看一眼“CA without P” ，对比下就好理解了。对于单节点，CA 必然是可以保证的。</p>
</blockquote>
<p>另外，关于 CAP 的论证过程，也是蛮有趣的一块内容，感兴趣的胖友，可以自己去搜索下。</p>
<p>🦅 <strong>BASE 理论</strong></p>
<p>BASE 是 Basically Available(基本可用)、Soft state(软状态)和 Eventually consistent (最终一致性) 三个短语的缩写。是对 CAP 中AP 的一个扩展</p>
<ol>
<li>BA 基本可用：分布式系统在出现故障时，允许损失部分可用功能，保证核心功能可用。</li>
<li>S 软状态：允许系统中存在中间状态，这个状态不影响系统可用性，这里指的是 CAP 中的不一致。</li>
<li>E 最终一致：最终一致是指经过一段时间后，所有节点数据都将会达到一致。</li>
</ol>
<p>BASE 解决了 CAP 中理论没有网络延迟，在 BASE 中用软状态和最终一致，保证了延迟后的一致性。</p>
<p>BASE 和 ACID 是相反的，它完全不同于 ACID 的强一致性模型，而是通过牺牲强一致性来获得可用性，并允许数据在一段时间内是不一致的，但最终达到一致状态。</p>
<blockquote>
<p>对于大部分的分布式应用而言，只要数据在规定的时间内达到最终一致性即可。我们可以把符合传统的 ACID 叫做刚性事务，把满足 BASE 理论的最终一致性事务叫做柔性事务。</p>
<p>一味的追求强一致性，并非最佳方案。对于分布式应用来说，刚柔并济是更加合理的设计方案，即在本地服务中采用强一致事务，在跨系统调用中采用最终一致性。如何权衡系统的性能与一致性，是十分考验架构师与开发者的设计功力的。</p>
</blockquote>
<p><strong>具体到分布式事务的实现上，业界主要采用了 XA 协议的强一致规范以及柔性事务的最终一致规范</strong>。</p>
<blockquote>
<p>艿艿：所以，市面上的分布式事务的解决方案，除了 XA 协议是强一直的，其他都是最终一致的。</p>
</blockquote>
<h2 id="分布式事务的实现主要有哪些方案？"><a href="#分布式事务的实现主要有哪些方案？" class="headerlink" title="分布式事务的实现主要有哪些方案？"></a>分布式事务的实现主要有哪些方案？</h2><p>分布式事务的实现主要有以下 6 种方案：</p>
<ul>
<li>XA 方案</li>
<li>TCC 方案</li>
<li>本地消息表</li>
<li>可靠消息最终一致性方案</li>
<li>最大努力通知方案</li>
<li>SAGA</li>
</ul>
<h2 id="聊聊-XA-方案？"><a href="#聊聊-XA-方案？" class="headerlink" title="聊聊 XA 方案？"></a>聊聊 XA 方案？</h2><p>XA 是 X/Open CAE Specification (Distributed Transaction Processing)模型，它定义的 TM（Transaction Manager）与 RM（Resource Manager）之间进行通信的接口。</p>
<p>Java中 的 <code>javax.transaction.xa.XAResource</code> 定义了 XA 接口，它依赖数据库厂商对 jdbc-driver 的具体实现。</p>
<ul>
<li><code>mysql-connector-java-5.1.30</code> 的实现可参 <code>com.mysql.jdbc.jdbc2.optional.MysqlXAConnection</code> 类。</li>
</ul>
<p>在 XA 规范中，数据库充当 RM 角色，应用需要充当 TM 的角色，即生成全局的 txId ，调用 XAResource 接口，把多个本地事务协调为全局统一的分布式事务。</p>
<p>目前 XA 有两种实现：</p>
<ul>
<li>基于一阶段提交( 1PC ) 的<strong>弱</strong> XA 。</li>
<li>基于二阶段提交( 2PC ) 的<strong>强</strong> XA 。</li>
</ul>
<h3 id="弱-XA"><a href="#弱-XA" class="headerlink" title="弱 XA"></a>弱 XA</h3><p><img src="http://static2.iocoder.cn/fca74dec683cdea6b986652feec19958" alt="弱 XA 的顺序图">                                                                                弱 XA 的顺序图</p>
<ul>
<li>弱 XA 通过去掉 XA 的 Prepare 阶段，以达到减少资源锁定范围而提升并发性能的效果。典型的实现为在一个业务线程中，遍历所有的数据库连接，依次做 commit 或者 rollback 。</li>
<li>弱 XA 同本地事务相比，性能损耗低，但在事务提交的执行过程中，若出现网络故障、数据库宕机等预期之外的异常，将会造成数据不一致，且无法进行回滚。</li>
</ul>
<p>🦅 <strong>解决方案？</strong></p>
<p>基于弱 XA 的事务无需额外的实现成本，相对容易。目前支持的有：</p>
<ul>
<li>MyCAT ，具体的源码解析，可以看看 <a target="_blank" rel="noopener" href="http://www.iocoder.cn/MyCAT/xa-distributed-transaction/">《MyCAT 源码分析 —— XA 分布式事务》</a> 。</li>
<li>Sharding-Sphere 默认支持。</li>
</ul>
<h3 id="强-XA"><a href="#强-XA" class="headerlink" title="强 XA"></a>强 XA</h3><p><img src="http://static2.iocoder.cn/c8f27f0e1107c328476600c4ed2608ec" alt="强 XA 的顺序图">                                                                                    强 XA 的顺序图</p>
<ul>
<li>二阶段提交是 XA 的标准实现。它将分布式事务的提交拆分为 2 个阶段：prepare 和 commit/rollback 。<ul>
<li>第一阶段：事务管理器要求每个涉及到事务的数据库预提交(precommit)此操作，并反映是否可以提交。</li>
<li>第二阶段：事务协调器要求每个数据库提交数据，或者回滚数据。</li>
</ul>
</li>
<li>开启 XA 全局事务后，所有子事务会按照本地默认的隔离级别锁定资源，并记录 undo 和 redo 日志。然后由 TM 发起 prepare 投票，询问所有的子事务是否可以进行提交：<ul>
<li>当所有子事务反馈的结果为 “yes” 时，TM 再发起 commit 。</li>
<li>若其中任何一个子事务反馈的结果为“no”，TM 则发起 rollback 。</li>
<li>如果在 prepare 阶段的反馈结果为 “yes” ，而 commit 的过程中出现宕机等异常时，则在节点服务重启后，可根据 XA recover 再次进行 commit 补偿，以保证数据的一致性。</li>
</ul>
</li>
</ul>
<p>🦅 <strong>优点？</strong></p>
<ul>
<li>尽量保证了数据的强一致，实现成本较低，在各大主流数据库都有自己实现，对于 MySQL 是从 5.5 开始支持。</li>
</ul>
<p>🦅 <strong>缺点？</strong></p>
<ul>
<li><p>单点问题：事务管理器在整个流程中扮演的角色很关键，如果其宕机，比如在第一阶段已经完成，在第二阶段正准备提交的时候事务管理器宕机，资源管理器就会一直阻塞，导致数据库无法使用。</p>
<blockquote>
<p>如果事务管理器是 Proxy 模式的数据库中间件，并且实现高可用，可能可以解决这个问题。不太肯定，需要到时翻下 Sharding Sphere 的源码。TODO</p>
</blockquote>
</li>
<li><p>同步阻塞：在准备就绪之后，资源管理器中的资源一直处于阻塞，直到提交完成，释放资源。</p>
</li>
<li><p>数据不一致：两阶段提交协议虽然为分布式数据强一致性所设计，但仍然存在数据不一致性的可能，比如在第二阶段中，假设协调者发出了事务commit 的通知，但是因为网络问题该通知仅被一部分参与者所收到并执行了 commit 操作，其余的参与者则因为没有收到通知一直处于阻塞状态，这时候就产生了数据的不一致性。</p>
<blockquote>
<p>此处的数据不一致也问题不大，因为使用 xa 会锁定记录，无法被访问。</p>
</blockquote>
</li>
</ul>
<p>🦅 解决方案？</p>
<ul>
<li><p>Sharding Sphere</p>
<blockquote>
<p>Sharding Sphere 支持基于 XA 的强一致性事务解决方案，可以通过 SPI 注入不同的第三方组件作为事务管理器实现 XA 协议，如 Atomikos 和 Narayana 。</p>
</blockquote>
</li>
<li><p><a target="_blank" rel="noopener" href="https://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-jta.html">Spring JTA + Atomikos</a></p>
</li>
</ul>
<h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><p>这种分布式事务方案，比较适合单块应用里，跨多个库的分布式事务，而且因为严重依赖于数据库层面来搞定复杂的事务，效率很低，绝对不适合高并发的场景。</p>
<p>这个方案，我们很少用，一般来说<strong>某个系统内部如果出现跨多个库</strong>的这么一个操作，是<strong>不合规</strong>的。我可以给大家介绍一下， 现在微服务，一个大的系统分成几百个服务，几十个服务。一般来说，我们的规定和规范，是要求<strong>每个服务只能操作自己对应的一个数据库</strong>。</p>
<p>如果你要操作别的服务对应的库，不允许直连别的服务的库，违反微服务架构的规范，你随便交叉胡乱访问，几百个服务的话，全体乱套，这样的一套服务是没法管理的，没法治理的，可能会出现数据被别人改错，自己的库被别人写挂等情况。</p>
<p>如果你要操作别人的服务的库，你必须是通过<strong>调用别的服务的接口</strong>来实现，绝对不允许交叉访问别人的数据库。</p>
<p><a target="_blank" rel="noopener" href="http://static2.iocoder.cn/baef17d9dde837632e9a7894cb825cb2"><img src="http://static2.iocoder.cn/baef17d9dde837632e9a7894cb825cb2" alt="distributed-transacion-XA"></a>distributed-transacion-XA</p>
<h2 id="聊聊-TCC-方案？"><a href="#聊聊-TCC-方案？" class="headerlink" title="聊聊 TCC 方案？"></a>聊聊 TCC 方案？</h2><p>TCC 模型是把锁的粒度完全交给业务处理，它需要每个子事务业务都实现Try-Confirm / Cancel 接口。</p>
<blockquote>
<p>TCC 模式本质也是 2PC ，只是 TCC 在应用层控制。</p>
</blockquote>
<ul>
<li><p>Try:</p>
<ul>
<li>尝试执行业务</li>
<li>完成所有业务检查（一致性）</li>
<li>预留必须业务资源（准隔离性）</li>
</ul>
</li>
<li><p>Confirm:</p>
<ul>
<li>确认执行业务；</li>
<li>真正执行业务，不作任何业务检查</li>
<li>只使用Try阶段预留的业务资源</li>
<li>Confirm 操作满足幂等性</li>
</ul>
</li>
<li><p>Cancel:</p>
<ul>
<li>取消执行业务</li>
<li>释放Try阶段预留的业务资源</li>
<li>Cancel操作满足幂等性</li>
</ul>
</li>
</ul>
<p>这三个阶段，都会按本地事务的方式执行。不同于 XA的prepare ，TCC 无需将 XA 的投票期间的所有资源挂起，因此极大的提高了吞吐量。</p>
<p>🦅 <strong>应用场景</strong></p>
<p>下面对TCC模式下，A账户往B账户汇款100元为例子，对业务的改造进行详细的分析：</p>
<p><a target="_blank" rel="noopener" href="http://static2.iocoder.cn/4da5bc0df774ef90e97c6358eb7e632f"><img src="http://static2.iocoder.cn/4da5bc0df774ef90e97c6358eb7e632f" alt="img"></a>img</p>
<ul>
<li>汇款服务和收款服务分别需要实现，Try-Confirm-Cancel 接口，并在业务初始化阶段将其注入到 TCC 事务管理器中。</li>
</ul>
<p>汇款服务</p>
<ul>
<li>Try：<ul>
<li>检查A账户有效性，即查看A账户的状态是否为“转帐中”或者“冻结”</li>
<li>检查A账户余额是否充足</li>
<li>从A账户中扣减 100 元，并将状态置为“转账中”</li>
<li>预留扣减资源，将从 A 往 B 账户转账 100 元这个事件存入消息或者日志中</li>
</ul>
</li>
<li>Confirm：<ul>
<li>不做任何操作</li>
</ul>
</li>
<li>Cancel：<ul>
<li>A 账户增加 100 元</li>
<li>从日志或者消息中，释放扣减资源</li>
</ul>
</li>
</ul>
<p>收款服务</p>
<ul>
<li>Try：<ul>
<li>检查 B 账户账户是否有效；</li>
</ul>
</li>
<li>Confirm：<ul>
<li>读取日志或者消息，B 账户增加 100 元</li>
<li>从日志或者消息中，释放扣减资源；</li>
</ul>
</li>
<li>Cancel：<ul>
<li>不做任何操作</li>
</ul>
</li>
</ul>
<p>由此可以看出，TCC 模型对业务的侵入强，改造的难度大。</p>
<p>但是，在需要前置资源锁定的场景，不得不使用 XA 或 TCC 的方式。再例如说，下单场景，在订单创建之前，需要扣除如下几个资源：</p>
<ul>
<li>优惠劵</li>
<li>钱包余额</li>
<li>积分</li>
<li>….</li>
</ul>
<p>那么，不得不进行前置多资源锁定，无非是使用 XA 的强锁，还是 TCC 的弱锁。在 <a target="_blank" rel="noopener" href="https://github.com/YunaiV/oceans/tree/0.0.1">oceans</a> 的 tag <code>0.0.1</code> 中，在未使用 TCC 的情况下，模拟 TCC 的效果的苦闷。</p>
<p>当然，如果能不用 TCC 的情况下，尽量不要用 TCC 。因为，编写回滚逻辑的代码，可能会比较恶心。</p>
<p>🦅 <strong>解决方案？</strong></p>
<ul>
<li>TCC-Transaction ，听说喜马拉雅在用。具体的源码解析，可以看看 <a target="_blank" rel="noopener" href="http://www.iocoder.cn/categories/TCC-Transaction/">《TCC-Transaction 源码分析》</a> 。</li>
<li>Hmily ，具体的源码解析，可以看看 <a target="_blank" rel="noopener" href="http://www.iocoder.cn/Hmily/good-collection/">《Hmily 实现原理与源码解析系列 —— 精品合集》</a> 。</li>
<li>ByteTCC</li>
</ul>
<h2 id="聊聊本地消息表？"><a href="#聊聊本地消息表？" class="headerlink" title="聊聊本地消息表？"></a>聊聊本地消息表？</h2><p>本地消息表，其实是 <a target="_blank" rel="noopener" href="https://queue.acm.org/detail.cfm?id=1394128">国外的 Ebay 搞出来的这么一套思想</a> 。</p>
<p>这个大概意思是这样的：</p>
<p><a target="_blank" rel="noopener" href="http://static2.iocoder.cn/b1fc3558543e402cb373792eade99e0f"><img src="http://static2.iocoder.cn/b1fc3558543e402cb373792eade99e0f" alt="distributed-transaction-local-message-table"></a>distributed-transaction-local-message-table</p>
<ol>
<li>A 系统在自己本地一个事务里操作同时，插入一条数据到消息表；</li>
<li>接着 A 系统将这个消息发送到 MQ 中去；</li>
<li>B 系统接收到消息之后，在一个事务里，往自己本地消息表里插入一条数据，同时执行其他的业务操作，如果这个消息已经被处理过了，那么此时这个事务会回滚，这样<strong>保证不会重复处理消息</strong>；</li>
<li>B 系统执行成功之后，就会更新自己本地消息表的状态以及 A 系统消息表的状态；</li>
<li>如果 B 系统处理失败了，那么就不会更新消息表状态，那么此时 A 系统会定时扫描自己的消息表，如果有未处理的消息，会再次发送到 MQ 中去，让 B 再次处理；</li>
<li>这个方案保证了最终一致性，哪怕 B 事务失败了，但是 A 会不断重发消息，直到 B 那边成功为止。</li>
</ol>
<p>这个方案说实话最大的问题就在于<strong>严重依赖于数据库的消息表来管理事务</strong>啥的，会导致如果是高并发场景咋办呢？咋扩展呢？所以一般确实很少用。</p>
<p>本地消息队列是 BASE 理论，是最终一致模型，适用于对一致性要求不高的。实现这个模型时需要注意重试的幂等。</p>
<h2 id="聊聊可靠消息最终一致性方案？"><a href="#聊聊可靠消息最终一致性方案？" class="headerlink" title="聊聊可靠消息最终一致性方案？"></a>聊聊可靠消息最终一致性方案？</h2><p>这个的意思，就是干脆不要用本地的消息表了，直接基于 MQ 来实现事务。比如阿里的 RocketMQ 就支持消息事务。</p>
<p>大概的意思就是：</p>
<p><a target="_blank" rel="noopener" href="http://static2.iocoder.cn/80a431c9be51ed67d9c67f7a1de7c2ed"><img src="http://static2.iocoder.cn/80a431c9be51ed67d9c67f7a1de7c2ed" alt="distributed-transaction-reliable-message"></a>distributed-transaction-reliable-message</p>
<ol>
<li>A 系统先发送一个 prepared 消息到 mq，如果这个 prepared 消息发送失败那么就直接取消操作别执行了；</li>
<li>如果这个消息发送成功过了，那么接着执行本地事务，如果成功就告诉 mq 发送确认消息，如果失败就告诉 mq 回滚消息；</li>
<li>如果发送了确认消息，那么此时 B 系统会接收到确认消息，然后执行本地的事务；</li>
<li>mq 会自动<strong>定时轮询</strong>所有 prepared 消息回调你的接口，问你，这个消息是不是本地事务处理失败了，所有没发送确认的消息，是继续重试还是回滚？一般来说这里你就可以查下数据库看之前本地事务是否执行，如果回滚了，那么这里也回滚吧。这个就是避免可能本地事务执行成功了，而确认消息却发送失败了。</li>
<li>这个方案里，要是系统 B 的事务失败了咋办？重试咯，自动不断重试直到成功，如果实在是不行，要么就是针对重要的资金类业务进行回滚，比如 B 系统本地回滚后，想办法通知系统 A 也回滚；或者是发送报警由人工来手工回滚和补偿。</li>
</ol>
<p><strong>这个还是比较合适的，目前国内互联网公司大都是这么玩儿的</strong>。</p>
<p>🦅 <strong>解决方案</strong></p>
<ul>
<li><p>RocketMQ 事务消息，源码解析，可见 <a target="_blank" rel="noopener" href="http://www.iocoder.cn/RocketMQ/message-transaction/?vip">《RocketMQ 源码分析 —— 事务消息》</a> 。</p>
<blockquote>
<p>虽然 RocketMQ 早期开源事务消息后又阉割闭源，但是在 RocketMQ 4.3 版本中，又重新提供。所以，不要搞错落。</p>
</blockquote>
</li>
<li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/u013256816/article/details/55515234">《RabbitMQ 之消息确认机制（事务+Confirm）》</a></p>
</li>
<li><p>Kafka 事务消息，<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/42046847">https://zhuanlan.zhihu.com/p/42046847</a> TODO 需要找厮大确认下</p>
</li>
</ul>
<h2 id="聊聊最大努力通知方案？"><a href="#聊聊最大努力通知方案？" class="headerlink" title="聊聊最大努力通知方案？"></a>聊聊最大努力通知方案？</h2><p>艿艿瞅了瞅市面上的资料，分别有两种解释。或者说，两种不同的解决方案。</p>
<h3 id="解释一"><a href="#解释一" class="headerlink" title="解释一"></a>解释一</h3><p>最大努力送达，是针对于弱 XA 的一种补偿策略。它采用事务表记录所有的事务操作 SQL 。</p>
<p><a target="_blank" rel="noopener" href="http://static2.iocoder.cn/728bf44f14926be91f33c4c7fda15fad"><img src="http://static2.iocoder.cn/728bf44f14926be91f33c4c7fda15fad" alt="img"></a>img</p>
<ul>
<li>如果子事务提交成功，将会删除事务日志。</li>
<li>如果执行失败，则会按照配置的重试次数，尝试再次提交，即最大努力的进行提交，尽量保证数据的一致性，这里可以根据不同的业务场景，平衡 C 和 A ，采用同步重试或异步重试。</li>
</ul>
<p>🦅 <strong>优点</strong></p>
<ul>
<li>无锁定资源时间，性能损耗小。</li>
</ul>
<p>🦅 <strong>缺点</strong></p>
<ul>
<li>尝试多次提交失败后，无法回滚，它仅适用于事务最终一定能够成功的业务场景。</li>
</ul>
<p>🦅 <strong>总结</strong></p>
<ul>
<li>因此 BED 是通过事务回滚功能上的妥协，来换取性能的提升。</li>
</ul>
<p>貌似，暂时也想象不到具体的使用场景。</p>
<p>🦅 <strong>解决方案</strong></p>
<p>正如上图，提供的解决方式 Sharding-JDBC ，具体的源码解析，可见 <a target="_blank" rel="noopener" href="http://www.iocoder.cn/Sharding-JDBC/transaction-bed/?vip">《Sharding-JDBC 源码分析 —— 分布式事务（一）之最大努力型》</a> 。</p>
<h3 id="解释二"><a href="#解释二" class="headerlink" title="解释二"></a>解释二</h3><p>这个方案的大致意思就是：</p>
<ol>
<li>系统 A 本地事务执行完之后，发送个消息到 MQ；</li>
<li>这里会有个专门消费 MQ 的<strong>最大努力通知服务</strong>，这个服务会消费 MQ 然后写入数据库中记录下来，或者是放入个内存队列也可以，接着调用系统 B 的接口；</li>
<li>要是系统 B 执行成功就 ok 了；要是系统 B 执行失败了，那么最大努力通知服务就定时尝试重新调用系统 B，反复 N 次，最后还是不行就放弃。</li>
</ol>
<p>🦅 <strong>解决方案</strong></p>
<p>按照这个解释，RocketMQ 的消息重试，符合这个解释。具体的源码解析，见 <a target="_blank" rel="noopener" href="http://www.iocoder.cn/RocketMQ/message-schedule-and-retry/">《RocketMQ 源码分析 —— 定时消息与消息重试》</a> 。</p>
<p>比较常见的场景，就是支付成功后，多次回调~</p>
<h2 id="聊聊-Saga-方案？"><a href="#聊聊-Saga-方案？" class="headerlink" title="聊聊 Saga 方案？"></a>聊聊 Saga 方案？</h2><p>Saga 是 30 年前一篇数据库伦理提到的一个概念。其核心思想是将长事务拆分为多个本地短事务，由 Saga 事务协调器协调，如果正常结束那就正常完成，如果某个步骤失败，则根据相反顺序一次调用补偿操作。</p>
<p>Saga 的组成如下：</p>
<ul>
<li>每个 Saga 由一系列 sub-transaction Ti 组成</li>
<li>每个Ti 都有对应的补偿动作 Ci ，补偿动作用于撤销 Ti 造成的结果。这里的每个 T ，都是一个本地事务。</li>
<li>可以看到，和 TCC 相比，Saga 没有“预留 try”动作 ，它的 Ti 就是直接提交到库。</li>
</ul>
<p>Saga的执行顺序有两种：</p>
<ul>
<li>子事务序列 T1, T2, …, Tn得以完成 (最佳情况)。</li>
<li>或者序列 T1, T2, …, Tj, Cj, …, C2, C1, 0 &lt; j &lt; n, 得以完成。</li>
</ul>
<p>Saga 定义了两种恢复策略：</p>
<ul>
<li><p>向后恢复：补偿所有已完成的事务，如果任一子事务失败。</p>
<blockquote>
<p>向后恢复，即上面提到的第二种执行顺序，其中 j 是发生错误的 sub-transaction ，这种做法的效果是撤销掉之前所有成功的 sub-transation ，使得整个 Saga 的执行结果撤销。</p>
</blockquote>
</li>
<li><p>向前恢复：重试失败的事务，假设每个子事务最终都会成功。</p>
<blockquote>
<p>显然，向前恢复没有必要提供补偿事务，如果你的业务中，子事务（最终）总会成功，或补偿事务难以定义或不可能，向前恢复更符合你的需求。理论上补偿事务永不失败，然而，在分布式世界中，服务器可能会宕机、网络可能会失败，甚至数据中心也可能会停电，这时需要提供故障恢复后回退的机制，比如人工干预。</p>
</blockquote>
</li>
</ul>
<p>🦅 <strong>如何解决没有 Prepare阶段可能带来的问题？</strong></p>
<p>由于 Saga 模型中没有 Prepare 阶段，因此事务间不能保证隔离性，当多个 Saga 事务操作同一资源时，就会产生更新丢失、脏数据读取等问题，这时需要在业务层控制并发。例如：</p>
<ul>
<li>在应用层面加锁。</li>
<li>应用层面预先冻结资源。</li>
</ul>
<p>还是拿 100 元买一瓶水的例子来说。</p>
<ul>
<li><p>这里定义：</p>
<ul>
<li>T1=扣100元 T2=给用户加一瓶水 T3=减库存一瓶水</li>
<li>C1=加100元 C2=给用户减一瓶水 C3=给库存加一瓶水</li>
</ul>
</li>
<li><p>我们一次进行 T1，T2，T3。如果发生问题，就执行发生问题的 C 操作的反向。上面说到的隔离性的问题会出现在，如果执行到 T3 这个时候需要执行回滚，但是这个用户已经把水喝了(<strong>另外一个事务</strong>)，回滚的时候就会发现，无法给用户减一瓶水了。这就是事务之间没有隔离性的问题。</p>
<blockquote>
<p>艿艿：也就是说，给的太早，但是可以被取消！</p>
</blockquote>
</li>
</ul>
<p>可以看见 Saga 模式没有隔离性的影响还是较大，可以参照华为的解决方案:</p>
<ul>
<li>从业务层面入手加入一 Session 以及锁的机制来保证能够串行化操作资源。</li>
<li>也可以在业务层面通过预先冻结资金的方式隔离这部分资源，最后在业务操作的过程中可以通过及时读取当前状态的方式获取到最新的更新。</li>
</ul>
<p>🦅 <strong>解决方案</strong></p>
<ul>
<li><p>Apache Service Comb 的 Saga 事务引擎</p>
</li>
<li><p>Sharding Sphere 的 Saga 支持</p>
<blockquote>
<p>实际是基于 Apache Service Comb 的 Saga 事务引擎之上进行开发。</p>
</blockquote>
</li>
</ul>
<h2 id="你们公司是如何处理分布式事务的？"><a href="#你们公司是如何处理分布式事务的？" class="headerlink" title="你们公司是如何处理分布式事务的？"></a>你们公司是如何处理分布式事务的？</h2><p>如果你真的被问到，可以这么说：</p>
<ul>
<li><p>我们某某特别严格的场景，用的是 TCC 来保证强一致性。</p>
<blockquote>
<p>你找一个严格资金要求绝对不能错的场景，你可以说你是用的 TCC 方案。</p>
</blockquote>
</li>
<li><p>然后其他的一些场景，基于阿里的 RocketMQ 来实现了分布式事务。</p>
<blockquote>
<p>如果是一般的分布式事务场景，订单插入之后要调用库存服务更新库存，库存数据没有资金那么的敏感，可以用可靠消息最终一致性方案。</p>
</blockquote>
</li>
</ul>
<h2 id="什么是三阶段协议？"><a href="#什么是三阶段协议？" class="headerlink" title="什么是三阶段协议？"></a>什么是三阶段协议？</h2><p>这个问题，严格来说不属于【分布式事务】相关，考虑到本文已经出现了一阶段提交、二阶段提交，所以这里就瞬时“硬塞”一个三阶段提交。</p>
<p>感兴趣的，可以看看 <a target="_blank" rel="noopener" href="https://www.jianshu.com/p/a20f1895d9c7">《数据库 分布式事务 2阶提交 3阶提交》</a> 文章。</p>
<p>##</p>
<h2 id="事务解决方案的对比总结"><a href="#事务解决方案的对比总结" class="headerlink" title="事务解决方案的对比总结"></a>事务解决方案的对比总结</h2><p>总的来说，TCC 和 MQ 都是以服务为范围进行分布式事务的处理，而 XA、BED、SAGA 则是以数据库为范围进行分布式处理。</p>
<blockquote>
<p>对于数据库中间来来说，更趋向于选择后者，对于业务而言侵入小，改造的成本低。</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="http://static2.iocoder.cn/c015006c18d7b4a59463fd00d589f2e1"><img src="http://static2.iocoder.cn/c015006c18d7b4a59463fd00d589f2e1" alt="对比图"></a>对比图</p>
<ul>
<li>图中暂时未包括：1）本地消息表；2）可靠消息最终一致性方案 。因为，这个是 Sharding Sphere 官方提供的图，嘻嘻。</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fatefrank.github.io/2020/08/10/%E7%B2%BE%E5%B0%BD%E3%80%90%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E3%80%91%E9%9D%A2%E8%AF%95%E9%A2%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Seif Zheng">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Seif Zheng's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/10/%E7%B2%BE%E5%B0%BD%E3%80%90%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E3%80%91%E9%9D%A2%E8%AF%95%E9%A2%98/" class="post-title-link" itemprop="url">分库分表 面试题</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-08-10 00:00:00 / 修改时间：14:37:54" itemprop="dateCreated datePublished" datetime="2020-08-10T00:00:00+08:00">2020-08-10</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="为什么使用分库分表？"><a href="#为什么使用分库分表？" class="headerlink" title="为什么使用分库分表？"></a>为什么使用分库分表？</h3><p>传统的将数据集中存储至单一数据节点的解决方案，在<strong>性能、可用性和运维成本</strong>这三方面已经难于满足互联网的海量数据场景。</p>
<p>1）性能</p>
<p>从性能方面来说，由于关系型数据库大多采用 B+ 树类型的索引，在数据量超过阈值的情况下，索引深度的增加也将使得磁盘访问的 IO 次数增加，进而导致查询性能的下降。</p>
<p>同时，高并发访问请求也使得集中式数据库成为系统的最大瓶颈。</p>
<p>2）可用性</p>
<p>从可用性的方面来讲，服务化的无状态型，能够达到较小成本的随意扩容，这必然导致系统的最终压力都落在数据库之上。而单一的数据节点，或者简单的主从架构，已经越来越难以承担。数据库的可用性，已成为整个系统的关键。</p>
<p>3）运维成本</p>
<p>从运维成本方面考虑，当一个数据库实例中的数据达到阈值以上，对于 DBA 的运维压力就会增大。数据备份和恢复的时间成本都将随着数据量的大小而愈发不可控。一般来讲，单一数据库实例的数据的阈值在 1TB 之内，是比较合理的范围。</p>
<p>🦅 <strong>那么为什么不选择 NoSQL 呢？</strong></p>
<p>在传统的关系型数据库无法满足互联网场景需要的情况下，将数据存储至原生支持分布式的 NoSQL 的尝试越来越多。 但 NoSQL 对 SQL 的不兼容性以及生态圈的不完善，使得它们在与关系型数据库的博弈中始终无法完成致命一击，而关系型数据库的地位却依然不可撼动。</p>
<h3 id="什么是分库分表？"><a href="#什么是分库分表？" class="headerlink" title="什么是分库分表？"></a>什么是分库分表？</h3><p>数据分片，指按照某个维度将存放在单一数据库中的数据分散地存放至多个数据库或表中以达到提升性能瓶颈以及可用性的效果。数据分片的有效手段是对关系型数据库进行<strong>分库和分表</strong>。</p>
<ul>
<li>分库和分表均可以有效的避免由数据量超过可承受阈值而产生的查询瓶颈。除此之外，分库还能够用于有效的分散对数据库单点的访问量。</li>
<li>分表虽然无法缓解数据库压力，但却能够提供尽量将分布式事务转化为本地事务的可能，一旦涉及到跨库的更新操作，分布式事务往往会使问题变得复杂。</li>
<li>使用多主多从的分片方式，可以有效的避免数据单点，从而提升数据架构的可用性。</li>
</ul>
<p>通过分库和分表进行数据的拆分来使得各个表的数据量保持在阈值以下，以及对流量进行疏导应对高访问量，是应对高并发和海量数据系统的有效手段。数据分片的拆分方式又分为垂直分片和水平分片。</p>
<p>🦅 <strong>垂直分片</strong></p>
<p>按照业务拆分的方式称为垂直分片，又称为纵向拆分，它的核心理念是专库专用。 在拆分之前，一个数据库由多个数据表构成，每个表对应着不同的业务。而拆分之后，则是按照业务将表进行归类，分布到不同的数据库中，从而将压力分散至不同的数据库。</p>
<p>垂直分片往往需要对架构和设计进行调整。通常来讲，是来不及应对互联网业务需求快速变化的；而且，它也并无法真正的解决单点瓶颈。 垂直拆分可以缓解数据量和访问量带来的问题，但无法根治。如果垂直拆分之后，表中的数据量依然超过单节点所能承载的阈值，则需要水平分片来进一步处理。</p>
<p>例如：根据业务需要，将用户表和订单表垂直分片到不同的数据库。</p>
<p>垂直拆分的优点：</p>
<ul>
<li>库表职责单一，复杂度降低，易于维护。</li>
<li>单库或单表压力降低。 相互之间的影响也会降低。</li>
</ul>
<p>垂直拆分的缺点：</p>
<ul>
<li>部分表关联无法在数据库级别完成，需要在程序中完成。</li>
<li>单表大数据量仍然存在性能瓶颈。</li>
<li>单表或单库高热点访问依旧对 DB 压力非常大。</li>
<li>事务处理相对更为复杂，需要分布式事务的介入。</li>
<li>拆分达到一定程度之后，扩展性会遇到限制。</li>
</ul>
<p>🦅 <strong>水平分片</strong></p>
<p>水平分片又称为横向拆分。 相对于垂直分片，它不再将数据根据业务逻辑分类，而是通过某个字段（或某几个字段），根据某种规则将数据分散至多个库或表中，每个分片仅包含数据的一部分。</p>
<p>例如：根据主键分片，偶数主键的记录放入 0 库（或表），奇数主键的记录放入 1 库（或表）。</p>
<p>水平分片从理论上突破了单机数据量处理的瓶颈，并且扩展相对自由，是分库分表的标准解决方案。</p>
<p>水平拆分的优点：</p>
<ul>
<li>解决单表单库大数据量和高热点访问性能遇到瓶颈的问题。</li>
<li>应用程序端整体架构改动相对较少。</li>
<li>事务处理相对简单。</li>
<li>只要切分规则能够定义好，基本上较难遇到扩展性限制。</li>
</ul>
<p>水平拆分缺点：</p>
<ul>
<li>拆分规则相对更复杂，很难抽象出一个能够满足整个数据库的切分规则。</li>
<li>后期数据的维护难度有所增加，人为手工定位数据更困难。</li>
<li>产品逻辑将变复杂。比如按年来进行历史数据归档拆分，这个时候在页面设计上就需要约束用户必须要先选择年，然后才能进行查询。</li>
</ul>
<p>🦅 <strong>总结？</strong></p>
<ul>
<li>数据表垂直拆分：单表复杂度。</li>
<li>数据库垂直拆分：功能拆分。</li>
<li>水平拆分<ul>
<li>分表：解决单表大数据量问题。</li>
<li>分库：为了解决单库性能问题。</li>
</ul>
</li>
</ul>
<h3 id="用了分库分表之后，有哪些常见问题？"><a href="#用了分库分表之后，有哪些常见问题？" class="headerlink" title="用了分库分表之后，有哪些常见问题？"></a>用了分库分表之后，有哪些常见问题？</h3><p>虽然数据分片解决了性能、可用性以及单点备份恢复等问题，但分布式的架构在获得了收益的同时，也引入了新的问题。</p>
<ul>
<li><p>面对如此散乱的分库分表之后的数据，应用开发工程师和数据库管理员对数据库的操作变得异常繁重就是其中的重要挑战之一。他们需要知道数据需要从哪个具体的数据库的分表中获取。</p>
</li>
<li><p>另一个挑战则是，能够正确的运行在单节点数据库中的 SQL ，在分片之后的数据库中并不一定能够正确运行。</p>
<ul>
<li>例如，分表导致表名称的修改，或者分页、排序、聚合分组等操作的不正确处理。</li>
<li>例如，跨节点 join 的问题。</li>
</ul>
</li>
<li><p><strong>跨库事务</strong>也是分布式的数据库集群要面对的棘手事情。</p>
<ul>
<li><p>合理采用分表，可以在降低单表数据量的情况下，尽量使用本地事务，善于使用同库不同表可有效避免分布式事务带来的麻烦。</p>
<blockquote>
<p>要达到这个效果，需要尽量把同一组数据放到同一组 DB 服务器上。</p>
<p>例如说，将同一个用户的订单主表，和订单明细表放到同一个库，那么在创建订单时，还是可以使用相同本地事务。</p>
</blockquote>
</li>
<li><p>在不能避免跨库事务的场景，有些业务仍然需要保持事务的一致性。而基于 XA 的分布式事务由于在并发度高的场景中性能无法满足需要，并未被互联网巨头大规模使用，他们大多采用最终一致性的柔性事务代替强一致事务。</p>
</li>
</ul>
</li>
<li><p>分布式全局唯一 ID 。</p>
<ul>
<li>在单库单表的情况下，直接使用数据库自增特性来生成主键ID，这样确实比较简单。</li>
<li>在分库分表的环境中，数据分布在不同的分表上，不能再借助数据库自增长特性。需要使用全局唯一 ID，例如 UUID、GUID等 。</li>
</ul>
</li>
</ul>
<p>关于这块，也可以看看 <a target="_blank" rel="noopener" href="https://www.yuque.com/lexiangqizhong/java/ckt9uw">《分库分表》</a> 文章。</p>
<h3 id="了解和使用过哪些分库分表中间件？"><a href="#了解和使用过哪些分库分表中间件？" class="headerlink" title="了解和使用过哪些分库分表中间件？"></a>了解和使用过哪些分库分表中间件？</h3><p>在将数据库进行分库分表之后，我们一般会引入分库分表的中间件，使之能够达到如下目标。</p>
<blockquote>
<p>尽量透明化分库分表所带来的影响，让使用方尽量像使用一个数据库一样使用水平分片之后的数据库集群，这是分库分表的主要设计目标。</p>
</blockquote>
<p>🦅 <strong>分库分表的实现方式？</strong></p>
<p>目前，市面上提供的分库分表的中间件，主要有两种实现方式：</p>
<ul>
<li>Client 模式</li>
<li>Proxy 模式</li>
</ul>
<p>🦅 <strong>分库分表中间件？</strong></p>
<p>比较常见的包括：</p>
<ul>
<li>Cobar</li>
<li>MyCAT</li>
<li>Atlas</li>
<li>TDDL</li>
<li>Sharding Sphere</li>
</ul>
<p>1）Cobar</p>
<p>阿里 b2b 团队开发和开源的，属于 Proxy 层方案。</p>
<p>早些年还可以用，但是最近几年都没更新了，基本没啥人用，差不多算是被抛弃的状态吧。而且不支持读写分离、存储过程、跨库 join 和分页等操作。</p>
<p>2）MyCAT</p>
<p>基于 Cobar 改造的，属于 Proxy 层方案，支持的功能非常完善，而且目前应该是非常火的而且不断流行的数据库中间件，社区很活跃，也有一些公司开始在用了。但是确实相比于 Sharding Sphere 来说，年轻一些，经历的锤炼少一些。</p>
<p>3）Atlas</p>
<p>360 开源的，属于 Proxy 层方案，以前是有一些公司在用的，但是确实有一个很大的问题就是社区最新的维护都在 5 年前了。所以，现在用的公司基本也很少了。</p>
<p>4）TDDL</p>
<p>淘宝团队开发的，属于 client 层方案。支持基本的 crud 语法和读写分离，但不支持 join、多表查询等语法。目前使用的也不多，因为还依赖淘宝的 diamond 配置管理系统。</p>
<p>5）Sharding Sphere</p>
<p>Sharding Sphere ，可能是目前最好的开源的分库分表解决方案，目前已经进入 Apache 孵化。</p>
<p>Sharding Sphere 提供三种模式：</p>
<blockquote>
<p>关于每一种模式的介绍，可以看看 <a target="_blank" rel="noopener" href="http://shardingsphere.io/document/current/cn/overview/">《ShardingSphere &gt; 概览》</a></p>
</blockquote>
<ul>
<li>Sharding-JDBC</li>
<li>Sharding-Proxy</li>
<li>Sharding-Sidecar 计划开发中。</li>
</ul>
<p>其中，Sharding-JDBC 属于 client 层方案，被大量互联网公司所采用。例如，当当、京东金融、中国移动等等。</p>
<p>🦅 <strong>如何选择？</strong></p>
<p>综上，现在其实建议考量的，就是 Sharding Sphere ，这个可以满足我们的诉求。</p>
<p>Sharding Sphere 的 Sharding-JDBC 方案，这种 Client 层方案的<strong>优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能很高</strong>，但是如果遇到升级啥的需要各个系统都重新升级版本再发布，各个系统都需要<strong>耦合</strong> sharding-jdbc 的依赖。</p>
<blockquote>
<p>据了解，例如阿里、美团内部，更多使用的是 Client 模式。</p>
</blockquote>
<p>Sharding Sphere 的 Sharding-Proxy 方案，这种 Proxy 层方案，可以解决我们平时查询数据库的需求。我们只需要连接一个 Sharding-Proxy ，就可以查询分库分表中的数据。另外，如果我们有跨语言的需求，例如 PHP、GO 等，也可以使用它。</p>
<h3 id="如何迁移到分库分表？"><a href="#如何迁移到分库分表？" class="headerlink" title="如何迁移到分库分表？"></a>如何迁移到分库分表？</h3><p>一般来说，会有三种方式：</p>
<ul>
<li>1、停止部署法。</li>
<li>2、双写部署法，基于业务层。</li>
<li>3、双写部署法，基于 binlog 。</li>
</ul>
<p>具体的详细方案，可以看看如下两篇文章：</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://www.iocoder.cn/Fight/After-the-database-sharding-how-to-deploy-online/">《数据库分库分表后，如何部署上线？》</a></li>
<li><a target="_blank" rel="noopener" href="http://www.chaiguanxin.com/articles/2018/11/11/1541923418699.html">《【面试宝典】如何把单库数据迁移到分库分表？》</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/daiwei1981/p/9416068.html">《分库分表的面试题3》</a></li>
</ul>
<p>另外，这是另外一个比较相对详细的【双写部署法，基于业务层】的过程：</p>
<ul>
<li>双写 ，老库为主。读操作还是读老库老表，写操作是双写到新老表。</li>
<li>历史数据迁移 dts + 新数据对账校验（job） + 历史数据校验。</li>
<li>切读：读写以新表为主，新表成功就成功了。</li>
<li>观察几天，下掉写老库操作。</li>
</ul>
<p>另外，飞哥的 <a target="_blank" rel="noopener" href="https://www.jianshu.com/p/223d71421f49">《不停机分库分表迁移》</a> 文章，也非常推荐看看。</p>
<p>🦅 <strong>如何设计可以动态扩容缩容的分库分表方案？</strong></p>
<p>可以参看 <a target="_blank" rel="noopener" href="https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/database-shard-dynamic-expand.md">《如何设计可以动态扩容缩容的分库分表方案？》</a> 文章。简单的结论是：</p>
<ul>
<li>提前考虑好容量的规划，避免扩容的情况。</li>
<li>如果真的需要扩容，走上述的 <a target="_blank" rel="noopener" href="http://svip.iocoder.cn/database-sharding/Interview/#">「如何迁移到分库分表？」</a> 提到的方案。</li>
</ul>
<h3 id="什么是分布式主键？怎么实现？"><a href="#什么是分布式主键？怎么实现？" class="headerlink" title="什么是分布式主键？怎么实现？"></a>什么是分布式主键？怎么实现？</h3><p>分布式主键的实现方案有很多，可以看看 <a target="_blank" rel="noopener" href="http://www.iocoder.cn/Architecture/talk-about-global-id/">《谈谈 ID》</a> 的总结。</p>
<p>一般来说，目前采用 SnowFlake 的居多，可以看看 <a target="_blank" rel="noopener" href="http://www.iocoder.cn/Sharding-JDBC/distributed-id/?vip">《Sharding-JDBC 源码分析 —— 分布式主键》</a> 的源码的具体实现，比较简单。</p>
<h3 id="分片键的选择？"><a href="#分片键的选择？" class="headerlink" title="分片键的选择？"></a>分片键的选择？</h3><p>分库分表后，分片键的选择非常重要。一般来说是这样的：</p>
<ul>
<li>信息表，使用 id 进行分片。例如说，文章、商品信息等等。</li>
<li>业务表，使用 user_id 进行分片。例如说，订单表、支付表等等。</li>
<li>日志表，使用 create_time 进行分片。例如说，访问日志、登陆日志等等。</li>
</ul>
<p>🦅 <strong>分片算法的选择？</strong></p>
<p>选择好分片键之后，还需要考虑分片算法。一般来说，有如下两种：</p>
<ul>
<li>取余分片算法。例如说，有四个库，那么 user_id 为 10 时，分到第<code>10 % 4 = 2</code>个库。<ul>
<li>当然，如果分片键是字符串，则需要先进行 hash 的方式，转换成整形，这样才可以取余。</li>
<li>当然，如果分片键是整数，也可以使用 hash 的方式。</li>
</ul>
</li>
<li>范围算法。<ul>
<li>例如说，时间范围。</li>
</ul>
</li>
</ul>
<p>上述两种算法，各有优缺点。</p>
<ul>
<li>对于取余来说：<ul>
<li>好处，可以平均分配每个库的数据量和请求压力。</li>
<li>坏处，在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表。</li>
</ul>
</li>
<li>对于 range 来说：<ul>
<li>好处，扩容的时候很简单，因为你只要预备好，给每个月都准备一个库就可以了，到了一个新的月份的时候，自然而然，就会写新的库了。</li>
<li>缺点，但是大部分的请求，都是访问最新的数据。实际生产用 range，要看场景。</li>
</ul>
</li>
</ul>
<p>🦅 <strong>如果查询条件不带分片键，怎么办？</strong></p>
<p>当查询不带分片键时，则中间件一般会扫描所有库表，然后聚合结果，然后进行返回。</p>
<p>对于大多数情况下，如果每个库表的查询速度还可以，返回结果的速度也是不错的。具体可以根据自己的业务进行测试。</p>
<p>🦅 <strong>使用 user_id 分库分表后，使用 id 查询怎么办？</strong></p>
<p>有四种方案。</p>
<p>1）不处理</p>
<p>正如在 <a target="_blank" rel="noopener" href="http://svip.iocoder.cn/database-sharding/Interview/#">「如果查询条件不带分片键，怎么办？」</a> 问题所说，如果性能可以接受，可以不去处理。当然，前提是这样的查询不多，不会给系统带来负担。</p>
<p>2）映射关系</p>
<p>创建映射表，只有 id、user_id 两列字段。使用 id 查询时，先从映射表获得 id 对应的 user_id ，然后再使用 id + user_id 去查询对应的表。</p>
<p>当然，随着业务量的增长，映射表也会越来越大，后续也可能需要进行分库分表。</p>
<p>对于这方式，也可以有一些优化方案。</p>
<ul>
<li>映射表改成缓存到 Redis 等 KV 缓存中。当然，需要考虑如果 Redis 持久化的情况。</li>
<li>将映射表缓存到内存中，减少一次到映射表的查询。</li>
</ul>
<p>3）基因 id</p>
<p>分库基因：假如通过 user_id 分库，分为 8 个库，采用 user_id % 8 的方式进行路由，此时是由 user_id 的最后 3bit 来决定这行 User 数据具体落到哪个库上，那么这 3bit 可以看为分库基因。那么，如果我们将这 3 bit 参考类似 Snowflake 的方式，融入进入到 id 。</p>
<blockquote>
<p>艿艿：这里的 3 bit 只是举例子，实际需要考虑自己分多少库表，来决定到底使用多少 bit 。</p>
</blockquote>
<p>上面的映射关系的方法需要额外存储映射表，按非 user_id 字段查询时，还需要多一次数据库或 Cache 的访问。通过基因 id ，就可以知道数据所在的库表。</p>
<p>详细说明，可以看看 <a target="_blank" rel="noopener" href="http://www.10tiao.com/html/249/201704/2651960032/1.html">《用 uid 分库，uname 上的查询怎么办？》</a> 文章。</p>
<p>目前，可以从 <a target="_blank" rel="noopener" href="https://tech.meituan.com/dianping_order_db_sharding.html">《大众点评订单系统分库分表实践》</a> 文章中，看到大众点评订单使用了基因 id 。</p>
<p>4）多 sharding column</p>
<p>具体的内容，可以参考 <a target="_blank" rel="noopener" href="https://yq.aliyun.com/articles/641529">《分库分表的正确姿势，你 GET 到了么？》</a> 。当然，这种方案也是比较复杂的方案。</p>
<h3 id="如何解决分布式事务？"><a href="#如何解决分布式事务？" class="headerlink" title="如何解决分布式事务？"></a>如何解决分布式事务？</h3><p>目前市面上，分布式事务的解决方案还是蛮多的，但是都是基于一个前提，需要保证本地事务。<strong>那么，就对我们在分库分表时，就有相应的要求：数据在分库分表时，需要保证一个逻辑中，能够形成本地事务</strong>。举个例子，创建订单时，我们会插入订单表和订单明细表，那么：</p>
<ul>
<li><p>如果我们基于这两个表的 id 进行分库分表，将会导致插入的记录被分到不同的库表中，因为创建下单可以购买 n 个商品，那么就会有 1 条订单记录和 n 条 订单明细记录。而这 n 条订单明细记录无法和 1 条订单记录分到一个库表中。</p>
</li>
<li><p>如果我们基于这两个表的 user_id 进行分库分表，那么插入的记录被分到相同的库表中。</p>
<blockquote>
<p>这也是为什么业务表一般使用 user_id 进行分库分表的原因之一。</p>
</blockquote>
</li>
</ul>
<p>可能会有胖友有疑问，为什么一定要形成本地事务？在有了本地事务的基础上，通过使用分布式事务的解决方案，协调多个本地事务，形成最终一致性。另外，本地事务在这个过程中，能够保证万一执行失败，再重试时，不会产生脏数据。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fatefrank.github.io/2020/08/10/Redis%20%E9%9D%A2%E8%AF%95%E9%A2%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Seif Zheng">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Seif Zheng's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/10/Redis%20%E9%9D%A2%E8%AF%95%E9%A2%98/" class="post-title-link" itemprop="url">Redis 面试题</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-08-10 00:00:00 / 修改时间：10:00:44" itemprop="dateCreated datePublished" datetime="2020-08-10T00:00:00+08:00">2020-08-10</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="什么是-Redis-？"><a href="#什么是-Redis-？" class="headerlink" title="什么是 Redis ？"></a>什么是 Redis ？</h3><p><a target="_blank" rel="noopener" href="http://lib.csdn.net/base/redis">Redis</a> ，全称 Remote Dictionary Server ，是一个基于内存的高性能 Key-Value <a target="_blank" rel="noopener" href="http://lib.csdn.net/base/mysql">数据库</a>。</p>
<p>Redis 已经成为互联网公司在缓存组件的<strong>唯一选择</strong>。例如说，在各种公有云上，缓存服务都是提供的 Redis。再例如说，招聘简历要求上，都会要求掌握 Redis 。</p>
<h3 id="Redis-有什么优点？"><a href="#Redis-有什么优点？" class="headerlink" title="Redis 有什么优点？"></a>Redis 有什么优点？</h3><p>🦅 <strong>1. 速度快</strong></p>
<p>因为数据存在内存中，类似于 HashMap ，HashMap 的优势就是查找和操作的时间复杂度都是O (1) 。</p>
<blockquote>
<p>Redis 本质上是一个 Key-Value 类型的内存数据库，很像 Memcached ，整个数据库统统加载在内存当中进行操作，定期通过异步操作把数据库数据 flush 到硬盘上进行保存。</p>
<p>因为是纯内存操作，Redis 的性能非常出色，每秒可以处理超过 10 万次读写操作，是已知性能最快的 Key-Value 数据库。</p>
</blockquote>
<ul>
<li>如果我们查看在<a target="_blank" rel="noopener" href="https://help.aliyun.com/document_detail/26350.html">阿里云销售的 Redis 规格</a>，最低的也是 8W QPS 。</li>
</ul>
<p>🦅 <strong>2. 支持丰富数据类型</strong></p>
<p>支持 String ，List，Set，Sorted Set，Hash 五种基础的数据结构。</p>
<blockquote>
<p>Redis 的出色之处不仅仅是性能，Redis 最大的魅力是支持保存多种数据结构，此外单个 Value 的最大限制是 1GB，不像 Memcached只能保存 1MB 的数据，因此 Redis 可以用来实现很多有用的功能。比方说：</p>
<ul>
<li>用他的 List 来做 FIFO 双向链表，实现一个轻量级的高性能消息队列服务。</li>
<li>用他的 Set 可以做高性能的 tag 系统等等。</li>
</ul>
</blockquote>
<p>同时，在基础的数据结构之上，还提供 <a target="_blank" rel="noopener" href="http://redisdoc.com/bitmap/index.html">Bitmap</a>、<a target="_blank" rel="noopener" href="http://redisdoc.com/hyperloglog/index.html">HyperLogLog</a>、<a target="_blank" rel="noopener" href="http://redisdoc.com/geo/index.html">GEO</a> 等高级的数据结构。</p>
<p>如果面试想要加分，胖友一定要去看看这些高级的数据结构，面试与日常开发，必备神器。</p>
<p>🦅 <strong>3. 丰富的特性</strong></p>
<ul>
<li>订阅发布 Pub / Sub 功能</li>
<li>Key 过期策略</li>
<li>事务</li>
<li>支持多个 DB</li>
<li>计数</li>
<li>…</li>
</ul>
<p>并且在 Redis 5.0 增加了 Stream 功能，一个新的强大的支持多播的可持久化的消息队列，提供类似 Kafka 的功能。</p>
<p>🦅 <strong>4. 持久化存储</strong></p>
<p>Redis 提供 RDB 和 AOF 两种数据的持久化存储方案，解决内存数据库最担心的万一 Redis 挂掉，数据会消失掉。</p>
<p>🦅 <strong>5、高可用</strong></p>
<p>内置 Redis Sentinel ，提供高可用方案，实现主从故障自动转移。</p>
<p>内置 Redis Cluster ，提供集群方案，实现基于槽的分片方案，从而支持更大的 Redis 规模。</p>
<h3 id="Redis-有什么缺点？"><a href="#Redis-有什么缺点？" class="headerlink" title="Redis 有什么缺点？"></a>Redis 有什么缺点？</h3><ul>
<li><p>1、由于 Redis 是内存数据库，所以，单台机器，存储的数据量，跟机器本身的内存大小。虽然 Redis 本身有 Key 过期策略，但是还是需要提前预估和节约内存。如果内存增长过快，需要定期删除数据。</p>
<blockquote>
<p>另外，可使用 Redis Cluster、Codis 等方案，对 Redis 进行分区，从单机 Redis 变成集群 Redis 。</p>
</blockquote>
</li>
<li><p>2、如果进行完整重同步，由于需要生成 RDB 文件，并进行传输，会占用主机的 CPU ，并会消耗现网的带宽。不过 Redis2.8 版本，已经有部分重同步的功能，但是还是有可能有完整重同步的。比如，新上线的备机。</p>
</li>
<li><p>3、修改配置文件，进行重启，将硬盘中的数据加载进内存，时间比较久。在这个过程中，Redis 不能提供服务。</p>
</li>
</ul>
<h3 id="Redis-和-Memcached-的区别有哪些？"><a href="#Redis-和-Memcached-的区别有哪些？" class="headerlink" title="Redis 和 Memcached 的区别有哪些？"></a>Redis 和 Memcached 的区别有哪些？</h3><blockquote>
<p>随着 Memcached 日渐没落，这个问题问的越来越少了。</p>
</blockquote>
<p>🦅 <strong>1. Redis 支持复杂的数据结构</strong></p>
<ul>
<li>Memcached 仅提供简单的字符串。</li>
<li>Redis 提供复杂的数据结构，丰富的数据操作。</li>
</ul>
<p>也因为 Redis 支持复杂的数据结构，Redis 即使晚于 Memcached 推出，却获得更多开发者的青睐。</p>
<p>Redis 相比 Memcached 来说，拥有更多的数据结构，能支持更丰富的数据操作。如果需要缓存能够支持更复杂的结构和操作，Redis 会是不错的选择。</p>
<p>🦅 <strong>2. Redis 原生支持集群模式</strong></p>
<ul>
<li>在 Redis3.x 版本中，官方便能支持 Cluster 模式。</li>
<li>Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据。</li>
</ul>
<p>🦅 <strong>3. 性能对比</strong></p>
<ul>
<li>Redis 只使用单核，而 Memcached 可以使用多核，所以平均每一个核上 Redis在存储小数据时比 Memcached 性能更高。</li>
<li>在 100k 以上的数据中，Memcached 性能要高于 Redis 。虽然 Redis 最近也在存储大数据的性能上进行优化，但是比起 Memcached，还是稍有逊色。</li>
</ul>
<p>更多关于性能的对比，可以看看 <a target="_blank" rel="noopener" href="https://www.jianshu.com/p/34f90813d7c9">《Memcached 与 Redis 的关键性能指标比较》</a> 。</p>
<p>🦅 <strong>4. 内存管理机制不同</strong></p>
<p>相比来说，Redis 的内存管理机制，会更加简单。</p>
<ul>
<li>Redis 采用的是<strong>包装</strong>的 malloc/free ，使用时现场申请的方式。</li>
<li>Memcached 采用的是 Slab Allocation 机制管理内存，预分配的内存池的方式。</li>
</ul>
<p>如果对比两者的内存使用效率：</p>
<ul>
<li>简单的 Key-Value 存储的话，Memcached 的内存利用率更高，可以使用类似内存池。</li>
<li>如果 Redis 采用 hash 结构来做 key-value 存储，由于其组合式的压缩， 其内存利用率会高于 Memcached 。</li>
</ul>
<p>🦅 <strong>5. 网络 IO 模型</strong></p>
<ul>
<li>Memcached 是多线程，非阻塞 IO 复用的网络模型，原型上接近 Nignx 。</li>
<li>Redis 使用单线程的 IO 复用模型，自己封装了一个简单的 AeEvent 事件处理框架，主要实现了 epoll ， kqueue 和 select ，更接近 Apache 早期的模式。</li>
</ul>
<p>🦅 <strong>6. 持久化存储</strong></p>
<ul>
<li>Memcached 不支持持久化存储，重启时，数据被清空。</li>
<li>Redis 支持持久化存储，重启时，可以恢复已持久化的数据。</li>
</ul>
<hr>
<p>也推荐阅读下 <a target="_blank" rel="noopener" href="https://www.imooc.com/article/23549">《脚踏两只船的困惑 - Memcached 与 Redis》</a> 。</p>
<h3 id="请说说-Redis-的线程模型？"><a href="#请说说-Redis-的线程模型？" class="headerlink" title="请说说 Redis 的线程模型？"></a>请说说 Redis 的线程模型？</h3><blockquote>
<p><strong>一般来说，回答道 Redis 是非阻塞 IO ，多路复用</strong>。</p>
</blockquote>
<p>Redis 内部使用文件事件处理器 <code>file event handler</code>，这个文件事件处理器是单线程的，所以 Redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 Socket，根据 Socket 上的事件来选择对应的事件处理器进行处理。</p>
<p>文件事件处理器的结构包含 4 个部分：</p>
<ul>
<li>多个 Socket 。</li>
<li>IO 多路复用程序。</li>
<li>文件事件分派器。</li>
<li>事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）。</li>
</ul>
<p>多个 Socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将 socket 产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理。</p>
<p>来看客户端与 redis 的一次通信过程 (3次入队出队)：</p>
<p><img src="http://static2.iocoder.cn/images/Redis/2019_11_22/01.png" alt="redis-single-thread-model">                                                                        redis-single-thread-model</p>
<ul>
<li>客户端 Socket01 向 Redis 的 Server Socket 请求建立连接，此时 Server Socket 会产生一个 <code>AE_READABLE</code> 事件(图中的ss)，IO 多路复用程序监听到 server socket 产生的事件后，将该事件压入队列中。文件事件分派器从队列中获取该事件，交给<code>连接应答处理器</code>。连接应答处理器会创建一个能与客户端通信的 Socket01，并将该 Socket01 的 <code>AE_READABLE</code> 事件与命令请求处理器关联。</li>
<li>假设此时客户端发送了一个 <code>set key value</code> 请求，此时 Redis 中的 Socket01 会产生 <code>AE_READABLE</code> 事件，IO 多路复用程序将事件压入队列，此时事件分派器从队列中获取到该事件，由于前面 Socket01 的 <code>AE_READABLE</code> 事件已经与命令请求处理器关联，因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取 Scket01 的 <code>set key value</code> 并在自己内存中完成 <code>set key value</code> 的设置。操作完成后，它会将 Socket01 的 <code>AE_WRITABLE</code> 事件与令回复处理器关联。</li>
<li>如果此时客户端准备好接收返回结果了，那么 Redis 中的 Socket01 会产生一个 <code>AE_WRITABLE</code> 事件，同样压入队列中，事件分派器找到相关联的命令回复处理器，由命令回复处理器对 socket01 输入本次操作的一个结果，比如 <code>ok</code>，之后解除 Socket01 的 <code>AE_WRITABLE</code> 事件与命令回复处理器的关联。</li>
</ul>
<p>这样便完成了一次通信。</p>
<h3 id="为什么-Redis-单线程模型也能效率这么高？"><a href="#为什么-Redis-单线程模型也能效率这么高？" class="headerlink" title="为什么 Redis 单线程模型也能效率这么高？"></a>为什么 Redis 单线程模型也能效率这么高？</h3><ul>
<li><p>1、C 语言实现。</p>
<blockquote>
<p>我们都知道，C 语言的执行速度非常快。</p>
</blockquote>
</li>
<li><p>2、纯内存操作。</p>
<blockquote>
<p>Redis 为了达到最快的读写速度，将数据都读到内存中，并通过异步的方式将数据写入磁盘。所以 Redis 具有快速和数据持久化的特征。</p>
<p>如果不将数据放在内存中，磁盘 I/O 速度为严重影响 Redis 的性能。</p>
</blockquote>
</li>
<li><p>3、基于非阻塞的 IO 多路复用机制。</p>
</li>
<li><p>4、单线程，避免了多线程的频繁上下文切换问题。</p>
<blockquote>
<p>Redis 利用队列技术，将并发访问变为串行访问，消除了传统数据库串行控制的开销。</p>
<p>实际上，Redis 4.0 开始，也开始有了一些异步线程，用于处理一些耗时操作。例如说，异步线程，实现<a target="_blank" rel="noopener" href="https://blog.csdn.net/zhanglong_4444/article/details/88350443">惰性删除</a>（解决大 KEY 删除，阻塞主线程）和异步 AOF （解决磁盘 IO 紧张时，fsync 执行一次很慢）等等。</p>
</blockquote>
</li>
<li><p>5、丰富的数据结构。</p>
<blockquote>
<p>Redis 全程使用 hash 结构，读取速度快，还有一些特殊的数据结构，对数据存储进行了优化。例如，压缩表，对短数据进行压缩存储；再再如，跳表，使用有序的数据结构加快读取的速度。</p>
<p>也因为 Redis 是单线程的，所以可以实现丰富的数据结构，无需考虑并发的问题。</p>
</blockquote>
</li>
</ul>
<h3 id="Redis-是单线程的，如何提高多核-CPU-的利用率？"><a href="#Redis-是单线程的，如何提高多核-CPU-的利用率？" class="headerlink" title="Redis 是单线程的，如何提高多核 CPU 的利用率？"></a>Redis 是单线程的，如何提高多核 CPU 的利用率？</h3><p>可以在同一个服务器部署多个 Redis 的实例，并把他们当作不同的服务器来使用，在某些时候，无论如何一个服务器是不够的， 所以，如果你想使用多个 CPU ，你可以考虑一下分区。</p>
<h3 id="Redis-有几种持久化方式？"><a href="#Redis-有几种持久化方式？" class="headerlink" title="Redis 有几种持久化方式？"></a>Redis 有几种持久化方式？</h3><blockquote>
<p>这个问题有一丢丢长，耐心看完。</p>
<p>面试的时候，如果不能完整回答出来，也不会有大问题。重点，在于有条理，对 RDB 和 AOF 有理解。</p>
</blockquote>
<p>🦅 <strong>持久化方式</strong></p>
<p>Redis 提供了两种方式，实现数据的持久化到硬盘。</p>
<ul>
<li>1、【全量】RDB 持久化，是指在指定的时间间隔内将内存中的<strong>数据集快照</strong>写入磁盘。实际操作过程是，fork 一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储。</li>
<li>2、【增量】AOF持久化，以日志的形式记录服务器所处理的每一个<strong>写、删除操作</strong>，查询操作不会记录，以文本的方式记录，可以打开文件看到详细的操作记录。</li>
</ul>
<p>🦅 <strong>RDB 优缺点</strong></p>
<p>① 优点</p>
<ul>
<li>灵活设置备份频率和周期。你可能打算每个小时归档一次最近 24 小时的数据，同时还要每天归档一次最近 30 天的数据。通过这样的备份策略，一旦系统出现灾难性故障，我们可以非常容易的进行恢复。</li>
<li>非常适合冷备份，对于灾难恢复而言，RDB 是非常不错的选择。因为我们可以非常轻松的将一个单独的文件压缩后再转移到其它存储介质上。推荐，可以将这种完整的数据文件发送到一些远程的安全存储上去，比如说 Amazon 的 S3 云服务上去，在国内可以是阿里云的 OSS 分布式存储上。</li>
<li>性能最大化。对于 Redis 的服务进程而言，在开始持久化时，它唯一需要做的只是 fork 出子进程，之后再由子进程完成这些持久化的工作，这样就可以极大的避免服务进程执行 IO 操作了。也就是说，RDB 对 Redis 对外提供的读写服务，影响非常小，可以让 Redis 保持高性能。</li>
<li>恢复更快。相比于 AOF 机制，RDB 的恢复速度更更快，更适合恢复数据，特别是在数据集非常大的情况。</li>
</ul>
<p>② 缺点</p>
<ul>
<li><p>如果你想保证数据的高可用性，即最大限度的避免数据丢失，那么 RDB 将不是一个很好的选择。因为系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失。</p>
<blockquote>
<p>所以，RDB 实际场景下，需要和 AOF 一起使用。</p>
</blockquote>
</li>
<li><p>由于 RDB 是通过 fork 子进程来协助完成数据持久化工作的，因此，如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是 1 秒钟。</p>
<blockquote>
<p>所以，RDB 建议在业务低估，例如在半夜执行。</p>
</blockquote>
</li>
</ul>
<p>🦅 <strong>AOF 优缺点</strong></p>
<p>① 优点</p>
<ul>
<li><p>该机制可以带来更高的数据安全性，即数据持久性。Redis 中提供了 3 种同步策略，即每秒同步、每修改(执行一个命令)同步和不同步。</p>
<ul>
<li>事实上，每秒同步也是异步完成的，其效率也是非常高的，所差的是一旦系统出现宕机现象，那么这一秒钟之内修改的数据将会丢失。</li>
<li>而每修改同步，我们可以将其视为同步持久化，即每次发生的数据变化都会被立即记录到磁盘中。可以预见，这种方式在效率上是最低的。</li>
<li>至于不同步，无需多言，我想大家都能正确的理解它。</li>
</ul>
</li>
<li><p>由于该机制对日志文件的写入操作采用的是append模式，因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。</p>
<ul>
<li>因为以 append-only 模式写入，所以没有任何磁盘寻址的开销，写入性能非常高。</li>
<li>另外，如果我们本次操作只是写入了一半数据就出现了系统崩溃问题，不用担心，在 Redis 下一次启动之前，我们可以通过 redis-check-aof 工具来帮助我们解决数据一致性的问题。</li>
</ul>
</li>
<li><p>如果 AOF 日志过大，Redis 可以自动启用 <strong>rewrite</strong> 机制。即使出现后台重写操作，也不会影响客户端的读写。因为在 rewrite log 的时候，会对其中的指令进行压缩，创建出一份需要恢复数据的最小日志出来。再创建新日志文件的时候，老的日志文件还是照常写入。当新的 merge 后的日志文件 ready 的时候，再交换新老日志文件即可。</p>
<blockquote>
<p>注意，AOF <strong>rewrite</strong> 机制，和 RDB 一样，也需要 fork 出一次子进程，如果 Redis 内存比较大，可能会因为 fork 阻塞下主进程。</p>
</blockquote>
</li>
<li><p>AOF 包含一个格式清晰、易于理解的日志文件用于记录所有的<strong>修改操作</strong>。事实上，我们也可以通过该文件完成数据的重建。</p>
</li>
</ul>
<p>② 缺点</p>
<ul>
<li>对于相同数量的数据集而言，AOF 文件通常要大于 RDB 文件。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。</li>
<li>根据同步策略的不同，AOF 在运行效率上往往会慢于 RDB 。总之，每秒同步策略的效率是比较高的，同步禁用策略的效率和 RDB 一样高效。</li>
<li>以前 AOF 发生过 bug ，就是通过 AOF 记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以说，类似 AOF 这种较为复杂的基于命令日志/merge/回放的方式，比基于 RDB 每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有 bug 。不过 AOF 就是为了避免 rewrite 过程导致的 bug ，因此每次 rewrite 并不是基于旧的指令日志进行 merge 的，而是基于当时内存中的数据进行指令的重新构建，这样健壮性会好很多。</li>
</ul>
<p>🦅 <strong>如何选择</strong></p>
<ul>
<li><p>不要仅仅使用 RDB，因为那样会导致你丢失很多数据。</p>
</li>
<li><p>也不要仅仅使用 AOF，因为那样有两个问题，第一，你通过 AOF 做冷备，没有 RDB 做冷备，来的恢复速度更快; 第二，RDB 每次简单粗暴生成数据快照，更加健壮，可以避免 AOF 这种复杂的备份和恢复机制的 bug 。</p>
</li>
<li><p>Redis 支持同时开启开启两种持久化方式，我们可以综合使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为数据恢复的第一选择; 用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复。</p>
<ul>
<li><p>如果同时使用 RDB 和 AOF 两种持久化机制，那么在 Redis 重启的时候，会使用 <strong>AOF</strong> 来重新构建数据，因为 AOF 中的<strong>数据更加完整</strong>。</p>
<blockquote>
<p>一般来说， 如果想达到足以媲美 PostgreSQL 的数据安全性， 你应该同时使用两种持久化功能。如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失，那么你可以只使用 RDB 持久化。</p>
<p>有很多用户都只使用 AOF 持久化，但并不推荐这种方式：因为定时生成 RDB 快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比AOF恢复的速度要快，除此之外，使用 RDB 还可以避免之前提到的 AOF 程序的 bug。</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<p>在 Redis4.0 版本开始，允许你使用 RDB-AOF 混合持久化方式，详细可见 <a target="_blank" rel="noopener" href="https://yq.aliyun.com/articles/193034">《Redis4.0 之 RDB-AOF 混合持久化》</a> 。也因此，RDB 和 AOF 同时使用，是希望达到安全的持久化的推荐方式。</p>
<hr>
<p>另外，RDB 和 AOF 涉及的知识点蛮多的，可以看看：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://redisbook.readthedocs.io/en/latest/internal/rdb.html">《Redis 设计与实现 —— RDB》</a></li>
<li><a target="_blank" rel="noopener" href="https://redisbook.readthedocs.io/en/latest/internal/aof.html">《Redis 设计与实现 —— AOF》</a></li>
</ul>
<p>如下是老钱对这块的总结，可能更加适合面试的场景：</p>
<ul>
<li><p>bgsave 做镜像全量持久化，AOF 做增量持久化。因为 bgsave 会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据，所以需要 AOF 来配合使用。在 Redis 实例重启时，会使用 bgsave 持久化文件重新构建内存，再使用 AOF 重放近期的操作指令来实现完整恢复重启之前的状态。</p>
<blockquote>
<p>和老钱沟通了下，最后一句重启恢复，使用的是 RDB-AOF 的混合方案。</p>
</blockquote>
</li>
<li><p>对方追问那如果突然机器掉电会怎样？取决于 AOF 日志 sync 属性的配置，如果不要求性能，在每条写指令时都 sync 一下磁盘，就不会丢失数据。但是在高性能的要求下每次都 sync 是不现实的，一般都使用定时 sync ，比如 1 秒 1 次，这个时候最多就会丢失 1 秒的数据。</p>
<blockquote>
<p>实际上，极端情况下，是最多丢失 2 秒的数据。因为 AOF 线程，负责每秒执行一次 fsync 操作，操作完成后，记录最后同步时间。主线程，负责对比上次同步时间，如果超过 2 秒，阻塞等待成功。</p>
</blockquote>
</li>
<li><p>对方追问 bgsave 的原理是什么？你给出两个词汇就可以了，fork 和 cow 。fork 是指 Redis 通过创建子进程来进行 bgsave 操作。cow 指的是 copy on write ，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。</p>
<blockquote>
<p>艿艿：这里 bgsave 操作后，会产生 RDB 快照文件。</p>
</blockquote>
</li>
</ul>
<p>为什么不建议在主 Redis 节点开启 RDB 功能呢？因为会带来一定时间的阻塞，特别是数据量大的时候。</p>
<blockquote>
<p>如下来自球友【jian】的回答，感恩~</p>
<ul>
<li>【重点】<strong>子进程 fork 相关的阻塞：在 bgsave 的时候，Redis 主进程会 fork 一个子进程，利用操作系统的写时复制技术，这个子进程在拷贝父进程的时候理论上是很快的，因为并不需要全拷贝，比如主进程虽然占了 10G 内存，但子进程拷贝他可能只要 200 毫秒，我认为也就阻塞了 200 毫秒(此耗时基本跟主进程占用的内存是成正比的)，这个具体的时间可以通过统计项 info stats 里的 last_fork_usec 查看。</strong></li>
<li>CPU 单线程相关的阻塞：Redis 主进程是单线程跑在单核 CPU 上的，如果显示绑定了CPU ，则子进程会与主进程共享一个 CPU ，而子进程进行持久化的时候是非常占CPU（强势 90%），因此这种情况也可能导致提供服务的主进程发生阻塞（因此如果需要持久化功能，不建议绑定CPU）。</li>
<li>内存相关的阻塞：虽然利用写时复制技术可以大大降低进程拷贝的内存消耗，但这也导致了父进程在处理写请求时需要维护修改的内存页，因此这部分内存过大的话（修改页数多或每页占空间大）也会导致父进程的写操作阻塞。（而不巧的是，Linux中TransparentHugePage 会将复制内存页面单位有 4K 变成 2M ，这对于 Redis 来说是比较不友好的，也是建议优化的，具体可百度之）</li>
<li>磁盘相关的阻塞：极端情况下，假设整个机器的内存已经所剩无几，触发了内存交换（SWAP），则整个 Redis的效率将会非常低下（显然这不仅仅针对 save/bgsave ），因此，关注系统的 io 情况，也是定位阻塞问题的一种方法。</li>
</ul>
<p>艿艿后来又看了下这个答案，是 <a target="_blank" rel="noopener" href="https://u.jd.com/lDNJa9">《Redis 开发与运维》</a> 的「5.3 持久化 —— 问题定位于优化」小节。</p>
</blockquote>
<h3 id="Redis-有几种数据“过期”策略？"><a href="#Redis-有几种数据“过期”策略？" class="headerlink" title="Redis 有几种数据“过期”策略？"></a>Redis 有几种数据“过期”策略？</h3><p>Redis 的过期策略，就是指当 Redis 中缓存的 key 过期了，Redis 如何处理。</p>
<p>Redis 提供了 3 种数据过期策略：</p>
<ul>
<li>被动删除：当读/写一个已经过期的 key 时，会触发惰性删除策略，直接删除掉这个过期 key 。</li>
<li>主动删除：由于惰性删除策略无法保证冷数据被及时删掉，所以 Redis 会定期主动淘汰一批已过期的 key 。</li>
<li>主动删除：当前已用内存超过 maxmemory 限定时，触发主动清理策略，即 <a target="_blank" rel="noopener" href="http://svip.iocoder.cn/Redis/Interview/#">「数据“淘汰”策略」</a> 。</li>
</ul>
<p>在 Redis 中，同时使用了上述 3 种策略，即它们<strong>非互斥</strong>的。</p>
<p>想要进一步了解，可以看看 <a target="_blank" rel="noopener" href="https://www.cnblogs.com/chenpingzhao/p/5022467.html">《关于 Redis 数据过期策略》</a> 文章。</p>
<h3 id="Redis-有哪几种数据“淘汰”策略？"><a href="#Redis-有哪几种数据“淘汰”策略？" class="headerlink" title="Redis 有哪几种数据“淘汰”策略？"></a>Redis 有哪几种数据“淘汰”策略？</h3><p>Redis 内存数据集大小上升到一定大小的时候，就会进行数据淘汰策略。</p>
<p>Redis 提供了 6 种数据淘汰策略：</p>
<ol>
<li>volatile-lru</li>
<li>volatile-ttl</li>
<li>volatile-random</li>
<li>allkeys-lru</li>
<li>allkeys-random</li>
<li>【默认策略】no-enviction</li>
</ol>
<p>具体的<strong>每种数据淘汰策略的定义</strong>，和<strong>如何选择讨论策略</strong>，可见 <a target="_blank" rel="noopener" href="http://blog.720ui.com/2016/redis_action_02_maxmemory_policy/">《Redis实战（二） 内存淘汰机制》</a> 。</p>
<p>在 Redis 4.0 后，基于 LFU（Least Frequently Used）最近最少使用算法，增加了 2 种淘汰策略：</p>
<ol>
<li>volatile-lfu</li>
<li>allkeys-lfu</li>
</ol>
<p>🦅 <strong>Redis LRU 算法</strong></p>
<p>另外，Redis 的 LRU 算法，<strong>并不是一个严格的 LRU 实现</strong>。这意味着 Redis 不能选择最佳候选键来回收，也就是最久未被访问的那些键。相反，Redis 会尝试执行一个近似的 LRU 算法，通过采样一小部分键，然后在采样键中回收最适合(拥有最久未被访问时间)的那个。</p>
<p><strong>Redis 没有使用真正实现严格的 LRU 算是的原因是，因为消耗更多的内存。然而对于使用 Redis 的应用来说，使用近似的 LRU 算法，事实上是等价的。</strong></p>
<p>具体的可以看看如下文章：</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://www.iocoder.cn/Fight/Cannot-think-of-The-interviewer-asked-me-what-if-Redis-runs-out-of-memory/?self">《想不到！面试官问我：Redis 内存满了怎么办？》</a></li>
<li><a target="_blank" rel="noopener" href="http://ifeve.com/lru-cache/">《使用 Redis 作为一个 LRU 缓存》</a></li>
</ul>
<p>🦅 <strong>MySQL 里有 2000w 数据，Redis 中只存 20w 的数据，如何保证 Redis 中的数据都是热点数据？</strong></p>
<blockquote>
<p>艿艿：这个是从网络上找到的一个神奇的问题，并且看了答案之后，觉得有点莫名的对不上。</p>
<p>所以，感觉这个问题的目的是，如何保证热点数据不要被淘汰。</p>
</blockquote>
<p>在 <a target="_blank" rel="noopener" href="http://svip.iocoder.cn/Redis/Interview/#">「Redis 有哪几种数据“淘汰”策略？」</a> 问题中，我们已经看到，“Redis 内存数据集大小上升到一定 maxmemory 的时候，就会进行数据淘汰策略。” 。</p>
<p>那么，如果我们此时要保证热点数据不被淘汰，那么需要选择 volatile-lru 或 allkeys-lru 这两个基于 LRU 算法的淘汰策略。</p>
<p>相比较来说，最终会选择 allkeys-lru 淘汰策略。原因是，如果我们的应用对缓存的访问符合幂律分布，也就是存在相对热点数据，或者我们不太清楚我们应用的缓存访问分布状况，我们可以选择 allkeys-lru 策略。如果在 Redis 4.0 版本，可以考虑使用 volatile-lfu ，更加符合“热”的概念，频率越高，代表越热。</p>
<p>🦅 <strong>Redis 回收进程如何工作的？</strong></p>
<p>理解回收进程如何工作是非常重要的：</p>
<ul>
<li>一个客户端运行了新的写命令，添加了新的数据。</li>
<li>Redis 检查内存使用情况，如果大于 maxmemory 的限制, 则根据设定好的策略进行回收。</li>
<li>Redis 执行新命令。</li>
</ul>
<p>所以我们不断地穿越内存限制的边界，通过不断达到边界然后不断地回收回到边界以下（跌宕起伏）。</p>
<h3 id="如果有大量的-key-需要设置同一时间过期，一般需要注意什么？"><a href="#如果有大量的-key-需要设置同一时间过期，一般需要注意什么？" class="headerlink" title="如果有大量的 key 需要设置同一时间过期，一般需要注意什么？"></a>如果有大量的 key 需要设置同一时间过期，一般需要注意什么？</h3><p>如果大量的 key 过期时间设置的过于集中，到过期的那个时间点，Redis可能会出现短暂的卡顿现象。</p>
<p>一般需要在时间上加一个随机值，使得过期时间分散一些。</p>
<hr>
<p>上次基友也碰到这个问题，请教了下，他的方案是调大 hz 参数，每次过期的 key 更多，从而最终达到避免一次过期过多。</p>
<blockquote>
<p>这个定期的频率，由配置文件中的 hz 参数决定，代表了一秒钟内，后台任务期望被调用的次数。Redis 3.0.0 中的默认值是 10 ，代表每秒钟调用 10 次后台任务。</p>
<p>hz 调大将会提高 Redis 主动淘汰的频率，如果你的 Redis 存储中包含很多冷数据占用内存过大的话，可以考虑将这个值调大，但 Redis 作者建议这个值不要超过 100 。我们实际线上将这个值调大到 100 ，观察到 CPU 会增加 2% 左右，但对冷数据的内存释放速度确实有明显的提高（通过观察 keyspace 个数和 used_memory 大小）。</p>
</blockquote>
<h3 id="Redis-有哪些数据结构？"><a href="#Redis-有哪些数据结构？" class="headerlink" title="Redis 有哪些数据结构？"></a>Redis 有哪些数据结构？</h3><p>如果你是 Redis 普通玩家，可能你的回答是如下五种数据结构：</p>
<ul>
<li>字符串 String</li>
<li>字典Hash</li>
<li>列表List</li>
<li>集合Set</li>
<li>有序集合 SortedSet</li>
</ul>
<p>如果你是 Redis 中级玩家，还需要加上下面几种数据结构：</p>
<ul>
<li>HyperLogLog</li>
<li>Geo</li>
<li>Bitmap</li>
</ul>
<p>如果你是 Redis 高端玩家，你可能玩过 Redis Module ，可以再加上下面几种数据结构：</p>
<ul>
<li>BloomFilter</li>
<li>RedisSearch</li>
<li>Redis-ML</li>
<li>JSON</li>
</ul>
<p>另外，在 Redis 5.0 增加了 Stream 功能，一个新的强大的支持多播的可持久化的消息队列，提供类似 Kafka 的功能。😈 默默跟面试官在装一波。</p>
<h3 id="聊聊-Redis-使用场景"><a href="#聊聊-Redis-使用场景" class="headerlink" title="聊聊 Redis 使用场景"></a>聊聊 Redis 使用场景</h3><p>Redis 可用的场景非常之多：</p>
<ul>
<li>数据缓存</li>
<li>会话缓存</li>
<li>时效性数据</li>
<li>访问频率</li>
<li>计数器</li>
<li>社交列表</li>
<li>记录用户判定信息</li>
<li>交集、并集和差集</li>
<li>热门列表与排行榜</li>
<li>最新动态</li>
<li>消息队列</li>
<li>分布式锁</li>
</ul>
<p>详细的介绍，可以看看如下文章：</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://blog.720ui.com/2017/redis_core_use/">《聊聊 Redis 使用场景》</a></li>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/af277c77b1c9">《Redis 应用场景及实例》</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/29665317">《Redis 常见的应用场景解析》</a></li>
<li><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/19829601">《Redis 和 Memcached 各有什么优缺点，主要的应用场景是什么样的？》</a></li>
</ul>
<h3 id="Redis-支持的-Java-客户端都有哪些？"><a href="#Redis-支持的-Java-客户端都有哪些？" class="headerlink" title="Redis 支持的 Java 客户端都有哪些？"></a>Redis 支持的 Java 客户端都有哪些？</h3><p>使用比较广泛的有三个 Java 客户端：</p>
<ul>
<li><p>Redisson</p>
<blockquote>
<p>Redisson ，是一个高级的分布式协调 Redis 客服端，能帮助用户在分布式环境中轻松实现一些 Java 的对象 (Bloom filter, BitSet, Set, SetMultimap, ScoredSortedSet, SortedSet, Map, ConcurrentMap, List, ListMultimap, Queue, BlockingQueue, Deque, BlockingDeque, Semaphore, Lock, ReadWriteLock, AtomicLong, CountDownLatch, Publish / Subscribe, HyperLogLog)。</p>
</blockquote>
</li>
<li><p>Jedis</p>
<blockquote>
<p>Jedis 是 Redis 的 Java 实现的客户端，其 API 提供了比较全面的 Redis 命令的支持。</p>
<p>Redisson 实现了分布式和可扩展的 Java 数据结构，和 Jedis 相比，Jedis 功能较为简单。</p>
<p>Redisson 的宗旨是促进使用者对 Redis 的关注分离，从而让使用者能够将精力更集中地放在处理业务逻辑上。</p>
</blockquote>
</li>
<li><p>Lettuce</p>
<blockquote>
<p>Lettuce 是一个可伸缩线程安全的 Redis 客户端。多个线程可以共享同一个 RedisConnection 。它利用优秀 Netty NIO 框架来高效地管理多个连接。</p>
</blockquote>
</li>
</ul>
<p>Redis 官方推荐使用 Redisson 或 Jedis 。</p>
<p>Spring Boot 2.x 内置支持 Jedis 和 Lettuce 。一般情况下，建议：</p>
<ul>
<li>使用 Spring Data Redis ，提供了透明使用 Jedis 和 Lettuce 的封装。也就是说，大多数时候，我们可以通过配置使用 Jedis 或 Lettuce 进行 Redis 的操作，而上层使用 Spring Data Redis 提供的统一 API 。</li>
<li>从目前来说，Jedis 会比 Lettuce 更加流行，并且更加稳定。虽然说 Jedis 有一段时间，不再进行更新，但是突然又开始更新，可能是诈尸了。</li>
<li>如果想要更加丰富的特性，例如说分布式锁，布隆过滤器，可以考虑研究下 Redisson 。</li>
</ul>
<h3 id="如何使用-Redis-实现分布式锁？"><a href="#如何使用-Redis-实现分布式锁？" class="headerlink" title="如何使用 Redis 实现分布式锁？"></a>如何使用 Redis 实现分布式锁？</h3><p>Redis 实现分布式锁，需要考虑如下几个方面：</p>
<ul>
<li><p>1、正确的获得锁</p>
<blockquote>
<p>set 指令附带 nx 参数，保证有且只有一个进程获得到。</p>
</blockquote>
</li>
<li><p>2、正确的释放锁</p>
<blockquote>
<p>使用 Lua 脚本，比对锁持有的是不是自己。如果是，则进行删除来释放。</p>
</blockquote>
</li>
<li><p>3、超时的自动释放锁</p>
<blockquote>
<p>set 指令附带 expire 参数，通过过期机制来实现超时释放。</p>
</blockquote>
</li>
<li><p>4、未获得到锁的等待机制</p>
<blockquote>
<p>sleep 或者基于 Redis 的订阅 Pub/Sub 机制。</p>
<p>一些业务场景，可能需要支持获得不到锁，直接返回 false ，不等待。</p>
</blockquote>
</li>
<li><p>5、【可选】锁的重入性</p>
<blockquote>
<p>通过 ThreadLocal 记录是第几次获得相同的锁。</p>
<p>1）有且第一次计数为 1 &amp;&amp; 获得锁时，才向 Redis 发起获得锁的操作。<br>2）有且计数为 0 &amp;&amp; 释放锁时，才向 Redis 发起释放锁的操作。</p>
</blockquote>
</li>
<li><p>6、锁超时的处理</p>
<blockquote>
<p>一般情况下，可以考虑告警 + 后台线程自动续锁的超时时间。通过这样的机制，保证有且仅有一个线程，正在持有锁。</p>
</blockquote>
</li>
<li><p>7、Redis 分布式锁丢失问题</p>
<blockquote>
<p>具体看「方案二：Redlock」。</p>
</blockquote>
</li>
</ul>
<p>下面，我们来详细说下每个方案。</p>
<p>🦅 <strong>方案一：set 指令</strong></p>
<p>先拿 setnx 来争抢锁，抢到之后，再用 expire 给锁加一个过期时间防止锁忘记了释放。</p>
<ul>
<li>这时候对方会告诉你说你回答得不错，然后接着问如果在 setnx 之后执行 expire 之前进程意外 crash 或者要重启维护了，那会怎么样？</li>
<li>这时候你要给予惊讶的反馈：唉，是喔，这个锁就永远得不到释放了。紧接着你需要抓一抓自己得脑袋，故作思考片刻，好像接下来的结果是你主动思考出来的，然后回答：我记得 set 指令有非常复杂的参数，这个应该是可以同时把 setnx 和 expire 合成一条指令来用的！对方这时会显露笑容，心里开始默念：摁，这小子还不错。</li>
</ul>
<p>所以，我们可以使用 <strong>set</strong> 指令，实现分布式锁。指令如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SET key value [EX seconds] [PX milliseconds] [NX|XX]</span><br></pre></td></tr></table></figure>

<ul>
<li>可以使用 <code>SET key value EX seconds NX</code> 命令，尝试获得锁。</li>
<li>具体的实现，可以参考如下文章：<ul>
<li><a target="_blank" rel="noopener" href="http://svip.iocoder.cn/Redisson/ReentrantLock/?self">《精尽 Redisson 源码分析 —— 可重入分布式锁 ReentrantLock》</a></li>
<li><a target="_blank" rel="noopener" href="http://www.iocoder.cn/Fight/redisfen-bu-shi-suo-jin-hua-shi/?self">《Redis 分布式锁进化史解读 + 缺陷分析》</a></li>
<li><a target="_blank" rel="noopener" href="http://www.iocoder.cn/Fight/Correct-implementation-of-Redis-distributed-locks-by-Java/?self">《Redis 分布式锁的正确实现方式（Java 版）》</a></li>
</ul>
</li>
</ul>
<p>🦅 <strong>方案二：Redlock</strong></p>
<p>set 指令的方案，适合用于在单机 Redis 节点的场景下，在多 Redis 节点的场景下，会存在分布式锁丢失的问题。所以，Redis 作者 Antirez 基于分布式环境下提出了一种更高级的分布式锁的实现方式：Redlock 。</p>
<p>具体的源码解析，可以看看 <a target="_blank" rel="noopener" href="http://svip.iocoder.cn/Redisson/RedLock/?self">《精尽 Redisson 源码分析 —— 可靠分布式锁 RedLock》</a> 文章。</p>
<p>具体的方案，胖友可以看看老友飞哥的两篇博客：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/JLEzNqQsx-Lec03eAsXFOQ">《Redlock：Redis分布式锁最牛逼的实现》</a></li>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/f302aa345ca8">《Redisson 实现 Redis 分布式锁的 N 种姿势》</a></li>
</ul>
<p>🦅 <strong>对比 Zookeeper 分布式锁</strong></p>
<ul>
<li>从可靠性上来说，Zookeeper 分布式锁好于 Redis 分布式锁。</li>
<li>从性能上来说，Redis 分布式锁好于 Zookeeper 分布式锁。</li>
</ul>
<p>所以，没有绝对的好坏，可以根据自己的业务来具体选择。如果想要更简单，甚至可以考虑基于 MySQL 行锁来实现分布式锁。</p>
<h3 id="如何使用-Redis-实现分布式限流？"><a href="#如何使用-Redis-实现分布式限流？" class="headerlink" title="如何使用 Redis 实现分布式限流？"></a>如何使用 Redis 实现分布式限流？</h3><p>在 Spring Cloud Gateway 中，提供了 Redis 分布式限流器的实现，具体直接看 <a target="_blank" rel="noopener" href="http://www.iocoder.cn/Spring-Cloud-Gateway/filter-request-rate-limiter/">《Spring-Cloud-Gateway 源码解析 —— 过滤器 (4.10) 之 RequestRateLimiterGatewayFilterFactory 请求限流》</a> 的 <a target="_blank" rel="noopener" href="http://svip.iocoder.cn/Redis/Interview/#">「5.3 Redis Lua 脚本」</a> 部分。</p>
<p>另外，Redisson 库中，也提供了 Redis 分布式限流的实现，不过需要使用 Pro 版本。</p>
<p>🦅 <strong>请用 Redis 和任意语言实现一段恶意登录保护的代码，限制 1 小时内每用户 Id 最多只能登录 5 次。</strong></p>
<p>这个问题，关键点，就是每个用户，每 3600 秒，只能登陆 5 次。这么一想，其实就是一个如何使用 Redis 实现限流的问题。Redis 实现限流，一共有两种方案：</p>
<ul>
<li><p>使用 zset 实现滑动窗口限流。代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isActionAllowed</span><span class="params">(String userId, String actionKey, <span class="keyword">int</span> period,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> maxCount)</span> </span>&#123;</span><br><span class="line">    String key = String.format(<span class="string">&quot;hist:%s:%s&quot;</span>, userId, actionKey); <span class="comment">// 使用用户编号 + 行为作为 KEY 。这样，我们就可以统计某个用户的操作行为。</span></span><br><span class="line">    <span class="keyword">long</span> nowTs = System.currentTimeMillis(); <span class="comment">// 获取当前时间。</span></span><br><span class="line">    Pipeline pipe = jedis.pipelined(); <span class="comment">// pipeline 批量操作，提升效率。</span></span><br><span class="line">    pipe.multi(); <span class="comment">// 此处启动了事务，可以保证指令的原子性。</span></span><br><span class="line">    pipe.zadd(key, nowTs, <span class="string">&quot;&quot;</span> + nowTs); <span class="comment">// zset 添加，key value score 要看下。</span></span><br><span class="line">    pipe.zremrangeByScore(key, <span class="number">0</span>, nowTs - (period * <span class="number">1000</span>)); <span class="comment">// zremrangeByScore ，移除超过周期的 value 。</span></span><br><span class="line"></span><br><span class="line">    Response&lt;Long&gt; count = pipe.zcard(key); <span class="comment">// zcard ，计算 zset 的数量</span></span><br><span class="line">    pipe.expire(key, period + <span class="number">1</span>); <span class="comment">// 设置过期。这里多 + 1 秒，为了防止网络延迟。</span></span><br><span class="line">    pipe.exec(); <span class="comment">// pipeline 执行</span></span><br><span class="line">    pipe.close();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> count.get() &lt;= maxCount; <span class="comment">// 是否超过最大次数。</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>该实现会存在一个问题，可能一个无效的操作，也被记录到次数中。完美的话，可能需要基于 Lua 脚本实现。</li>
<li>另外，上述代码是每秒操作的时间，实际需要改成每 N 秒。比较简单，直接上手怼即可。</li>
</ul>
</li>
<li><p>使用 Lua 脚本，实现令牌桶限流算法。具体可以看看艿艿对 <a target="_blank" rel="noopener" href="http://www.iocoder.cn/Spring-Cloud-Gateway/filter-request-rate-limiter/?self">《Spring-Cloud-Gateway 源码解析 —— 过滤器 (4.10) 之 RequestRateLimiterGatewayFilterFactory 请求限流》</a> 的源码解析。</p>
</li>
<li><p>使用 Lua 脚本，实现简单的滑动窗口。具体可以看看艿艿对 <a target="_blank" rel="noopener" href="http://svip.iocoder.cn/Redisson/RateLimiter/?self">《精尽 Redisson 源码分析 —— 限流器 RateLimiter》</a> 的源码解析。</p>
</li>
</ul>
<h3 id="如何使用-Redis-实现消息队列？"><a href="#如何使用-Redis-实现消息队列？" class="headerlink" title="如何使用 Redis 实现消息队列？"></a>如何使用 Redis 实现消息队列？</h3><p>一般使用 list 结构作为队列，rpush 生产消息，lpop 消费消息。当 lpop 没有消息的时候，要适当 sleep 一会再重试。</p>
<ul>
<li><p>如果对方追问可不可以不用 sleep 呢？list 还有个指令叫 blpop ，在没有消息的时候，它会阻塞住直到消息到来。</p>
</li>
<li><p>如果对方追问能不能生产一次消费多次呢？使用 pub / sub 主题订阅者模式，可以实现 1:N 的消息队列。</p>
</li>
<li><p>如果对方追问 pub / sub 有什么缺点？在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如 rabbitmq 等。</p>
<blockquote>
<p>之前生产中，艿艿就碰到因为网络闪断，导致订阅的 pub/sub 消息丢失，导致 JVM 应用的数据字典和系统参数等缓存未刷新，业务受到影响。所以，最好还是使用专业的消息队列的订阅功能（广播消费）。</p>
</blockquote>
</li>
<li><p>如果对方追问 redis 如何实现延时队列？我估计现在你很想把面试官一棒打死如果你手上有一根棒球棍的话，怎么问的这么详细。但是你很克制，然后神态自若的回答道：使用 sortedset ，拿时间戳作为 score ，消息内容作为 key 调用 zadd 来生产消息，消费者用 zrangebyscore 指令获取 N 秒之前的数据轮询进行处理。</p>
<blockquote>
<p>可能很多胖友会觉得抽象，可以看看 <a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1401122">《Redis 学习笔记之延时队列》</a> 。面试中，能回答到 Redis zset 实现延迟队列，还是蛮加分的。</p>
</blockquote>
</li>
</ul>
<p>到这里，面试官暗地里已经对你竖起了大拇指。但是他不知道的是此刻你却竖起了中指，在椅子背后。</p>
<p>当然，实际上 Redis 真的真的真的不推荐作为消息队列使用，它最多只是消息队列的存储层，上层的逻辑，还需要做大量的封装和支持。</p>
<p>另外，在 Redis 5.0 增加了 Stream 功能，一个新的强大的支持多播的可持久化的消息队列，提供类似 Kafka 的功能。</p>
<h3 id="什么是-Redis-Pipelining-？"><a href="#什么是-Redis-Pipelining-？" class="headerlink" title="什么是 Redis Pipelining ？"></a>什么是 Redis Pipelining ？</h3><p>一次请求/响应服务器能实现处理新的请求即使旧的请求还未被响应。这样就可以将多个命令发送到服务器，而不用等待回复，最后在一个步骤中读取该答复。</p>
<blockquote>
<p>注意，Redis Pipelining 是 Redis Client 实现的功能，而不是 Redis Server 提供的特性。假设我们有 3 个请求进行下举例子。</p>
<ul>
<li>未使用 Pipeline 时，那么整个执行的顺序是，req1-&gt;resp1-&gt;req2-&gt;resp2-&gt;req3-&gt;resp3 。</li>
<li>在使用 Pipeline 时，那么整个执行的顺序是，[req1,req2,req3] 一起发给 Redis Server ，而 Redis Server 收到请求后，一个一个请求进行执行，然后响应，不会进行什么特殊处理。而 Client 在收到 resp1,resp2,resp3 后，进行响应给业务上层。</li>
</ul>
<p>所以，Pipeline 的作用，是避免每发一个请求，就阻塞等待这个请求的结果。</p>
</blockquote>
<p>这就是管道（pipelining），是一种几十年来广泛使用的技术。例如许多 POP3 协议已经实现支持这个功能，大大加快了从服务器下载新邮件的过程。</p>
<p>Redis 很早就支持管道（<a target="_blank" rel="noopener" href="http://redis.cn/topics/pipelining.html">pipelining</a>）技术，因此无论你运行的是什么版本，你都可以使用管道（pipelining）操作 Redis。</p>
<p>🦅 <strong>Redis 如何做大量数据插入？</strong></p>
<p>Redis 2.6 开始，Redis-cli 支持一种新的被称之为 pipe mode 的新模式用于执行大量数据插入工作。</p>
<p>具体可见 <a target="_blank" rel="noopener" href="http://www.redis.cn/topics/mass-insert.html">《Redis 大量数据插入》</a> 文章。</p>
<h3 id="什么是-Redis-事务？"><a href="#什么是-Redis-事务？" class="headerlink" title="什么是 Redis 事务？"></a>什么是 Redis 事务？</h3><p>和众多其它数据库一样，Redis 作为 NoSQL 数据库也同样提供了事务机制。在 Redis 中，MULTI / EXEC / DISCARD / WATCH 这四个命令是我们实现事务的基石。相信对有关系型数据库开发经验的开发者而言这一概念并不陌生，即便如此，我们还是会简要的列出 Redis 中事务的实现特征：</p>
<ul>
<li><p>1、在事务中的所有命令都将会被串行化的顺序执行，事务执行期间，Redis 不会再为其它客户端的请求提供任何服务，从而保证了事物中的所有命令被原子的执行。</p>
<blockquote>
<p>Lua 脚本，也能实现该功能。</p>
</blockquote>
</li>
<li><p>2、和关系型数据库中的事务相比，在 Redis 事务中如果有某一条命令执行失败，其后的命令仍然会被继续执行。</p>
<blockquote>
<p>这一点，非常重要。回答错了，就回家面壁思过，一天不许喝可乐。</p>
<p>这一点，是 Lua 脚本不具备的。</p>
</blockquote>
</li>
<li><p>3、我们可以通过 MULTI 命令开启一个事务，有关系型数据库开发经验的人可以将其理解为 <code>&quot;BEGIN TRANSACTION&quot;</code> 语句。在该语句之后执行的命令，都将被视为事务之内的操作，最后我们可以通过执行 EXEC / DISCARD 命令来提交 / 回滚该事务内的所有操作。这两个 Redis 命令，可被视为等同于关系型数据库中的 COMMIT / ROLLBACK 语句。</p>
<blockquote>
<p>开启事务后，所有语句，发送给 Redis Server ，都会暂存在 Server 中。</p>
</blockquote>
</li>
<li><p>4、在事务开启之前，如果客户端与服务器之间出现通讯故障并导致网络断开，其后所有待执行的语句都将不会被服务器执行。然而如果网络中断事件是发生在客户端执行 EXEC 命令之后，那么该事务中的所有命令都会被服务器执行。</p>
</li>
</ul>
<p>🦅 <strong>如何实现 Redis CAS 操作？</strong></p>
<p>在 Redis 的事务中，WATCH 命令可用于提供 CAS(check-and-set) 功能。</p>
<p>假设我们通过 WATCH 命令在事务执行之前监控了多个 keys ，倘若在 WATCH 之后有任何 Key 的值发生了变化，EXEC 命令执行的事务都将被放弃，同时返回 <code>nil</code> 应答以通知调用者事务执行失败。</p>
<p>具体的示例，可以看看 <a target="_blank" rel="noopener" href="https://www.jianshu.com/p/0244a875aa26">《Redis 事务锁 CAS 实现以及深入误区》</a> 。</p>
<h3 id="Redis-集群都有哪些方案？"><a href="#Redis-集群都有哪些方案？" class="headerlink" title="Redis 集群都有哪些方案？"></a>Redis 集群都有哪些方案？</h3><p>Redis 集群方案如下：</p>
<ul>
<li>1、Redis Sentinel</li>
<li>2、Redis Cluster</li>
<li>3、Twemproxy</li>
<li>4、Codis</li>
<li>5、客户端分片</li>
</ul>
<p>关于前四种，可以看看 <a target="_blank" rel="noopener" href="http://blog.720ui.com/2016/redis_action_04_cluster/">《Redis 实战（四）集群机制》</a> 这篇文章。</p>
<p>关于最后一种，客户端分片，在 Redis Cluster 出现之前使用较多，目前已经使用比较少了。实现方式如下：</p>
<blockquote>
<p>在业务代码层实现，起几个毫无关联的 Redis 实例，在代码层，对 Key 进行 hash 计算，然后去对应的 Redis 实例操作数据。</p>
<p>这种方式对 hash 层代码要求比较高，考虑部分包括，节点失效后的替代算法方案，数据震荡后的自动脚本恢复，实例的监控，等等。</p>
</blockquote>
<p>🦅 <strong>选择</strong></p>
<p>目前一般在选型上来说：</p>
<ul>
<li><p>体量较小时，选择 Redis Sentinel ，单主 Redis 足以支撑业务。</p>
</li>
<li><p>体量较大时，选择 Redis Cluster ，通过分片，使用更多内存。</p>
<blockquote>
<p>关于这个问题，多大体量需要使用 Redis Cluster 呢？朋友的建议是 10G+ 的时候。主要原因是：</p>
<ul>
<li>1、一次 RDB 时间随着内存越大，会变大越来越久。同时，一次 fork 的时间也会变久。还有，重启通过 RDB 文件，或者 AOF 日志，恢复时间都会变长。</li>
<li>2、体量大之后，读写的 QPS 势必比体量小的时候打的多，那么使用 Redis Cluster 相比 Redis Sentinel ，可以分散读写压力到不同的集群中。</li>
</ul>
</blockquote>
</li>
</ul>
<p>🦅 <strong>Redis 集群如何扩容？</strong></p>
<ul>
<li><p><del>如果 Redis 被当做<strong>缓存</strong>使用，使用一致性哈希实现动态扩容缩容。</del></p>
<blockquote>
<p>删除的原因是，不考虑客户端分片的情况，目前基本已经不在用了。</p>
</blockquote>
</li>
<li><p>如果 Redis 被当做一个<strong>持久化存</strong>储使用，必须使用固定的 keys-to-nodes 映射关系，节点的数量一旦确定不能变化。否则的话(即 Redis 节点需要动态变化的情况），必须使用可以在运行时进行数据再平衡的一套系统，而当前只有 Redis Cluster、Codis 可以做到这样。</p>
</li>
</ul>
<p>如果是 Redis Cluster 集群的扩容，可以看看 <a target="_blank" rel="noopener" href="https://u.jd.com/lDNJa9">《Redis 开发与运维》</a> 的「10.4 集群 —— 集群伸缩」小节。简单来说，一共三步：</p>
<ul>
<li>1、准备新节点。</li>
<li>2、加入集群。</li>
<li>3、迁移槽和数据。</li>
</ul>
<h3 id="什么是-Redis-主从同步？"><a href="#什么是-Redis-主从同步？" class="headerlink" title="什么是 Redis 主从同步？"></a>什么是 Redis 主从同步？</h3><p><strong>Redis 主从同步</strong></p>
<p>Redis 的主从同步(replication)机制，允许 Slave 从 Master 那里，通过网络传输拷贝到完整的数据备份，从而达到主从机制。</p>
<ul>
<li>主数据库可以进行读写操作，当发生写操作的时候自动将数据同步到从数据库，而从数据库一般是只读的，并接收主数据库同步过来的数据。</li>
<li>一个主数据库可以有多个从数据库，而一个从数据库只能有一个主数据库。</li>
<li>第一次同步时，主节点做一次 bgsave 操作，并同时将后续修改操作记录到内存 buffer ，待完成后将 RDB 文件全量同步到复制节点，复制节点接受完成后将 RDB 镜像加载到内存。加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放就完成了同步过程。</li>
</ul>
<p><strong>好处</strong></p>
<p>通过 Redis 的复制功，能可以很好的实现数据库的读写分离，提高服务器的负载能力。主数据库主要进行写操作，而从数据库负责读操作。</p>
<blockquote>
<p>实际上，我们不是非常推荐在 Redis 中，使用读写分离。主要有两个原因：</p>
<ul>
<li>Redis Sentinel 只保证主节点的故障的失效转移，而例如说 Jedis 库，也只监听了主节点的变化，但是从节点故障的情况，Jedis 是不进行处理的。这就会导致，Jedis 读会访问到从节点，导致问题。当然，Redisson 库的功能比较强大，已经支持从节点的故障监听。</li>
<li>如果到达需要读写分离的体量，一般写操作也不一定会少，可以考虑上 Redis Cluster 方案，更加可靠。</li>
</ul>
</blockquote>
<hr>
<p>Redis 主从同步，是很多 Redis 集群方案的基础，例如 Redis Sentinel、Redis Cluster 等等。</p>
<p>更多详细，可以看看如下：</p>
<blockquote>
<p>因为主从复制的内容很多，艿艿这里就不详细哔哔了。实际场景下，对于开发的面试，我们也不会特别问，毕竟更偏运维的内容。</p>
</blockquote>
<ul>
<li><a target="_blank" rel="noopener" href="http://redis.cn/topics/replication.html">《Redis 官方文档 —— 复制》</a></li>
<li><a target="_blank" rel="noopener" href="https://u.jd.com/lDNJa9">《Redis 开发与运维》</a> 的「6. 复制」章节，更加详细完整。</li>
</ul>
<h3 id="如何使用-Redis-Sentinel-实现高可用？"><a href="#如何使用-Redis-Sentinel-实现高可用？" class="headerlink" title="如何使用 Redis Sentinel 实现高可用？"></a>如何使用 Redis Sentinel 实现高可用？</h3><p>详细，可以看看如下：</p>
<blockquote>
<p>因为 Redis Sentinel 的内容很多，这里就不详细哔哔了。实际场景下，对于开发的面试，我们也不会特别问，毕竟更偏运维的内容。</p>
</blockquote>
<ul>
<li><a target="_blank" rel="noopener" href="http://redis.cn/topics/sentinel.html">《Redis 官方文档 —— Sentinel 高可用》</a></li>
<li><a target="_blank" rel="noopener" href="https://u.jd.com/lDNJa9">《Redis 开发与运维》</a> 的「9. 哨兵」章节，更加详细完整。</li>
</ul>
<h3 id="如果使用-Redis-Cluster-实现高可用？"><a href="#如果使用-Redis-Cluster-实现高可用？" class="headerlink" title="如果使用 Redis Cluster 实现高可用？"></a>如果使用 Redis Cluster 实现高可用？</h3><p>详细，可以看看如下：</p>
<blockquote>
<p>因为 Redis Sentinel 的内容很多，艿艿这里就不详细哔哔了。实际场景下，对于开发的面试，我们也不会特别问，毕竟更偏运维的内容。</p>
</blockquote>
<ul>
<li><a target="_blank" rel="noopener" href="http://redis.cn/topics/cluster-tutorial.html">《Redis 官方文档 —— Redis Cluster 集群》</a></li>
<li><a target="_blank" rel="noopener" href="https://u.jd.com/lDNJa9">《Redis 开发与运维》</a> 的「10. 集群」章节，更加详细完整。</li>
</ul>
<p>🦅 <strong>说说 Redis 哈希槽的概念？</strong></p>
<p>Redis Cluster 没有使用一致性 hash ，而是引入了哈希槽的概念。</p>
<p>Redis 集群有 16384 个哈希槽，每个 key 通过 CRC16 校验后对 16384 取模来决定放置哪个槽，集群的每个节点负责一部分 hash 槽。</p>
<p>因为最大是 16384 个哈希槽，所以考虑 Redis 集群中的每个节点都能分配到一个哈希槽，所以最多支持 16384 个 Redis 节点。</p>
<p>为什么是 16384 呢？主要考虑集群内的网络带宽，而 16384 刚好是 2K 字节大小。</p>
<p>🦅 <strong>Redis Cluster 的主从复制模型是怎样的？</strong></p>
<p>为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了<strong>主从复制</strong>模型，每个节点都会有 N-1 个复制节点。</p>
<p>所以，Redis Cluster 可以说是 Redis Sentinel 带分片的加强版。也可以说：</p>
<ul>
<li>Redis Sentinel 着眼于高可用，在 master 宕机时会自动将 slave 提升为 master ，继续提供服务。</li>
<li>Redis Cluster 着眼于扩展性，在单个 Redis 内存不足时，使用 Cluster 进行分片存储。</li>
</ul>
<p>🦅 <strong>Redis Cluster 方案什么情况下会导致整个集群不可用？</strong></p>
<p>有 A，B，C 三个节点的集群，在没有复制模型的情况下，如果节点 B 宕机了，那么整个集群就会以为缺少 5501-11000 这个范围的槽而不可用。当然，这种情况也可以配置 <code>cluster-require-full-coverage=no</code> ，整个集群无需所有槽位覆盖。</p>
<p>🦅 <strong>Redis Cluster 会有写操作丢失吗？为什么？</strong></p>
<p>Redis 并不能保证数据的强一致性，而是【异步复制】，这意味这在实际中集群在特定的条件下可能会丢失写操作。</p>
<blockquote>
<p>一定要注意，无论对于 Redis Sentinel 还是 Redis Cluster 方案，都是通过主从复制，所以在数据的复制方面，都存在相同的情况。</p>
</blockquote>
<p>🦅 <strong>Redis 集群如何选择数据库？</strong></p>
<p>Redis 集群目前无法做数据库选择，默认在 0 数据库。</p>
<p>🦅 <strong>请说说生产环境中的 Redis 是怎么部署的？</strong></p>
<blockquote>
<p>重点问题，仔细理解。</p>
</blockquote>
<ul>
<li><p>Redis Cluster ，10 台机器，5 台机器部署了 Redis 主实例，另外 5 台机器部署了 Redis 的从实例，每个主实例挂了一个从实例，5 个节点对外提供读写服务，每个节点的读写高峰 qps 可能可以达到每秒 5 万，5 台机器最多是 25 万读写请求每秒。</p>
</li>
<li><p>机器是什么配置？32G 内存 + 8 核 CPU + 1T 磁盘，但是分配给 Redis 进程的是 10G 内存，一般线上生产环境，Redis 的内存尽量不要超过 10G，超过 10G 可能会有问题。那么，5 台机器对外提供读写，一共有 50G 内存。</p>
</li>
<li><p>因为每个主实例都挂了一个从实例，所以是高可用的，任何一个主实例宕机，都会自动故障迁移，Redis 从实例会自动变成主实例继续提供读写服务。</p>
</li>
<li><p>你往内存里写的是什么数据？每条数据的大小是多少？商品数据，每条数据是 10kb 。100 条数据是 1mb ，10 万条数据是 1G 。常驻内存的是 200 万条商品数据，占用内存是 20G ，仅仅不到总内存的 50% 。目前高峰期每秒就是 3500 左右的请求量。</p>
<blockquote>
<p>一般来说，当公司体量大了之后，建议是一个业务线独占一个或多个 Redis Cluster 集群，实现好业务线与业务线之间的隔离。</p>
</blockquote>
</li>
<li><p>其实大型的公司，会有基础架构的 Team 负责缓存集群的运维。</p>
</li>
</ul>
<h3 id="什么是-Redis-分区？"><a href="#什么是-Redis-分区？" class="headerlink" title="什么是 Redis 分区？"></a>什么是 Redis 分区？</h3><blockquote>
<p>这个问题，和 <a target="_blank" rel="noopener" href="http://svip.iocoder.cn/Redis/Interview/#">「Redis 集群都有哪些方案？」</a> 是同类问题。</p>
<p>简单看看即可，重点还是去理解 Redis Cluster 集群方案。</p>
</blockquote>
<p>🦅 关于如下四个问题，直接看 <a target="_blank" rel="noopener" href="http://www.runoob.com/redis/redis-partitioning.html">《Redis 分区》</a> 文章。</p>
<ul>
<li>Redis 分区是什么？</li>
<li>分区的优势？</li>
<li>分区的不足？</li>
<li>分区类型？</li>
</ul>
<p>可能有人会懵逼，又是 Redis 主从复制，又是 Redis 分区，又是 Redis 集群。傻傻分不清啊！</p>
<ul>
<li><p>Redis 分区是一种模式，将数据分区到不同的 Redis 节点上，而 Redis 集群的 Redis Cluster、Twemproxy、Codis、客户端分片( 不包括 Redis Sentinel ) 这四种方案，是 Redis 分区的具体实现。</p>
<blockquote>
<p>注意，Redis Sentinel 实现的是 Redis 的高可用，一定要分清楚。实际上，胖友可以对比 MySQL 和 MongoDB 的高可用、集群的方案，发现思路都是一致的。</p>
</blockquote>
</li>
<li><p>Redis 每个分区，如果想要实现高可用，需要使用到 Redis 主从复制。</p>
</li>
</ul>
<p>🦅 <strong>你知道有哪些 Redis 分区实现方案</strong>？</p>
<p>Redis 分区方案，主要分成两种类型：</p>
<ul>
<li>客户端分区，就是在客户端就已经决定数据会被存储到哪个 Redis 节点或者从哪个 Redis 节点读取。大多数客户端已经实现了客户端分区。<ul>
<li>案例：Redis Cluster 和客户端分区。</li>
</ul>
</li>
<li>代理分区，意味着客户端将请求发送给代理，然后代理决定去哪个节点写数据或者读数据。代理根据分区规则决定请求哪些 Redis 实例，然后根据 Redis 的响应结果返回给客户端。<ul>
<li>案例：Twemproxy 和 Codis 。</li>
</ul>
</li>
</ul>
<p>查询路由(Query routing)的意思，是客户端随机地请求任意一个 Redis 实例，然后由 Redis 将请求转发给正确的 Redis 节点。Redis Cluster 实现了一种混合形式的查询路由，但并不是直接将请求从一个Redis 节点转发到另一个 Redis 节点，而是在客户端的帮助下直接 Redirect 到正确的 Redis 节点。</p>
<blockquote>
<p>Redis Cluster 的重定向，可以认真看看 <a target="_blank" rel="noopener" href="https://u.jd.com/lDNJa9">《Redis 开发与运维》</a> 的「10.5 集群 - 请求路由」章节。</p>
</blockquote>
<p>🦅 <strong>分布式 Redis 是前期做还是后期规模上来了再做好？为什么？？</strong></p>
<p>如下是网络上的一个答案：</p>
<blockquote>
<p>既然 Redis 是如此的轻量，为防止以后的扩容，最好的办法就是一开始就启动较多实例。即便你只有一台服务器，你也可以一开始就让 Redis 以分布式的方式运行，使用分区，在同一台服务器上启动多个实例。</p>
<p>一开始就多设置几个 Redis 实例，例如 32 或者 64 个实例，对大多数用户来说这操作起来可能比较麻烦，但是从长久来看做这点牺牲是值得的。</p>
<p>这样的话，当你的数据不断增长，需要更多的 Redis 服务器时，你需要做的就是仅仅将 Redis 实例从一台服务迁移到另外一台服务器而已（而不用考虑重新分区的问题）。一旦你添加了另一台服务器，你需要将你一半的 Redis 实例从第一台机器迁移到第二台机器。</p>
</blockquote>
<ul>
<li>和飞哥沟通了下，这个操作不是很合理。</li>
<li>无论怎么说，建议，需要搭建下 Redis Sentinel 高可用，至于拓展性，根据自己的情况，是否使用 Redis Cluster 集群。同时， Redis Cluster 集群会有运维的复杂性，同时会存在跨分片操作（例如说 mget 等等）、事务等操作是不支持的。</li>
</ul>
<h3 id="Redis-有哪些重要的健康指标？"><a href="#Redis-有哪些重要的健康指标？" class="headerlink" title="Redis 有哪些重要的健康指标？"></a>Redis 有哪些重要的健康指标？</h3><p>推荐阅读 <a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/D_khsApGkRckEoV75pYpDA">《Redis 几个重要的健康指标》</a></p>
<ul>
<li>存活情况</li>
<li>连接数</li>
<li>阻塞客户端数量</li>
<li>使用内存峰值</li>
<li>内存碎片率</li>
<li>缓存命中率</li>
<li>OPS</li>
<li>持久化</li>
<li>失效KEY</li>
<li>慢日志</li>
</ul>
<p><strong>如何提高 Redis 命中率？</strong></p>
<p>推荐阅读 <a target="_blank" rel="noopener" href="http://www.cnblogs.com/shamo89/p/8383915.html">《如何提高缓存命中率（Redis）》</a> 。</p>
<h3 id="怎么优化-Redis-的内存占用？"><a href="#怎么优化-Redis-的内存占用？" class="headerlink" title="怎么优化 Redis 的内存占用？"></a>怎么优化 Redis 的内存占用？</h3><p>推荐阅读 <a target="_blank" rel="noopener" href="https://www.jianshu.com/p/8677603d3865">《Redis 的内存优化》</a></p>
<ul>
<li>redisObject 对象</li>
<li>缩减键值对象</li>
<li>共享对象池</li>
<li>字符串优化</li>
<li>编码优化</li>
<li>控制 key 的数量</li>
</ul>
<p>🦅 <strong>一个 Redis 实例最多能存放多少的 keys？List、Set、Sorted Set 他们最多能存放多少元素？</strong></p>
<p>一个 Redis 实例，最多能存放多少的 keys ，List、Set、Sorted Set 他们最多能存放多少元素。</p>
<p>理论上，Redis 可以处理多达 2^32 的 keys ，并且在实际中进行了测试，每个实例至少存放了 2 亿 5 千万的 keys。</p>
<p>任何 list、set、和 sorted set 都可以放 2^32 个元素。</p>
<p>🦅 <strong>假如 Redis 里面有 1 亿个 key，其中有 10w 个 key 是以某个固定的已知的前缀开头的，如果将它们全部找出来？</strong></p>
<p>使用 <code>keys</code> 指令可以扫出指定模式的 key 列表。</p>
<ul>
<li>对方接着追问：如果这个 Redis 正在给线上的业务提供服务，那使用 <code>keys</code> 指令会有什么问题？</li>
<li>这个时候你要回答 Redis 关键的一个特性：Redis 的单线程的。<code>keys</code> 指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用 <code>scan</code> 指令，<code>scan</code> 指令可以无阻塞的提取出指定模式的 key 列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用 <code>keys</code> 指令长。</li>
</ul>
<h3 id="Redis-常见的性能问题都有哪些？如何解决？"><a href="#Redis-常见的性能问题都有哪些？如何解决？" class="headerlink" title="Redis 常见的性能问题都有哪些？如何解决？"></a>Redis 常见的性能问题都有哪些？如何解决？</h3><ul>
<li><p>1、<strong>Master 最好不要做任何持久化工作，如 RDB 内存快照和 AOF 日志文件</strong>。</p>
<blockquote>
<p>经过和朋友讨论，主节点开启 AOF 日志功能，尽量避免 AOF 重写。</p>
</blockquote>
<ul>
<li>Master 写内存快照，save 命令调度 rdbSave 函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以 Master 最好不要写内存快照。</li>
<li>Master AOF 持久化，如果不重写 AOF 文件，这个持久化方式对性能的影响是最小的，但是 AOF 文件会不断增大，AOF 文件过大会影响 Master 重启的恢复速度。</li>
<li>所以，Master 最好不要做任何持久化工作，包括内存快照和 AOF 日志文件，特别是不要启用内存快照做持久化。如果数据比较关键，某个 Slave 开启AOF备份数据，策略为每秒同步一次。</li>
</ul>
</li>
<li><p>2、Master 调用 BGREWRITEAOF 重写 AOF 文件，AOF 在重写的时候会占大量的 CPU 和内存资源，导致服务 load 过高，出现短暂服务暂停现象。</p>
<ul>
<li>一般来说，出现这个问题，很多时候是因为 Master 的内存过大，一次 AOF 重写需要占用的 CPU 和内存的资源较多，此时可以考虑 Redis Cluster 方案。</li>
</ul>
</li>
<li><p>3、尽量避免在压力很大的主库上增加过多的从库。</p>
<ul>
<li>可以考虑在从上挂载其它的从。</li>
</ul>
</li>
<li><p>4、主从复制不要用图状结构，用单向链表结构更为稳定，即：<code>Master &lt;- Slave1 &lt;- Slave2 &lt;- Slave3...</code> 。</p>
<ul>
<li><p>这样的结构，也方便解决单点故障问题，实现 Slave 对 Master 的替换。如果 Master挂了，可以立刻启用 Slave1 做 Master ，其他不变。</p>
<blockquote>
<p>从节点在切换主节点作为复制源的时候，会重新发起全量复制。所以此处通过 Slave1 挂在 Slave 下，可以规避这个问题。同时，也减少了 Master 的复制压力。当然，坏处就是 Slave1 的延迟可能会高一些些，所以还是需要取舍。</p>
</blockquote>
</li>
</ul>
</li>
<li><p>5、Redis 主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave 和 Master 最好在同一个局域网内。</p>
</li>
</ul>
<hr>
<p>有的公司，主节点开启 AOF ，从节点开启 AOF + RDB 。</p>
<p>有的公司，他们主节点开启 AOF ，从节点开启 RDB 居多，也有开启 AOF + RDB 的。</p>
<h3 id="修改配置不重启-Redis-会实时生效吗？"><a href="#修改配置不重启-Redis-会实时生效吗？" class="headerlink" title="修改配置不重启 Redis 会实时生效吗？"></a>修改配置不重启 Redis 会实时生效吗？</h3><p>针对运行实例，有许多配置选项可以通过 <code>CONFIG SET</code> 命令进行修改，而无需执行任何形式的重启。</p>
<p>从 Redis 2.2 开始，可以从 AOF 切换到 RDB 的快照持久性或其他方式而不需要重启 Redis。检索 <code>CONFIG GET *</code> 命令获取更多信息。</p>
<p>但偶尔重新启动是必须的，如为升级 Redis 程序到新的版本，或者当你需要修改某些目前 CONFIG 命令还不支持的配置参数的时候。</p>
<h3 id="其他问题"><a href="#其他问题" class="headerlink" title="其他问题"></a>其他问题</h3><p>有些比较凶残的面试官，可能会问我们一些 Redis 数据结构的问题，例如：</p>
<ul>
<li><p>Skiplist 插入和查询原理？</p>
</li>
<li><p>压缩列表的原理？</p>
</li>
<li><p>Redis 底层为什么使用跳跃表而不是红黑树？</p>
<blockquote>
<p>跳跃表在范围查找的时候性能比较高。</p>
</blockquote>
</li>
</ul>
<p>想要了解这块，需要花一定的时间去撸一撸源码，推荐可以看如下两块内容：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://juejin.im/book/5afc2e5f6fb9a07a9b362527?referrer=5904c637b123db3ee479d923">《Redis 深度历险：核心原理与应用实践》</a></li>
<li><a target="_blank" rel="noopener" href="https://u.jd.com/Fl5NTt">《Redis 设计与实现》</a></li>
</ul>
<p>推荐先读第一本，可以深入浅出的了解 Redis 原理和源码。然后在读第二本，硬核了解 Redis 的设计与实现（源码）。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fatefrank.github.io/2020/08/10/%E7%B2%BE%E5%B0%BD%20MySQL%20%E9%9D%A2%E8%AF%95%E9%A2%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Seif Zheng">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Seif Zheng's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/10/%E7%B2%BE%E5%B0%BD%20MySQL%20%E9%9D%A2%E8%AF%95%E9%A2%98/" class="post-title-link" itemprop="url">Mysql 面试题</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-08-10 00:00:00 / 修改时间：11:55:16" itemprop="dateCreated datePublished" datetime="2020-08-10T00:00:00+08:00">2020-08-10</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>MySQL 涉及的内容非常非常非常多，所以面试题也容易写的杂乱。当年，我们记着几个一定要掌握的重心：</p>
<blockquote>
<p>重点的题目，已经在标题前，添加了【重点】前缀。</p>
</blockquote>
<ol>
<li>索引。</li>
<li>锁。</li>
<li>事务和隔离级别。</li>
</ol>
<p>因为 MySQL 还会有部分内容和运维相关度比较高，所以本文我们分成两部分【开发】【运维】两部分。</p>
<ul>
<li>对于【开发】部分，我们需要掌握。</li>
<li>对于【运维】部分，更多考验开发的知识储备情况，当然能回答出来是比较好的，特别是对于高级开发工程师、架构师等。</li>
</ul>
<h2 id="开发"><a href="#开发" class="headerlink" title="开发"></a>开发</h2><h3 id="数据库的三范式是什么？什么是反模式？"><a href="#数据库的三范式是什么？什么是反模式？" class="headerlink" title="数据库的三范式是什么？什么是反模式？"></a>数据库的三范式是什么？什么是反模式？</h3><blockquote>
<p>重点在于反模式的回答。实际开发中，不会严格遵守三范式。</p>
</blockquote>
<p>数据库范式是为解决关系数据库中数据冗余、更新异常、插入异常、删除异常问题而引入的。简单的理解，数据库范式可以避免数据冗余，减少数据库的空间，并且减轻维护数据完整性的麻烦。</p>
<p><strong>第一范式（1NF）</strong></p>
<p>第一范式，强调属性的原子性约束，要求属性具有原子性，不可再分解。</p>
<p>举个例子，活动表（活动编码，活动名称，活动地址），假设这个场景中，活动地址可以细分为国家、省份、城市、市区、位置，那么就没有达到第一范式。</p>
<p><strong>第二范式（2NF）</strong></p>
<p>第二范式，强调记录的唯一性约束，表必须有一个主键，并且没有包含在主键中的列必须完全依赖于主键，而不能只依赖于主键的一部分。</p>
<p>举个例子，版本表（版本编码，版本名称，产品编码，产品名称），其中主键是（版本编码，产品编码），这个场景中，数据库设计并不符合第二范式，因为产品名称只依赖于产品编码。存在部分依赖。所以，为了使其满足第二范式，可以改造成两个表：版本表（版本编码，产品编码）和产品表（产品编码，产品名称）。</p>
<p><strong>第三范式（3NF）</strong></p>
<p>第三范式，强调属性冗余性的约束，即非主键列必须直接依赖于主键。</p>
<p>举个例子，订单表（订单编码，顾客编码，顾客名称），其中主键是（订单编码），这个场景中，顾客编码、顾客名称都完全依赖于主键，因此符合第二范式，但是顾客名称依赖于顾客编码，从而间接依赖于主键，所以不能满足第三范式。为了使其满足第三范式，可以拆分两个表：订单表（订单编码，顾客编码）和顾客表（顾客编码，顾客名称），拆分后的数据库设计，就可以完全满足第三范式的要求了。</p>
<p>值得注意的是，第二范式的侧重点是非主键列是否完全依赖于主键，还是依赖于主键的一部分。第三范式的侧重点是非主键列是直接依赖于主键，还是直接依赖于非主键列。</p>
<p><strong>反模式</strong></p>
<p>范式可以避免数据冗余，减少数据库的空间，减轻维护数据完整性的麻烦。</p>
<p>然而，通过数据库范式化设计，将导致数据库业务涉及的表变多，并且可能需要将涉及的业务表进行多表连接查询，这样将导致性能变差，且不利于分库分表。因此，出于性能优先的考量，可能在数据库的结构中需要使用反模式的设计，即空间换取时间，采取数据冗余的方式避免表之间的关联查询。至于数据一致性问题，因为难以满足数据强一致性，一般情况下，使存储数据尽可能达到用户一致，保证系统经过一段较短的时间的自我恢复和修正，数据最终达到一致。</p>
<p>需要谨慎使用反模式设计数据库。一般情况下，尽可能使用范式化的数据库设计，因为范式化的数据库设计能让产品更加灵活，并且能在数据库层保持数据完整性。</p>
<p>有的时候，提升性能最好的方法是在同一表中保存冗余数据，如果能容许少量的脏数据，创建一张完全独立的汇总表或缓存表是非常好的方法。举个例子，设计一张“下载次数表”来缓存下载次数信息，可使在海量数据的情况下，提高查询总数信息的速度。</p>
<p>另外一个比较典型的场景，出于扩展性考虑，可能会使用 BLOB 和 TEXT 类型的列存储 JSON 结构的数据，这样的好处在于可以在任何时候，将新的属性添加到这个字段中，而不需要更改表结构。但是，这个设计的缺点也比较明显，就是需要获取整个字段内容进行解码来获取指定的属性，并且无法进行索引、排序、聚合等操作。因此，如果需要考虑更加复杂的使用场景，更加建议使用 MongoDB 这样的文档型数据库。</p>
<h3 id="MySQL-有哪些数据类型？"><a href="#MySQL-有哪些数据类型？" class="headerlink" title="MySQL 有哪些数据类型？"></a>MySQL 有哪些数据类型？</h3><p>MySQL 支持多种类型，大致可以分为三类：数值、日期/时间和字符串(字符)类型。具体可以看看 <a target="_blank" rel="noopener" href="http://www.runoob.com/mysql/mysql-data-types.html">《MySQL 数据类型》</a> 文档。</p>
<ul>
<li>正确的使用数据类型，对数据库的优化是非常重要的。</li>
</ul>
<p>🦅 <strong>MySQL 中 varchar 与 char 的区别？varchar(50) 中的 50 代表的涵义？</strong></p>
<ul>
<li><p>1、varchar 与 char 的区别，char 是一种固定长度的类型，varchar 则是一种可变长度的类型。</p>
</li>
<li><p>2、varchar(50) 中 50 的涵义最多存放 50 个字符。varchar(50) 和 (200) 存储 hello 所占空间一样，</p>
<p>但后者在排序时会消耗更多内存，因为 <code>ORDER BY col</code> 采用 fixed_length 计算 col 长度(memory引擎也一样)</p>
<p>。</p>
<blockquote>
<p>所以，实际场景下，选择合适的 varchar 长度还是有必要的。</p>
</blockquote>
</li>
</ul>
<p>🦅 <strong>int(11) 中的 11 代表什么涵义？</strong></p>
<p>int(11) 中的 11 ，不影响字段存储的范围，只影响展示效果。具体可以看看 <a target="_blank" rel="noopener" href="https://blog.csdn.net/qmhball/article/details/51544484">《MySQL 中 int 长度的意义》</a> 文章。</p>
<p>🦅 <strong>金额(金钱)相关的数据，选择什么数据类型？</strong></p>
<ul>
<li>方式一，使用 int 或者 bigint 类型。如果需要存储到分的维度，需要 *100 进行放大。</li>
<li>方式二，使用 decimal 类型，避免精度丢失。如果使用 Java 语言时，需要使用 BigDecimal 进行对应。</li>
</ul>
<p>🦅 <strong>一张表，里面有 ID 自增主键，当 insert 了 17 条记录之后，删除了第 15,16,17 条记录，再把 MySQL 重启，再 insert 一条记录，这条记录的 ID 是 18 还是 15？</strong></p>
<ul>
<li>一般情况下，我们创建的表的类型是 InnoDB ，如果新增一条记录（不重启 MySQL 的情况下），这条记录的 ID 是18 ；但是如果重启 MySQL 的话，这条记录的 ID 是 15 。因为 InnoDB 表只把自增主键的最大 ID 记录到内存中，所以重启数据库或者对表 OPTIMIZE 操作，都会使最大 ID 丢失。</li>
<li>但是，如果我们使用表的类型是 MyISAM ，那么这条记录的 ID 就是 18 。因为 MyISAM 表会把自增主键的最大 ID 记录到数据文件里面，重启 MYSQL 后，自增主键的最大 ID 也不会丢失。</li>
</ul>
<p>最后，还可以跟面试官装个 x ，生产数据，不建议进行物理删除记录。</p>
<p>🦅 <strong>表中有大字段 X(例如：text 类型)，且字段 X 不会经常更新，以读为为主，请问您是选择拆成子表，还是继续放一起?写出您这样选择的理由</strong></p>
<ul>
<li><p>拆带来的问题：连接消耗 + 存储拆分空间。</p>
<blockquote>
<p>如果能容忍拆分带来的空间问题，拆的话最好和经常要查询的表的主键在物理结构上放置在一起(分区) 顺序 IO ，减少连接消耗，最后这是一个文本列再加上一个全文索引来尽量抵消连接消耗。</p>
</blockquote>
</li>
<li><p>不拆可能带来的问题：查询性能。</p>
<blockquote>
<p>如果能容忍不拆分带来的查询性能损失的话，上面的方案在某个极致条件下肯定会出现问题，那么不拆就是最好的选择。</p>
</blockquote>
</li>
</ul>
<p>实际场景下，例如说商品表数据量比较大的情况下，会将商品描述单独存储到一个表中。即，使用拆的方案。</p>
<h3 id="MySQL-有哪些存储引擎？"><a href="#MySQL-有哪些存储引擎？" class="headerlink" title="MySQL 有哪些存储引擎？"></a>MySQL 有哪些存储引擎？</h3><p>MySQL 提供了多种的存储引擎：</p>
<ul>
<li>InnoDB</li>
<li>MyISAM</li>
<li>MRG_MYISAM</li>
<li>MEMORY</li>
<li>CSV</li>
<li>ARCHIVE</li>
<li>BLACKHOLE</li>
<li>PERFORMANCE_SCHEMA</li>
<li>FEDERATED</li>
<li>…</li>
</ul>
<p>具体每种存储引擎的介绍，可以看看 <a target="_blank" rel="noopener" href="https://github.com/jaywcjlove/mysql-tutorial/blob/master/chapter3/3.5.md">《数据库存储引擎》</a> 。</p>
<p>🦅 <strong>如何选择合适的存储引擎？</strong></p>
<p>提供几个选择标准，然后按照标准，选择对应的存储引擎即可，也可以根据 <a target="_blank" rel="noopener" href="https://github.com/jaywcjlove/mysql-tutorial/blob/master/chapter3/3.5.md#%E5%B8%B8%E7%94%A8%E5%BC%95%E6%93%8E%E5%AF%B9%E6%AF%94">常用引擎对比</a> 来选择你使用的存储引擎。使用哪种引擎需要根据需求灵活选择，一个数据库中多个表可以使用不同的引擎以满足各种性能和实际需求。使用合适的存储引擎，将会提高整个数据库的性能。</p>
<ol>
<li><p>是否需要支持事务。</p>
</li>
<li><p>对索引和缓存的支持。</p>
</li>
<li><p>是否需要使用热备。</p>
</li>
<li><p>崩溃恢复，能否接受崩溃。</p>
</li>
<li><p>存储的限制。</p>
</li>
<li><p>是否需要外键支持。</p>
<blockquote>
<p>目前开发已经不考虑外键，主要原因是性能。具体可以看看 <a target="_blank" rel="noopener" href="http://www.justabug.net/think-in-mysql-foreign-key/">《从 MySQL 物理外键开始的思考》</a> 文章。</p>
</blockquote>
</li>
</ol>
<p>目前，MySQL 默认的存储引擎是 InnoDB ，并且也是最主流的选择。主要原因如下：</p>
<ul>
<li>【最重要】支持事务。</li>
<li>支持行级锁和表级锁，能支持更多的并发量。</li>
<li>查询不加锁，完全不影响查询。</li>
<li>支持崩溃后恢复。</li>
</ul>
<p>在 MySQL5.1 以及之前的版本，默认的存储引擎是 MyISAM ，但是目前已经不再更新，且它有几个比较关键的缺点：</p>
<ul>
<li>不支持事务。</li>
<li>使用表级锁，如果数据量大，一个插入操作锁定表后，其他请求都将阻塞。</li>
</ul>
<blockquote>
<p>也就是说，我们不需要花时间学习 MyISAM。</p>
</blockquote>
<p>🦅 <strong>请说明 InnoDB 和 MyISAM 的区别</strong></p>
<table>
<thead>
<tr>
<th align="left"></th>
<th align="left">InnoDB</th>
<th align="left">MyISAM</th>
</tr>
</thead>
<tbody><tr>
<td align="left">事务</td>
<td align="left">支持</td>
<td align="left">不支持</td>
</tr>
<tr>
<td align="left">存储限制</td>
<td align="left">64TB</td>
<td align="left">无</td>
</tr>
<tr>
<td align="left">锁粒度</td>
<td align="left">行锁</td>
<td align="left">表锁</td>
</tr>
<tr>
<td align="left">崩溃后的恢复</td>
<td align="left">支持</td>
<td align="left">不支持</td>
</tr>
<tr>
<td align="left">外键</td>
<td align="left">支持</td>
<td align="left">不支持</td>
</tr>
<tr>
<td align="left">全文检索</td>
<td align="left">5.7 版本后支持</td>
<td align="left">支持</td>
</tr>
</tbody></table>
<p>更完整的对比，可以看看 <a target="_blank" rel="noopener" href="https://github.com/jaywcjlove/mysql-tutorial/blob/master/chapter3/3.5.md">《数据库存储引擎》</a> 的 <a target="_blank" rel="noopener" href="http://svip.iocoder.cn/MySQL/Interview/#">「常用引擎对比」</a> 小节。</p>
<p>🦅 <strong>请说说 InnoDB 的 4 大特性？</strong></p>
<blockquote>
<p>貌似我面试没被问过…反正，我是没弄懂过~~</p>
</blockquote>
<ul>
<li>插入缓冲(insert buffer)</li>
<li>二次写(double write)</li>
<li>自适应哈希索引(ahi)</li>
<li>预读(read ahead)</li>
</ul>
<p>🦅 <strong>为什么 SELECT COUNT(*) FROM table 在 InnoDB 比 MyISAM 慢？</strong></p>
<p>对于 <code>SELECT COUNT(*) FROM table</code> 语句，在没有 <code>WHERE</code> 条件的情况下，InnoDB 比 MyISAM 可能会慢很多，尤其在大表的情况下。因为，InnoDB 是去实时统计结果，会全表扫描；而 MyISAM 内部维持了一个计数器，预存了结果，所以直接返回即可。</p>
<p>详细的原因，胖友可以看看 <a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_15037231/article/details/81179383">《高性能 MySQL 之 Count 统计查询》</a> 博客。</p>
<p>🦅 <strong>各种不同 MySQL 版本的 Innodb 的改进？</strong></p>
<blockquote>
<p>艿艿：这是一个选择了解的问题。</p>
</blockquote>
<p>MySQL5.6 下 Innodb 引擎的主要改进：</p>
<ol>
<li>online DDL</li>
<li>memcached NoSQL 接口</li>
<li>transportable tablespace（ alter table discard/import tablespace）</li>
<li>MySQL 正常关闭时，可以 dump 出 buffer pool 的（ space， page_no），重启时 reload，加快预热速度</li>
<li>索引和表的统计信息持久化到 mysql.innodb_table_stats 和 mysql.innodb_index_stats，可提供稳定的执行计划</li>
<li>Compressed row format 支持压缩表</li>
</ol>
<p>MySQL5.7 下 Innodb 引擎的主要改进：</p>
<ul>
<li><p>1、修改 varchar 字段长度有时可以使用</p>
<blockquote>
<p>这里的“有时”，指的是也有些限制。可见 <a target="_blank" rel="noopener" href="https://yq.aliyun.com/articles/581726">《MySQL 5.7 online ddl 的一些改进》</a> 。</p>
</blockquote>
</li>
<li><p>2、Buffer pool 支持在线改变大小</p>
</li>
<li><p>3、Buffer pool 支持导出部分比例</p>
</li>
<li><p>4、支持新建 innodb tablespace，并可以在其中创建多张表</p>
</li>
<li><p>5、磁盘临时表采用 innodb 存储，并且存储在 innodb temp tablespace 里面，以前是 MyISAM 存储</p>
</li>
<li><p>6、透明表空间压缩功能</p>
</li>
</ul>
<h3 id="【重点】什么是索引？"><a href="#【重点】什么是索引？" class="headerlink" title="【重点】什么是索引？"></a>【重点】什么是索引？</h3><p>索引，类似于书籍的目录，想找到一本书的某个特定的主题，需要先找到书的目录，定位对应的页码。</p>
<p>MySQL 中存储引擎使用类似的方式进行查询，先去索引中查找对应的值，然后根据匹配的索引找到对应的数据行。</p>
<p>🦅 <strong>索引有什么好处？</strong></p>
<ol>
<li>提高数据的检索速度，降低数据库IO成本：使用索引的意义就是通过缩小表中需要查询的记录的数目从而加快搜索的速度。</li>
<li>降低数据排序的成本，降低CPU消耗：索引之所以查的快，是因为先将数据排好序，若该字段正好需要排序，则正好降低了排序的成本。</li>
</ol>
<p>🦅 <strong>索引有什么坏处？</strong></p>
<ol>
<li>占用存储空间：索引实际上也是一张表，记录了主键与索引字段，一般以索引文件的形式存储在磁盘上。</li>
<li>降低更新表的速度：表的数据发生了变化，对应的索引也需要一起变更，从而减低的更新速度。否则索引指向的物理数据可能不对，这也是索引失效的原因之一。</li>
</ol>
<p>🦅 <strong>索引的使用场景？</strong></p>
<ul>
<li><p>1、对非常小的表，大部分情况下全表扫描效率更高。</p>
</li>
<li><p>2、对中大型表，索引非常有效。</p>
</li>
<li><p>3、特大型的表，建立和使用索引的代价随着增长，可以使用分区技术来解决。</p>
<blockquote>
<p>实际场景下，MySQL 分区表很少使用，原因可以看看 <a target="_blank" rel="noopener" href="https://blog.csdn.net/admin1973/article/details/55504018">《互联网公司为啥不使用 MySQL 分区表？》</a> 文章。</p>
<p>对于特大型的表，更常用的是“分库分表”，目前解决方案有 Sharding Sphere、MyCAT 等等。</p>
</blockquote>
</li>
</ul>
<p>🦅 <strong>索引的类型？</strong></p>
<p>索引，都是实现在存储引擎层的。主要有六种类型：</p>
<ul>
<li><p>1、普通索引：最基本的索引，没有任何约束。</p>
</li>
<li><p>2、唯一索引：与普通索引类似，但具有唯一性约束。</p>
</li>
<li><p>3、主键索引：特殊的唯一索引，不允许有空值。</p>
</li>
<li><p>4、复合索引：将多个列组合在一起创建索引，可以覆盖多个列。</p>
</li>
<li><p>5、外键索引：只有InnoDB类型的表才可以使用外键索引，保证数据的一致性、完整性和实现级联操作。</p>
</li>
<li><p>6、全文索引：MySQL 自带的全文索引只能用于 InnoDB、MyISAM ，并且只能对英文进行全文检索，一般使用全文索引引擎。</p>
<blockquote>
<p>常用的全文索引引擎的解决方案有 Elasticsearch、Solr 等等。最为常用的是 Elasticsearch 。</p>
</blockquote>
</li>
</ul>
<p>具体的使用，可以看看 <a target="_blank" rel="noopener" href="http://blog.720ui.com/2017/mysql_core_03_how_use_index/">《服务端指南 数据存储篇 | MySQL（03） 如何设计索引》</a> 。</p>
<p>🦅 <strong>MySQL 索引的“创建”原则？</strong></p>
<blockquote>
<p>注意，是“创建”噢。</p>
</blockquote>
<ul>
<li><p>1、最适合索引的列是出现在 <code>WHERE</code> 子句中的列，或连接子句中的列，而不是出现在 <code>SELECT</code> 关键字后的列。</p>
</li>
<li><p>2、索引列的基数越大，索引效果越好。</p>
<blockquote>
<p>具体为什么，可以看看如下两篇文章：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/mingyundezuoan/article/details/79038989">《MySQL 索引基数》</a> 理解相对简单</li>
<li><a target="_blank" rel="noopener" href="https://www.ibm.com/developerworks/cn/data/library/techarticle/dm-1309cardinal/index.html">《低基数索引为什么会对性能产生负面影响》</a> 写的更原理，所以较为难懂。</li>
</ul>
</blockquote>
</li>
<li><p>3、根据情况创建复合索引，复合索引可以提高查询效率。</p>
<blockquote>
<p>因为复合索引的基数会更大。</p>
</blockquote>
</li>
<li><p>4、避免创建过多的索引，索引会额外占用磁盘空间，降低写操作效率。</p>
</li>
<li><p>5、主键尽可能选择较短的数据类型，可以有效减少索引的磁盘占用提高查询效率。</p>
</li>
<li><p>6、对字符串进行索引，应该定制一个前缀长度，可以节省大量的索引空间。</p>
</li>
</ul>
<p>🦅 <strong>MySQL 索引的“使用”注意事项？</strong></p>
<blockquote>
<p>注意，是“使用”噢。</p>
</blockquote>
<ul>
<li><p>1、应尽量避免在 <code>WHERE</code> 子句中使用 <code>!=</code> 或 <code>&lt;&gt;</code> 操作符，否则将引擎放弃使用索引而进行全表扫描。优化器将无法通过索引来确定将要命中的行数,因此需要搜索该表的所有行。</p>
<blockquote>
<p>注意，<code>column IS NULL</code> 也是不可以使用索引的。</p>
</blockquote>
</li>
<li><p>2、应尽量避免在 <code>WHERE</code> 子句中使用 <code>OR</code> 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如：<code>SELECT id FROM t WHERE num = 10 OR num = 20</code> 。</p>
</li>
<li><p>3、应尽量避免在 <code>WHERE</code> 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。</p>
</li>
<li><p>4、应尽量避免在 <code>WHERE</code> 子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。</p>
</li>
<li><p>5、不要在 <code>WHERE</code> 子句中的 <code>=</code> 左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引。</p>
</li>
<li><p>6、复合索引遵循前缀原则。</p>
</li>
<li><p>7、如果 MySQL 评估使用索引比全表扫描更慢，会放弃使用索引。如果此时想要索引，可以在语句中添加强制索引。</p>
</li>
<li><p>8、列类型是字符串类型，查询时一定要给值加引号，否则索引失效。</p>
</li>
<li><p>9、<code>LIKE</code> 查询，<code>%</code> 不能在前，因为无法使用索引。如果需要模糊匹配，可以使用全文索引。</p>
</li>
</ul>
<p>关于这块，可以看看 <a target="_blank" rel="noopener" href="http://blog.720ui.com/2017/mysql_core_04_index_item/">《服务端指南 数据存储篇 | MySQL（04） 索引使用的注意事项》</a> 文章，写的更加细致。</p>
<p>🦅 <strong>以下三条 SQL 如何建索引，只建一条怎么建？</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">WHERE a &#x3D; 1 AND b &#x3D; 1</span><br><span class="line">WHERE b &#x3D; 1</span><br><span class="line">WHERE b &#x3D; 1 ORDER BY time DESC</span><br></pre></td></tr></table></figure>

<ul>
<li>以顺序 b , a, time 建立复合索引，<code>CREATE INDEX table1_b_a_time ON index_test01(b, a, time)</code>。</li>
<li>对于第一条 SQL ，因为最新 MySQL 版本会优化 <code>WHERE</code> 子句后面的列顺序，以匹配复合索引顺序。</li>
</ul>
<p>🦅 <strong>想知道一个查询用到了哪个索引，如何查看?</strong></p>
<p><code>EXPLAIN</code> 显示了 MYSQL 如何使用索引来处理 SELECT 语句以及连接表,可以帮助选择更好的索引和写出更优化的查询语句。</p>
<p>使用方法，在 <code>SELECT</code> 语句前加上 <code>EXPLAIN</code> 就可以了。感兴趣，可以详细看看 <a target="_blank" rel="noopener" href="http://www.jfox.info/2017/mysql-explain%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%E8%AF%A6%E7%BB%86%E8%A7%A3%E9%87%8A.html">《MySQL explain 执行计划详细解释》</a> 。</p>
<h3 id="【重点】MySQL-索引的原理？"><a href="#【重点】MySQL-索引的原理？" class="headerlink" title="【重点】MySQL 索引的原理？"></a>【重点】MySQL 索引的原理？</h3><p>解释 MySQL 索引的原理，篇幅会比较长，并且网络上已经有靠谱的资料可以看。</p>
<ul>
<li><p><a target="_blank" rel="noopener" href="http://blog.codinglabs.org/articles/theory-of-mysql-index.html">《MySQL索引背后的数据结构及算法原理》</a></p>
<blockquote>
<p>写的一点都不好，艿艿在地铁反复看了 10 遍。</p>
<p>强烈推荐！！！！</p>
</blockquote>
</li>
<li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/u013235478/article/details/50625677">《MySQL 索引原理》</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/tongdanping/article/details/79878302">《深入理解 MySQL 索引原理和实现 —— 为什么索引可以加速查询？》</a></p>
</li>
</ul>
<p>下面，艿艿对关键知识做下整理，方便胖友回顾。</p>
<p>🦅 <strong>MySQL 有哪些索引方法？</strong></p>
<blockquote>
<p>这个问题是索引方法 Index Method ，上面的索引类型 Index Type 。</p>
</blockquote>
<p>在 MySQL 中，我们可以看到两种索引方式：</p>
<ul>
<li>B-Tree 索引。</li>
<li>Hash 索引。</li>
</ul>
<p>实际场景下，我们基本仅仅使用 B-Tree 索引。详细的对比可以看看 <a target="_blank" rel="noopener" href="https://blog.csdn.net/oChangWen/article/details/54024063">《MySQL BTree 索引和 hash 索引的区别》</a> 。</p>
<p>对于 Hash 索引，我们了解即可，面试重点是掌握 B-Tree 索引的原理。</p>
<p>🦅 <strong>什么是 B-Tree 索引？</strong></p>
<p>B-Tree 是为磁盘等外存储设备设计的一种平衡查找树。因此在讲 B-Tree 之前先了解下磁盘的相关知识。</p>
<ul>
<li><p>系统从磁盘读取数据到内存时是以磁盘块（block）为基本单位的，位于同一个磁盘块中的数据会被一次性读取出来，而不是需要什么取什么。</p>
</li>
<li><p>InnoDB存储引擎中有页（Page）的概念，页是其磁盘管理的最小单位。InnoDB 存储引擎中默认每个页的大小为 16 KB，可通过参数 innodb_page_size 将页的大小设置为 4K、8K、16K ，在 MySQL 中可通过如下命令查看页的大小：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like &#39;innodb_page_size&#39;;</span><br></pre></td></tr></table></figure>
</li>
<li><p>而系统一个磁盘块的存储空间往往没有这么大，因此 InnoDB 每次申请磁盘空间时都会是若干地址连续磁盘块来达到页的大小 16KB 。InnoDB 在把磁盘数据读入到磁盘时会以页为基本单位，在查询数据时如果一个页中的每条数据都能有助于定位数据记录的位置，这将会减少磁盘 I/O 次数，提高查询效率。</p>
</li>
</ul>
<p>B-Tree 结构的数据可以让系统高效的找到数据所在的磁盘块。为了描述B-Tree，首先定义一条记录为一个二元组 [key, data] ，key 为记录的键值，对应表中的主键值，data 为一行记录中除主键外的数据。对于不同的记录，key值互不相同。</p>
<p>一棵 m 阶的 B-Tree 有如下特性：</p>
<ol>
<li>每个节点最多有 m 个孩子。<ul>
<li>除了根节点和叶子节点外，其它每个节点至少有 Ceil(m/2) 个孩子。</li>
<li>若根节点不是叶子节点，则至少有 2 个孩子。</li>
</ul>
</li>
<li>所有叶子节点都在同一层，且不包含其它关键字信息。</li>
<li>每个非叶子节点包含 n 个关键字信息（P0,P1,…Pn, k1,…kn）<ul>
<li>关键字的个数 n 满足：ceil(m/2)-1 &lt;= n &lt;= m-1</li>
<li>ki(i=1,…n) 为关键字，且关键字升序排序。</li>
<li>Pi(i=0,…n) 为指向子树根节点的指针。P(i-1) 指向的子树的所有节点关键字均小于 ki ，但都大于 k(i-1) 。</li>
</ul>
</li>
</ol>
<p>B-Tree 中的每个节点根据实际情况可以包含大量的关键字信息和分支，如下图所示为一个 3 阶的 B-Tree：</p>
<p><img src="http://static2.iocoder.cn/84ea509fa091a10add4e7614e6cb37db" alt="B-Tree 的结构">                                                                                        B-Tree 的结构</p>
<ul>
<li>每个节点占用一个盘块的磁盘空间，一个节点上有两个升序排序的 key 和三个指向子树根节点的 point ，point 存储的是子节点所在磁盘块的地址。两个 key 划分成的三个范围域，对应三个 point 指向的子树的数据的范围域。</li>
<li>以根节点为例，key 为 17 和 35 ，P1 指针指向的子树的数据范围为小于 17 ，P2 指针指向的子树的数据范围为 [17~35] ，P3 指针指向的子树的数据范围为大于 35 。</li>
</ul>
<p>模拟查找 key 为 29 的过程：</p>
<ul>
<li>1、根据根节点找到磁盘块 1 ，读入内存。【磁盘I/O操作第1次】</li>
<li>2、比较 key 29 在区间（17,35），找到磁盘块 1 的指针 P2 。</li>
<li>3、根据 P2 指针找到磁盘块 3 ，读入内存。【磁盘I/O操作第2次】</li>
<li>4、比较 key 29 在区间（26,30），找到磁盘块3的指针P2。</li>
<li>5、根据 P2 指针找到磁盘块 8 ，读入内存。【磁盘I/O操作第3次】</li>
<li>6、在磁盘块 8 中的 key 列表中找到 eky 29 。</li>
</ul>
<p>分析上面过程，发现需要 3 次磁盘 I/O 操作，和 3 次内存查找操作。由于内存中的 key 是一个有序表结构，可以利用二分法查找提高效率。而 3 次磁盘 I/O 操作是影响整个 B-Tree 查找效率的决定因素。B-Tree 相对于 AVLTree 缩减了节点个数，使每次磁盘 I/O 取到内存的数据都发挥了作用，从而提高了查询效率。</p>
<p>🦅 <strong>什么是 B+Tree 索引？</strong></p>
<p>B+Tree 是在 B-Tree 基础上的一种优化，使其更适合实现外存储索引结构，InnoDB存储引擎就是用 B+Tree 实现其索引结构。</p>
<blockquote>
<p>下面这一段，面试非常关键。</p>
</blockquote>
<p>从上一节中的 B-Tree 结构图中可以看到，每个节点中不仅包含数据的 key 值，还有 data 值。而每一个页的存储空间是有限的，如果 data 数据较大时将会导致每个节点（即一个页）能存储的 key 的数量很小，当存储的数据量很大时同样会导致 B-Tree 的深度较大，增大查询时的磁盘 I/O 次数，进而影响查询效率。在 B+Tree 中，所有数据记录节点都是按照键值大小顺序存放在同一层的叶子节点上，而非叶子节点上只存储 key 值信息，这样可以大大加大每个节点存储的 key 值数量，降低 B+Tree 的高度。</p>
<p>B+Tree 相对于 B-Tree 有几点不同：</p>
<ul>
<li>非叶子节点只存储键值信息。</li>
<li>所有叶子节点之间都有一个链指针。</li>
<li>数据记录都存放在叶子节点中。</li>
</ul>
<p>将上一节中的 B-Tree 优化，由于 B+Tree 的非叶子节点只存储键值信息，假设每个磁盘块能存储 4 个键值及指针信息，则变成 B+Tree 后其结构如下图所示：</p>
<p><img src="http://static2.iocoder.cn/259d196856a231aff5e3cf1505848af4" alt="B+Tree 的结构">                                                                                    B+Tree 的结构</p>
<ul>
<li>通常在 B+Tree 上有两个头指针，一个指向根节点，另一个指向关键字最小的叶子节点，而且所有叶子节点（即数据节点）之间是一种链式环结构。因此可以对 B+Tree 进行两种查找运算：一种是对于主键的范围查找和分页查找，另一种是从根节点开始，进行随机查找。</li>
</ul>
<p>可能上面例子中只有 22 条数据记录，看不出 B+Tree 的优点，下面做一个推算：</p>
<ul>
<li>InnoDB 存储引擎中页的大小为 16KB，一般表的主键类型为 INT（占用4个字节） 或 BIGINT（占用8个字节），指针类型也一般为 4 或 8 个字节，也就是说一个页（B+Tree 中的一个节点）中大概存储 16KB/(8B+8B)=1K 个键值（因为是估值，为方便计算，这里的 K 取值为〖10〗^3）。也就是说一个深度为 3 的 B+Tree 索引可以维护10^3 <em>10^3</em> 10^3 = 10亿 条记录。</li>
<li>实际情况中每个节点可能不能填充满，因此在数据库中，B+Tree 的高度一般都在 2<del>4 层。MySQL 的 InnoDB 存储引擎在设计时是将根节点常驻内存的，也就是说查找某一键值的行记录时最多只需要 1</del>3 次磁盘 I/O 操作。</li>
</ul>
<p>🦅 <strong>B-Tree 有哪些索引类型？</strong></p>
<p>在 B+Tree 中，根据叶子节点的内容，索引类型分为<strong>主键索引</strong>和<strong>非主键索引</strong>。</p>
<blockquote>
<p>注意，这里的索引类型，和上面的索引类型，还是对的上的噢。</p>
</blockquote>
<ul>
<li><p>主键索引的叶子节点存的数据是整行数据( 即具体数据 )。在 InnoDB 里，主键索引也被称为<strong>聚集索引</strong>（clustered index）。</p>
</li>
<li><p>非主键索引的叶子节点存的数据是整行数据的主键，键值是索引。在 InnoDB 里，非主键索引也被称为</p>
<p>辅助索引</p>
<p>（secondary index）。</p>
<blockquote>
<p>二级索引的叶节点存储的是主键值，而不是行指针，这是为了减少当出现行移动或数据页分裂时二级索引的维护工作，但会让二级索引占用更多的空间。</p>
</blockquote>
</li>
</ul>
<p>辅助索引与聚集索引的区别在于辅助索引的叶子节点并不包含行记录的全部数据，而是存储相应行数据的聚集索引键，即主键。当通过辅助索引来查询数据时，需要进过两步：</p>
<ul>
<li>首先，InnoDB 存储引擎会遍历辅助索引找到主键。</li>
<li>然后，再通过主键在聚集索引中找到完整的行记录数据。</li>
</ul>
<p>另外，InnoDB 通过主键聚簇数据，如果没有定义主键，会选择一个唯一的非空索引代替，如果没有这样的索引，会隐式定义个主键作为聚簇索引。</p>
<p>再另外，可能有胖友有和艿艿的一样疑惑，在<strong>辅助索引</strong>如果相同的索引怎么存储？最终存储到 B+Tree 非子节点中时，它们对应的主键 ID 是不同的，所以妥妥的。如下图所示：<a target="_blank" rel="noopener" href="http://static2.iocoder.cn/images/MySQL/2019_12_01/01.png"><img src="http://static2.iocoder.cn/images/MySQL/2019_12_01/01.png" alt="相同的索引怎么存储"></a>相同的索引怎么存储</p>
<p>🦅 <strong>聚簇索引的注意点有哪些？</strong></p>
<p>聚簇索引表最大限度地提高了 I/O 密集型应用的性能，但它也有以下几个限制：</p>
<ul>
<li><p>1、插入速度严重依赖于插入顺序，按照主键的顺序插入是最快的方式，否则将会出现页分裂，严重影响性能。因此，对于 InnoDB 表，我们一般都会定义一个自增的 ID 列为主键。</p>
<blockquote>
<p>关于这一点，可能面试官会换一个问法。例如，为什么主键需要是自增 ID ，又或者为什么主键需要带有时间性关联。</p>
</blockquote>
</li>
<li><p>2、更新主键的代价很高，因为将会导致被更新的行移动。因此，对于InnoDB 表，我们一般定义主键为不可更新。</p>
<blockquote>
<p>MySQL 默认情况下，主键是允许更新的。对于 MongoDB ，其 主键是不允许更新的。</p>
</blockquote>
</li>
<li><p>3、二级索引访问需要两次索引查找，第一次找到主键值，第二次根据主键值找到行数据。</p>
<blockquote>
<p>当然，有一种情况可以无需二次查找，基于非主键索引查询，但是查询字段只有主键 ID ，那么在二级索引中就可以查找到。</p>
</blockquote>
</li>
<li><p>4、主键 ID 建议使用整型。因为，每个主键索引的 B+Tree 节点的键值可以存储更多主键 ID ，每个非主键索引的 B+Tree 节点的数据可以存储更多主键 ID 。</p>
</li>
</ul>
<p>🦅 <strong>什么是索引的最左匹配特性？</strong></p>
<p>当 B+Tree 的数据项是复合的数据结构，比如索引 <code>(name, age, sex)</code> 的时候，B+Tree 是按照从左到右的顺序来建立搜索树的。</p>
<ul>
<li>比如当 <code>(张三, 20, F)</code> 这样的数据来检索的时候，B+Tree 会优先比较 name 来确定下一步的所搜方向，如果 name 相同再依次比较 age 和 sex ，最后得到检索的数据。</li>
<li>但当 <code>(20, F)</code> 这样的没有 name 的数据来的时候，B+Tree 就不知道下一步该查哪个节点，因为建立搜索树的时候 name 就是第一个比较因子，必须要先根据 name 来搜索才能知道下一步去哪里查询。</li>
<li>比如当 <code>(张三, F)</code> 这样的数据来检索时，B+Tree 可以用 name 来指定搜索方向，但下一个字段 age 的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是 F 的数据了。</li>
</ul>
<p>这个是非常重要的性质，即索引的最左匹配特性。</p>
<p>🦅 <strong>MyISAM 索引实现？</strong></p>
<blockquote>
<p>艿艿：注意，我们上面看到的都是 InnoDB 存储引擎下的索引实现。</p>
</blockquote>
<p>MyISAM 索引的实现，和 InnoDB 索引的实现是一样使用 B+Tree ，<strong>差别在于 MyISAM 索引文件和数据文件是分离的，索引文件仅保存数据记录的地址</strong>。</p>
<p>1）主键索引：</p>
<p>MyISAM引 擎使用B+Tree作为索引结构，<strong>叶节点的data域存放的是数据记录的地址</strong>。下图是MyISAM主键索引的原理图：</p>
<p><a target="_blank" rel="noopener" href="http://static2.iocoder.cn/d49d260fc1eb8f992df0401b70d70e3d"><img src="http://static2.iocoder.cn/d49d260fc1eb8f992df0401b70d70e3d" alt="主键索引"></a>主键索引</p>
<ul>
<li>这里设表一共有三列，假设我们以 Col1 为主键，上图是一个 MyISAM 表的主索引（Primary key）示意。可以看出 MyISAM 的索引文件仅仅保存数据记录的地址。</li>
</ul>
<p>2）辅助索引：</p>
<p><strong>在 MyISAM 中，主索引和辅助索引在结构上没有任何区别，只是主索引要求 key 是唯一的，而辅助索引的 key 可以重复。</strong>如果我们在 Col2 上建立一个辅助索引，则此索引的结构如下图所示：</p>
<p><a target="_blank" rel="noopener" href="http://static2.iocoder.cn/2fb922405a35479fa99eb2de4708638c"><img src="http://static2.iocoder.cn/2fb922405a35479fa99eb2de4708638c" alt="辅助索引"></a>辅助索引</p>
<ul>
<li>同样也是一颗 B+Tree ，data 域保存数据记录的地址。因此，<strong>MyISAM 中索引检索的算法为首先按照 B+Tree 搜索算法搜索索引，如果指定的 Key 存在，则取出其 data 域的值，然后以 data 域的值为地址，读取相应数据记录。</strong></li>
</ul>
<p>MyISAM 的索引方式也叫做“<strong>非聚集</strong>”的，之所以这么称呼是为了与InnoDB 的聚集索引区分。</p>
<p>🦅 <strong>MyISAM 索引与 InnoDB 索引的区别？</strong></p>
<ul>
<li><p>InnoDB 索引是聚簇索引，MyISAM 索引是非聚簇索引。</p>
</li>
<li><p>InnoDB 的主键索引的叶子节点存储着行数据，因此主键索引非常高效。</p>
</li>
<li><p>MyISAM 索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。</p>
</li>
<li><p>InnoDB 非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效。</p>
<blockquote>
<p>覆盖索引，指的是基于非主键索引查询，但是查询字段只有主键 ID ，那么在二级索引中就可以查找到。</p>
</blockquote>
</li>
</ul>
<h3 id="【重点】请说说-MySQL-的四种事务隔离级别？"><a href="#【重点】请说说-MySQL-的四种事务隔离级别？" class="headerlink" title="【重点】请说说 MySQL 的四种事务隔离级别？"></a>【重点】请说说 MySQL 的四种事务隔离级别？</h3><blockquote>
<p>这是面试中最常见的问题。如果回答不对，可能就被抬走了。</p>
</blockquote>
<p>事务就是对一系列的数据库操作（比如插入多条数据）进行统一的提交或回滚操作，如果插入成功，那么一起成功，如果中间有一条出现异常，那么回滚之前的所有操作。</p>
<p>这样可以防止出现脏数据，防止数据库数据出现问题。</p>
<p>🦅 <strong>事务的特性指的是？</strong></p>
<p>指的是 <strong>ACID</strong> ，如下图所示：</p>
<p><img src="http://static2.iocoder.cn/images/Spring/2018-12-24/06.png" alt="事务的特性">事务的特性</p>
<ol>
<li><strong>原子性</strong> Atomicity ：一个事务（transaction）中的所有操作，或者全部完成，或者全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被恢复（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。即，事务不可分割、不可约简。</li>
<li><strong>一致性</strong> Consistency ：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7">约束</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%A7%A6%E5%8F%91%E5%99%A8_(%E6%95%B0%E6%8D%AE%E5%BA%93)">触发器</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/w/index.php?title=%E7%BA%A7%E8%81%94%E5%9B%9E%E6%BB%9A&action=edit&redlink=1">级联回滚</a>等。</li>
<li><strong>隔离性</strong> Isolation ：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。</li>
<li><strong>持久性</strong> Durability ：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。</li>
</ol>
<p>🦅 <strong>事务的并发问题？</strong></p>
<p>实际场景下，事务并不是串行的，所以会带来如下三个问题：</p>
<ul>
<li>1、脏读：事务 A 读取了事务 B 更新的数据，然后 B 回滚操作，那么 A 读取到的数据是脏数据。</li>
<li>2、不可重复读：事务 A 多次读取同一数据，事务 B 在事务 A 多次读取的过程中，对数据作了更新并提交，导致事务 A 多次读取同一数据时，结果不一致。</li>
<li>3、幻读：系统管理员 A 将数据库中所有学生的成绩从具体分数改为 ABCDE 等级，但是系统管理员 B 就在这个时候插入了一条具体分数的记录，当系统管理员 A 改结束后发现还有一条记录没有改过来，就好像发生了幻觉一样，这就叫幻读。</li>
</ul>
<p>小结：不可重复读的和幻读很容易混淆，不可重复读侧重于修改，幻读侧重于新增或删除。解决不可重复读的问题只需锁住满足条件的行，解决幻读需要锁表。</p>
<p>🦅 <strong>MySQL 事务隔离级别会产生的并发问题？</strong></p>
<p>事务定义了四种事务隔离级别，不同数据库在实现时，产生的并发问题是不同的。</p>
<blockquote>
<p>不同的隔离级别有不同的现象，并有不同的锁定/并发机制，隔离级别越高，数据库的并发性就越差。</p>
</blockquote>
<ul>
<li><p>READ UNCOMMITTED（未提交读）：事务中的修改，即使没有提交，对其他事务也都是可见的。</p>
<blockquote>
<p>会导致脏读。</p>
</blockquote>
</li>
<li><p>READ COMMITTED（提交读）：事务从开始直到提交之前，所做的任何修改对其他事务都是不可见的。</p>
<blockquote>
<p>会导致不可重复读。</p>
<p>这个隔离级别，也可以叫做“不可重复读”。</p>
</blockquote>
</li>
<li><p>REPEATABLE READ（可重复读）：一个事务按相同的查询条件读取以前检索过的数据，其他事务插入了满足其查询条件的新数据。产生幻行。</p>
<blockquote>
<p>会导致幻读。</p>
</blockquote>
</li>
<li><p>SERIALIZABLE（可串行化）：强制事务串行执行。</p>
</li>
</ul>
<p>MySQL InnoDB 采用 <strong>MVCC</strong> 来支持高并发，实现结果如下表所示：</p>
<blockquote>
<p>关于 Oracle 和 PostgreSQL ，需要胖友自己去搜索资料。</p>
</blockquote>
<table>
<thead>
<tr>
<th align="left">事务隔离级别</th>
<th align="left">脏读</th>
<th align="left">不可重复读</th>
<th align="left">幻读</th>
</tr>
</thead>
<tbody><tr>
<td align="left">读未提交（read-uncommitted）</td>
<td align="left">是</td>
<td align="left">是</td>
<td align="left">是</td>
</tr>
<tr>
<td align="left">读已提交（read-committed）</td>
<td align="left">否</td>
<td align="left">是</td>
<td align="left">是</td>
</tr>
<tr>
<td align="left">可重复读（repeatable-read）</td>
<td align="left">否</td>
<td align="left">否</td>
<td align="left">是（x）</td>
</tr>
<tr>
<td align="left">串行化（serializable）</td>
<td align="left">否</td>
<td align="left">否</td>
<td align="left">否</td>
</tr>
</tbody></table>
<ul>
<li><p>MySQL 默认的事务隔离级别为可重复读（repeatable-read） 。</p>
</li>
<li><p>上图的 <code>&lt;X&gt;</code> 处，<strong>MySQL 通过 MVCC + 事务第一次调用 <code>SELECT</code> 语句才生成快照，实现其在可重复读（repeatable-read）的隔离级别下，不存在幻读问题。</strong>也就是说，上图 <code>&lt;X&gt;</code> 处，需要改成“否”！！！！想要进一步了解的，可以看看 <a target="_blank" rel="noopener" href="https://blog.csdn.net/cxm19881208/article/details/79415726">《MySQL InnoDB 事务 —— 一致性读(快照读)》</a>、<a target="_blank" rel="noopener" href="https://blog.csdn.net/z69183787/article/details/81709743">《MYSQL 当前读和快照读》</a>、<a target="_blank" rel="noopener" href="https://www.cnblogs.com/wwcom123/p/10727194.html">《【MySQL】当前读、快照读、MVCC》</a> 文章。</p>
<blockquote>
<p>艿艿：实际上，艿艿在看完上述几篇文章，仿佛理解了，仿佛又有一点懵逼。后来在看完丁奇老师的 <a target="_blank" rel="noopener" href="http://www.iocoder.cn/images/jikeshijian/MySQL%E5%AE%9E%E6%88%9845%E8%AE%B2.jpg">《MySQL 实战 45 讲》</a> 的「08 | 事务到底是隔离的还是不隔离的？」后，稳了，通透了。</p>
</blockquote>
</li>
<li><p>😈 记住这个表的方式，我们会发现它是自左上向右下是一个对角线。当然，最好是去理解。</p>
</li>
<li><p>具体的实验，胖友可以看看 <a target="_blank" rel="noopener" href="https://www.cnblogs.com/huanongying/p/7021555.html">《MySQL 的四种事务隔离级别》</a> 。</p>
</li>
<li><p>有些资料说可重复读解决了幻读，实际是存在的，可以通过 <code>SELECT xxx FROM t WHERE id = ? FOR UPDATE</code> 的方式，获得到悲观锁，禁止其它事务操作对应的数据，从而解决幻读问题。感兴趣的胖友，可以看看如下文章：</p>
<ul>
<li><p>必读 <a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000016566788">《MySQL 幻读的详解、实例及解决办法》</a> 案例性更强，易懂。</p>
<blockquote>
<p>其实 RR 也是可以避免幻读的，通过对 select 操作手动加 行X锁（SELECT … FOR UPDATE 这也正是 SERIALIZABLE 隔离级别下会隐式为你做的事情），同时还需要知道，即便当前记录不存在，比如 id = 1 是不存在的，当前事务也会获得一把记录锁（因为InnoDB的行锁锁定的是索引，故记录实体存在与否没关系，存在就加 行X锁，不存在就加 next-key lock间隙X锁），其他事务则无法插入此索引的记录，故杜绝了幻读。</p>
</blockquote>
</li>
<li><p>选读 <a target="_blank" rel="noopener" href="http://blog.sina.com.cn/s/blog_499740cb0100ugs7.html">《MySQL 的 InnoDB 的幻读问题》</a> 原理性更强，读懂会很爽。</p>
</li>
<li><p>随意 <a target="_blank" rel="noopener" href="https://github.com/Yhzhtk/note/issues/42">《Innodb 中 RR 隔离级别能否防止幻读？》</a> 一个简单的讨论。</p>
</li>
</ul>
</li>
</ul>
<h3 id="【重点】请说说-MySQL-的锁机制？"><a href="#【重点】请说说-MySQL-的锁机制？" class="headerlink" title="【重点】请说说 MySQL 的锁机制？"></a>【重点】请说说 MySQL 的锁机制？</h3><p>表锁是日常开发中的常见问题，因此也是面试当中最常见的考察点，当多个查询同一时刻进行数据修改时，就会产生并发控制的问题。MySQL 的共享锁和排他锁，就是读锁和写锁。</p>
<ul>
<li>共享锁：不堵塞，多个用户可以同时读一个资源，互不干扰。</li>
<li>排他锁：一个写锁会阻塞其他的读锁和写锁，这样可以只允许一个用户进行写入，防止其他用户读取正在写入的资源。</li>
</ul>
<p>🦅 <strong>锁的粒度？</strong></p>
<ul>
<li>表锁：系统开销最小，会锁定整张表，MyIsam 使用表锁。</li>
<li>行锁：最大程度的支持并发处理，但是也带来了最大的锁开销，InnoDB 使用行锁。</li>
</ul>
<p>🦅 <strong>什么是悲观锁？什么是乐观锁？</strong></p>
<p>1）悲观锁</p>
<p>它指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度，因此，在整个数据处理过程中，将数据处于锁定状态。悲观锁的实现，往往依靠数据库提供的锁机制（也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据）。</p>
<p>在悲观锁的情况下，为了保证事务的隔离性，就需要一致性锁定读。读取数据时给加锁，其它事务无法修改这些数据。修改删除数据时也要加锁，其它事务无法读取这些数据。</p>
<blockquote>
<p>悲观锁，就是我们上面看到的共享锁和排他锁。</p>
</blockquote>
<p>2）乐观锁</p>
<p>相对悲观锁而言，乐观锁机制采取了更加宽松的加锁机制。悲观锁大多数情况下依靠数据库的锁机制实现，以保证操作最大程度的独占性。但随之而来的就是数据库性能的大量开销，特别是对长事务而言，这样的开销往往无法承受。</p>
<p>而乐观锁机制在一定程度上解决了这个问题。乐观锁，大多是基于数据版本（ Version ）记录机制实现。何谓数据版本？即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库表增加一个 “version” 字段来实现。读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。此时，将提交数据的版本数据与数据库表对应记录的当前版本信息进行比对，如果提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据。</p>
<blockquote>
<p>乐观锁，实际就是通过版本号，从而实现 CAS 原子性更新。</p>
</blockquote>
<p>🦅 <strong>什么是死锁？</strong></p>
<p>多数情况下，可以认为如果一个资源被锁定，它总会在以后某个时间被释放。而死锁发生在当多个进程访问同一数据库时，其中每个进程拥有的锁都是其他进程所需的，由此造成每个进程都无法继续下去。简单的说，进程 A 等待进程 B 释放他的资源，B 又等待 A 释放他的资源，这样就互相等待就形成死锁。</p>
<p>虽然进程在运行过程中，可能发生死锁，但死锁的发生也必须具备一定的条件，死锁的发生必须具备以下四个必要条件：</p>
<ul>
<li>互斥条件：指进程对所分配到的资源进行排它性使用，即在一段时间内某资源只由一个进程占用。如果此时还有其它进程请求资源，则请求者只能等待，直至占有资源的进程用毕释放。</li>
<li>请求和保持条件：指进程已经保持至少一个资源，但又提出了新的资源请求，而该资源已被其它进程占有，此时请求进程阻塞，但又对自己已获得的其它资源保持不放。</li>
<li>不剥夺条件：指进程已获得的资源，在未使用完之前，不能被剥夺，只能在使用完时由自己释放。</li>
<li>环路等待条件：指在发生死锁时，必然存在一个进程——资源的环形链，即进程集合 {P0，P1，P2，•••，Pn} 中的 P0 正在等待一个 P1 占用的资源；P1 正在等待 P2 占用的资源，……，Pn 正在等待已被 P0 占用的资源。</li>
</ul>
<p>下列方法有助于最大限度地降低死锁：</p>
<ul>
<li><p>设置获得锁的超时时间。</p>
<blockquote>
<p>通过超时，至少保证最差最差最差情况下，可以有退出的口子。</p>
</blockquote>
</li>
<li><p>按同一顺序访问对象。</p>
<blockquote>
<p>这个是最重要的方式。</p>
</blockquote>
</li>
<li><p>避免事务中的用户交互。</p>
</li>
<li><p>保持事务简短并在一个批处理中。</p>
</li>
<li><p>使用低隔离级别。</p>
</li>
<li><p>使用绑定连接。</p>
</li>
</ul>
<p>🦅 <strong>MySQL 中 InnoDB 引擎的行锁是通过加在什么上完成(或称实现)的？为什么是这样子的？？</strong></p>
<p>InnoDB 是基于索引来完成行锁。例如：<code>SELECT * FROM tab_with_index WHERE id = 1 FOR UPDATE</code> 。</p>
<ul>
<li><code>FOR UPDATE</code> 可以根据条件来完成<strong>行锁</strong>锁定，并且 id 是有索引键的列,如果 id 不是索引键那么 InnoDB 将完成<strong>表锁</strong>，并发将无从谈起。</li>
</ul>
<p>🦅 <strong>关于熟悉 MySQL 的锁机制？</strong></p>
<ul>
<li><p>gap 锁</p>
</li>
<li><p>next-key 锁</p>
</li>
<li><p>Innodb 的行锁是怎么实现的？</p>
<blockquote>
<p>Innodb 的锁的策略为 next-key 锁，即 record lock + gap lock ，是通过在 index 上加 lock 实现的。</p>
<ul>
<li>如果 index 为 unique index ，则降级为 record lock 行锁。</li>
<li>如果是普通 index ，则为 next-key lock 。</li>
<li>如果没有 index ，则直接锁住全表，即表锁。</li>
</ul>
</blockquote>
</li>
<li><p>MyISAM 的表锁是怎么实现的？</p>
<blockquote>
<p>MyISAM 直接使用表锁。</p>
</blockquote>
</li>
</ul>
<h3 id="【重要】MySQL-查询执行顺序？"><a href="#【重要】MySQL-查询执行顺序？" class="headerlink" title="【重要】MySQL 查询执行顺序？"></a>【重要】MySQL 查询执行顺序？</h3><p>MySQL 查询执行的顺序是：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">(1)     SELECT</span><br><span class="line">(2)     DISTINCT &lt;select_list&gt;</span><br><span class="line">(3)     FROM &lt;left_table&gt;</span><br><span class="line">(4)     &lt;join_type&gt; JOIN &lt;right_table&gt;</span><br><span class="line">(5)     ON &lt;join_condition&gt;</span><br><span class="line">(6)     WHERE &lt;where_condition&gt;</span><br><span class="line">(7)     GROUP BY &lt;group_by_list&gt;</span><br><span class="line">(8)     HAVING &lt;having_condition&gt;</span><br><span class="line">(9)     ORDER BY &lt;order_by_condition&gt;</span><br><span class="line">(10)    LIMIT &lt;limit_number&gt;</span><br></pre></td></tr></table></figure>

<p>具体的，可以看看 <a target="_blank" rel="noopener" href="http://zouzls.github.io/2017/03/23/SQL%E6%9F%A5%E8%AF%A2%E4%B9%8B%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F%E8%A7%A3%E6%9E%90/">《SQL 查询之执行顺序解析》</a> 文章。</p>
<h3 id="【重要】聊聊-MySQL-SQL-优化？"><a href="#【重要】聊聊-MySQL-SQL-优化？" class="headerlink" title="【重要】聊聊 MySQL SQL 优化？"></a>【重要】聊聊 MySQL SQL 优化？</h3><p>可以看看如下几篇文章：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/ab958a4823d1">《PHP 面试之 MySQL 查询优化》</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/DERRANTCM/article/details/51534411">《【面试】【MySQL常见问题总结】【03】》</a> 第 078、095、105 题</li>
</ul>
<p>另外，除了从 SQL 层面进行优化，也可以从服务器硬件层面，进一步优化 MySQL 。具体可以看看 <a target="_blank" rel="noopener" href="https://blog.csdn.net/bemavery/article/details/46241533">《MySQL 数据库性能优化之硬件优化》</a> 。</p>
<h3 id="【加分】什么是-MVCC-？"><a href="#【加分】什么是-MVCC-？" class="headerlink" title="【加分】什么是 MVCC ？"></a>【加分】什么是 MVCC ？</h3><blockquote>
<p>艿艿：这是一个面试的加分题，一些大厂比较喜欢问，例如蚂蚁金服。</p>
</blockquote>
<p>多版本并发控制（MVCC），是一种用来<strong>解决读-写冲突</strong>的无锁并发控制，也就是为事务分配单向增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始前的数据库的快照。 这样在读操作不用阻塞写操作，写操作不用阻塞读操作的同时，避免了脏读和不可重复读。</p>
<p>推荐可以看看如下资料：</p>
<ul>
<li><p>沈询 <a target="_blank" rel="noopener" href="https://www.imooc.com/learn/272">《在线分布式数据库原理与实践》</a></p>
<blockquote>
<p>一共 1 小时 53 分钟，有趣，牛逼，强烈推荐！！！</p>
</blockquote>
</li>
<li><p>钟延辉</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/sOxLZlXRYR-zZKStE7qAwg">《分布式数据库 MVCC 技术探秘 (1)》</a></li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/8lX3Gyq4J5vLHETtG01EdA">《分布式数据库 MVCC 技术探秘(2): 混合逻辑时钟》</a></li>
</ul>
</li>
</ul>
<h3 id="编写-SQL-查询语句的考题合集"><a href="#编写-SQL-查询语句的考题合集" class="headerlink" title="编写 SQL 查询语句的考题合集"></a>编写 SQL 查询语句的考题合集</h3><p>因为考题比较多，艿艿就不一一列举，瞄了一些还不错的文章，如下：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.yanxurui.cc/posts/mysql/2016-11-10-10-sql-interview-questions/">《10 道 MySQL 查询语句面试题》</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/geaozhang/p/6839297.html">《MySQL 开发面试题》</a></li>
<li><a target="_blank" rel="noopener" href="https://juejin.im/entry/5b57ebdcf265da0f61320e6f">《企业面试题｜最常问的 MySQL 面试题集合（二）》</a></li>
</ul>
<h3 id="MySQL-数据库-CPU-飙升到-500-的话，怎么处理？"><a href="#MySQL-数据库-CPU-飙升到-500-的话，怎么处理？" class="headerlink" title="MySQL 数据库 CPU 飙升到 500% 的话，怎么处理？"></a>MySQL 数据库 CPU 飙升到 500% 的话，怎么处理？</h3><p>当 CPU 飙升到 500% 时，先用操作系统命令 top 命令观察是不是 mysqld 占用导致的，如果不是，找出占用高的进程，并进行相关处理。</p>
<blockquote>
<p>如果此时是 IO 压力比较大，可以使用 iostat 命令，定位是哪个进程占用了磁盘 IO 。</p>
</blockquote>
<p>如果是 mysqld 造成的，使用 <code>show processlist</code> 命令，看看里面跑的 Session 情况，是不是有消耗资源的 SQL 在运行。找出消耗高的 SQL ，看看执行计划是否准确， index 是否缺失，或者实在是数据量太大造成。一般来说，肯定要 kill 掉这些线程(同时观察 CPU 使用率是否下降)，等进行相应的调整(比如说加索引、改 SQL 、改内存参数)之后，再重新跑这些 SQL。</p>
<blockquote>
<p>也可以查看 MySQL 慢查询日志，看是否有慢 SQL 。</p>
</blockquote>
<p>也有可能是每个 SQL 消耗资源并不多，但是突然之间，有大量的 Session 连进来导致 CPU 飙升，这种情况就需要跟应用一起来分析为何连接数会激增，再做出相应的调整，比如说限制连接数等。</p>
<p>🦅 <strong>在 MySQL 服务器运行缓慢的情况下输入什么命令能缓解服务器压力？</strong></p>
<blockquote>
<p>这个回答，和上面的回答思路是差不多的，优秀在更有层次感。</p>
</blockquote>
<p>1）检查系统的状态</p>
<p>通过操作系统的一些工具检查系统的状态，比如 CPU、内存、交换、磁盘的利用率，根据经验或与系统正常时的状态相比对，有时系统表面上看起来看空闲，这也可能不是一个正常的状态，因为 CPU 可能正等待IO的完成。除此之外，还应观注那些占用系统资源(CPU、内存)的进程。</p>
<ul>
<li>使用 sar 来检查操作系统是否存在 IO 问题。</li>
<li>使用 vmstat 监控内存 CPU 资源。</li>
<li>磁盘 IO 问题，处理方式：做 raid10 提高性能 。</li>
<li>网络问题，telnet 一下 MySQL 对外开放的端口。如果不通的话，看看防火墙是否正确设置了。另外，看看 MySQ L是不是开启了 skip-networking 的选项，如果开启请关闭。</li>
</ul>
<p>2）检查 MySQL 参数</p>
<ul>
<li>max_connect_errors</li>
<li>connect_timeout</li>
<li>skip-name-resolve</li>
<li>slave-net-timeout=seconds</li>
<li>master-connect-retry</li>
</ul>
<p>3）检查 MySQL 相关状态值</p>
<ul>
<li>关注连接数</li>
<li>关注下系统锁情况</li>
<li>关注慢查询（slow query）日志</li>
</ul>
<h2 id="运维"><a href="#运维" class="headerlink" title="运维"></a>运维</h2><h3 id="Innodb-的事务与日志的实现方式"><a href="#Innodb-的事务与日志的实现方式" class="headerlink" title="Innodb 的事务与日志的实现方式"></a>Innodb 的事务与日志的实现方式</h3><p>🦅 <strong>有多少种日志？</strong></p>
<ul>
<li>redo 日志</li>
<li>undo 日志</li>
</ul>
<p>🦅 <strong>日志的存放形式？</strong></p>
<ul>
<li>redo：在页修改的时候，先写到 redo log buffer 里面， 然后写到 redo log 的文件系统缓存里面(fwrite)，然后再同步到磁盘文件（fsync）。</li>
<li>undo：在 MySQL5.5 之前，undo 只能存放在 ibdata <em>文件里面， 5.6 之后，可以通过设置 innodb_undo_tablespaces 参数把 undo log 存放在 ibdata</em> 之外。</li>
</ul>
<p>🦅 <strong>事务是如何通过日志来实现的，说得越深入越好</strong></p>
<blockquote>
<p>艿艿：这个流程的理解还是比较简单的，实际思考实现感觉还是蛮复杂的。</p>
</blockquote>
<p>基本流程如下：</p>
<ul>
<li>因为事务在修改页时，要先记 undo ，在记 undo 之前要记 undo 的 redo， 然后修改数据页，再记数据页修改的 redo。 redo（里面包括 undo 的修改）一定要比数据页先持久化到磁盘。</li>
<li>当事务需要回滚时，因为有 undo，可以把数据页回滚到前镜像的状态。</li>
<li>崩溃恢复时，如果 redo log 中事务没有对应的 commit 记录，那么需要用 undo 把该事务的修改回滚到事务开始之前。如果有 commit 记录，就用 redo 前滚到该事务完成时并提交掉。</li>
</ul>
<h3 id="MySQL-binlog-的几种日志录入格式以及区别"><a href="#MySQL-binlog-的几种日志录入格式以及区别" class="headerlink" title="MySQL binlog 的几种日志录入格式以及区别"></a>MySQL binlog 的几种日志录入格式以及区别</h3><p>🦅 <strong>各种日志格式的涵义</strong></p>
<p>binlog 有三种格式类型，分别如下：</p>
<p>1）Statement</p>
<p>每一条会修改数据的 SQL 都会记录在 binlog 中。</p>
<ul>
<li><p>优点：不需要记录每一行的变化，减少了 binlog 日志量，节约了 IO，提高性能。(相比 row 能节约多少性能与日志量，这个取决于应用的 SQL 情况，正常同一条记录修改或者插入 row 格式所产生的日志量还小于 Statement 产生的日志量，但是考虑到如果带条件的 update 操作，以及整表删除，alter 表等操作，ROW 格式会产生大量日志，因此在考虑是否使用 ROW 格式日志时应该跟据应用的实际情况，其所产生的日志量会增加多少，以及带来的 IO 性能问题。)</p>
</li>
<li><p>缺点：由于记录的只是执行语句，为了这些语句能在 slave 上正确运行，因此还必须记录每条语句在执行的时候的一些相关信息，以保证所有语句能在 slave 得到和在 master 端执行时候相同 的结果。另外 MySQL 的复制，像一些特定函数功能，slave 可与 master 上要保持一致会有很多相关问题(如 <code>sleep()</code> 函数，<code>last_insert_id()</code>，以及 user-defined functions(udf) 会出现问题)。</p>
</li>
<li><p>使用以下函数的语句也无法被复制：</p>
<ul>
<li><p><code>LOAD_FILE()</code></p>
</li>
<li><p><code>UUID()</code></p>
</li>
<li><p><code>USER()</code></p>
</li>
<li><p><code>FOUND_ROWS()</code></p>
</li>
<li><p><code>SYSDATE()</code> (除非启动时启用了 <code>--sysdate-is-now</code> 选项)</p>
<blockquote>
<p>同时在 INSERT …SELECT 会产生比 RBR 更多的行级锁 。</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<p>2）Row</p>
<p>不记录 SQL 语句上下文相关信息，仅保存哪条记录被修改。</p>
<ul>
<li>优点：binlog 中可以不记录执行的 SQL 语句的上下文相关的信息，仅需要记录那一条记录被修改成什么了。所以 rowlevel 的日志内容会非常清楚的记录下每一行数据修改的细节。而且不会出现某些特定情况下的存储过程，或 function ，以及 trigger 的调用和触发无法被正确复制的问题。</li>
<li>缺点：所有的执行的语句当记录到日志中的时候，都将以每行记录的修改来记录，这样可能会产生大量的日志内容,比如一条 Update 语句，修改多条记录，则 binlog 中每一条修改都会有记录，这样造成 binlog 日志量会很大，特别是当执行 alter table 之类的语句的时候，由于表结构修改，每条记录都发生改变，那么该表每一条记录都会记录到日志中。</li>
</ul>
<p>3）Mixedlevel</p>
<p>是以上两种 level 的混合使用。</p>
<ul>
<li>一般的语句修改使用 Statement 格式保存 binlog 。</li>
<li>如一些函数，statement 无法完成主从复制的操作，则采用 Row 格式保存 binlog 。</li>
</ul>
<p>MySQL 会根据执行的每一条具体的 SQL 语句来区分对待记录的日志形式，也就是在 Statement 和 Row 之间选择 一种。</p>
<p>新版本的 MySQL 中对 row level 模式也被做了优化，并不是所有的修改都会以 row level 来记录。</p>
<ul>
<li>像遇到表结构变更的时候就会以 Statement 模式来记录。</li>
<li>至于 Update 或者 Delete 等修改数据的语句，还是会记录所有行的变更，即使用 Row 模式。</li>
</ul>
<p>🦅 <strong>适用场景？</strong></p>
<p>在一条 SQL 操作了多行数据时， Statement 更节省空间，Row 更占用空间。但是， Row 模式更可靠。</p>
<p>因为，互联网公司，使用 MySQL 的功能相对少，基本不使用存储过程、触发器、函数的功能，选择默认的语句模式，Statement Level（默认）即可。</p>
<p>🦅 <strong>结合第一个问题，每一种日志格式在复制中的优劣？</strong></p>
<ul>
<li>Statement 可能占用空间会相对小一些，传送到 slave 的时间可能也短，但是没有 Row 模式的可靠。</li>
<li>Row 模式在操作多行数据时更占用空间，但是可靠。</li>
</ul>
<p>所以，这是在占用空间和可靠之间的选择。</p>
<p><strong>如何在线正确清理 MySQL binlog？</strong></p>
<p>MySQL 中的 binlog 日志记录了数据中的数据变动，便于对数据的基于时间点和基于位置的恢复。但日志文件的大小会越来越大，占用大量的磁盘空间，因此需要定时清理一部分日志信息。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 首先查看主从库正在使用的binlog文件名称</span><br><span class="line">show master(slave) status</span><br><span class="line"></span><br><span class="line"># 删除之前一定要备份</span><br><span class="line">purge master logs before&#39;2017-09-01 00:00:00&#39;; # 删除指定时间前的日志</span><br><span class="line">purge master logs to&#39;mysql-bin.000001&#39;; # 删除指定的日志文件</span><br><span class="line"></span><br><span class="line"># 自动删除：通过设置binlog的过期时间让系统自动删除日志</span><br><span class="line">show variables like &#39;expire_logs_days&#39;; # 查看过期时间</span><br><span class="line">set global expire_logs_days &#x3D; 30; # 设置过期时间</span><br></pre></td></tr></table></figure>



<h3 id="MySQL-主从复制的流程是怎么样的？"><a href="#MySQL-主从复制的流程是怎么样的？" class="headerlink" title="MySQL 主从复制的流程是怎么样的？"></a>MySQL 主从复制的流程是怎么样的？</h3><p>MySQL 的主从复制是基于如下 3 个线程的交互（多线程复制里面应该是 4 类线程）：</p>
<ul>
<li>1、Master 上面的 binlog dump 线程，该线程负责将 master 的 binlog event 传到 slave 。</li>
<li>2、Slave 上面的 IO 线程，该线程负责接收 Master 传过来的 binlog，并写入 relay log 。</li>
<li>3、Slave 上面的 SQL 线程，该线程负责读取 relay log 并执行。</li>
<li>4、如果是多线程复制，无论是 5.6 库级别的假多线程还是 MariaDB 或者 5.7 的真正的多线程复制， SQL 线程只做 coordinator ，只负责把 relay log 中的 binlog 读出来然后交给 worker 线程， woker 线程负责具体 binlog event 的执行。</li>
</ul>
<p>🦅 <strong>MySQL 如何保证复制过程中数据一致性？</strong></p>
<blockquote>
<p>艿艿：这个问题比较难，理解不了也没问题。我自己也没完全理解，主要是网络找到这个答案，后续有精力在研究。</p>
</blockquote>
<ul>
<li>1、在 MySQL5.5 以及之前， slave 的 SQL 线程执行的 relay log 的位置只能保存在文件（ relay-log.info）里面，并且该文件默认每执行 10000 次事务做一次同步到磁盘， 这意味着 slave 意外 crash 重启时， SQL 线程执行到的位置和数据库的数据是不一致的，将导致复制报错，如果不重搭复制，则有可能会导致数据不一致。<ul>
<li>MySQL 5.6 引入参数 relay_log_info_repository，将该参数设置为 TABLE 时， MySQL 将 SQL 线程执行到的位置存到 mysql.slave_relay_log_info 表，这样更新该表的位置和 SQL 线程执行的用户事务绑定成一个事务，这样 slave 意外宕机后，slave 通过 innodb 的崩溃恢复可以把 SQL 线程执行到的位置和用户事务恢复到一致性的状态。</li>
</ul>
</li>
<li>2、MySQL 5.6 引入 GTID 复制，每个 GTID 对应的事务在每个实例上面最多执行一次， 这极大地提高了复制的数据一致性。</li>
<li>3、MySQL 5.5 引入半同步复制， 用户安装半同步复制插件并且开启参数后，设置超时时间，可保证在超时时间内如果 binlog 不传到 slave 上面，那么用户提交事务时不会返回，直到超时后切成异步复制，但是如果切成异步之前用户线程提交时在 master 上面等待的时候，事务已经提交，该事务对 master 上面的其他 session 是可见的，如果这时 master 宕机，那么到 slave 上面该事务又不可见了，该问题直到 5.7 才解决。</li>
<li>4、MySQL 5.7 引入无损半同步复制，引入参 rpl_semi_sync_master_wait_point，该参数默认为 after_sync，指的是在切成半同步之前，事务不提交，而是接收到 slave 的 ACK 确认之后才提交该事务，从此，复制真正可以做到无损的了。</li>
<li>5、可以再说一下 5.7 的无损复制情况下， master 意外宕机，重启后发现有 binlog 没传到 slave 上面，这部分 binlog 怎么办？？？分 2 种情况讨论， 1 宕机时已经切成异步了， 2 是宕机时还没切成异步？？？ 这个怎么判断宕机时有没有切成异步呢？？？ 分别怎么处理？？？</li>
</ul>
<p>🦅 <strong>MySQL 如何解决主从复制的延时性？</strong></p>
<p>5.5 是单线程复制，5.6 是多库复制（对于单库或者单表的并发操作是没用的），5.7 是真正意义的多线程复制，它的原理是基于 group commit， 只要 master 上面的事务是 group commit 的，那 slave 上面也可以通过多个 worker线程去并发执行。 和 MairaDB10.0.0.5 引入多线程复制的原理基本一样。</p>
<p>🦅 <strong>工作遇到的复制 bug 的解决方法？</strong></p>
<p>5.6 的多库复制有时候自己会停止，我们写了一个脚本重新 start slave 。</p>
<p>🦅 <strong>你是否做过主从一致性校验，如果有，怎么做的，如果没有，你打算怎么做？</strong></p>
<p>主从一致性校验有多种工具 例如 checksum、mysqldiff、pt-table-checksum 等。</p>
<h3 id="聊聊-MySQL-备份方式？备份策略是怎么样的？"><a href="#聊聊-MySQL-备份方式？备份策略是怎么样的？" class="headerlink" title="聊聊 MySQL 备份方式？备份策略是怎么样的？"></a>聊聊 MySQL 备份方式？备份策略是怎么样的？</h3><p>具体的，胖友可以看看 <a target="_blank" rel="noopener" href="http://www.qinglin.net/1015.html">《MySQL 高级备份策略》</a> 。主要有几个知识点：</p>
<ul>
<li><p>数据的备份类型</p>
<ul>
<li><p>【常用】完全备份</p>
<blockquote>
<p>这是大多数人常用的方式，它可以备份整个数据库，包含用户表、系统表、索引、视图和存储过程等所有数据库对象。但它需要花费更多的时间和空间，所以，一般推荐一周做一次完全备份。</p>
</blockquote>
</li>
<li><p>增量备份</p>
<blockquote>
<p>它是只备份数据库一部分的另一种方法，它不使用事务日志，相反，它使用整个数据库的一种新映象。它比最初的完全备份小，因为它只包含自上次完全备份以来所改变的数据库。它的优点是存储和恢复速度快。推荐每天做一次差异备份。</p>
</blockquote>
</li>
<li><p>【常用】事务日志备份</p>
<blockquote>
<p>事务日志是一个单独的文件，它记录数据库的改变，备份的时候只需要复制自上次备份以来对数据库所做的改变，所以只需要很少的时间。为了使数据库具有鲁棒性，推荐每小时甚至更频繁的备份事务日志。</p>
</blockquote>
</li>
<li><p>文件备份</p>
<blockquote>
<p>数据库可以由硬盘上的许多文件构成。如果这个数据库非常大，并且一个晚上也不能将它备份完，那么可以使用文件备份每晚备份数据库的一部分。由于一般情况下数据库不会大到必须使用多个文件存储，所以这种备份不是很常用。</p>
</blockquote>
</li>
</ul>
</li>
<li><p>备份数据的类型</p>
<ul>
<li>热备份</li>
<li>温备份</li>
<li>冷备份</li>
</ul>
</li>
<li><p>备份工具</p>
<ul>
<li>cp</li>
<li>mysqldump</li>
<li>xtrabackup</li>
<li>lvm2 快照</li>
</ul>
</li>
</ul>
<p>🦅 <strong>MySQL 几种备份方式？</strong></p>
<p>MySQL 一般有 3 种备份方式。</p>
<p>1）逻辑备份</p>
<p>使用 MySQL 自带的 mysqldump 工具进行备份。备份成sql文件形式。</p>
<ul>
<li>优点：最大好处是能够与正在运行的 MySQL 自动协同工作，在运行期间可以确保备份是当时的点，它会自动将对应操作的表锁定，不允许其他用户修改(只能访问)。可能会阻止修改操作。SQL 文件通用方便移植。</li>
<li>缺点：备份的速度比较慢。如果是数据量很多的时候，就很耗时间。如果数据库服务器处在提供给用户服务状态，在这段长时间操作过程中，意味着要锁定表(一般是读锁定，只能读不能写入数据)，那么服务就会影响的。</li>
</ul>
<p>2）物理备份</p>
<blockquote>
<p>艿艿：因为现在主流是 InnoDB ，所以基本不再考虑这种方式。</p>
</blockquote>
<p>直接拷贝只适用于 MyISAM 类型的表。这种类型的表是与机器独立的。但实际情况是，你设计数据库的时候不可能全部使用 MyISAM 类型表。你也不可能因为 MyISAM 类型表与机器独立，方便移植，于是就选择这种表，这并不是选择它的理由。</p>
<ul>
<li>缺点：你不能去操作正在运行的 MySQL 服务器(在拷贝的过程中有用户通过应用程序访问更新数据，这样就无法备份当时的数据)，可能无法移植到其他机器上去。</li>
</ul>
<p>3）双机热备份。</p>
<p>当数据量太大的时候备份是一个很大的问题，MySQL 数据库提供了一种主从备份的机制，也就是双机热备。</p>
<ul>
<li>优点：适合数据量大的时候。现在明白了，大的互联网公司对于 MySQL 数据备份，都是采用热机备份。搭建多台数据库服务器，进行主从复制。</li>
</ul>
<p>🦅 <strong>数据库不能停机，请问如何备份? 如何进行全备份和增量备份?</strong></p>
<p>可以使用逻辑备份和双机热备份。</p>
<ul>
<li>完全备份：完整备份一般一段时间进行一次，且在网站访问量最小的时候，这样常借助批处理文件定时备份。主要是写一个批处理文件在里面写上处理程序的绝对路径然后把要处理的东西写在后面，即完全备份数据库。</li>
<li>增量备份：对 ddl 和 dml 语句进行二进制备份。且 5.0 无法增量备份，5.1 后可以。如果要实现增量备份需要在 <code>my.ini</code> 文件中配置备份路径即可，重启 MySQL 服务器，增量备份就启动了。</li>
</ul>
<p>🦅 <strong>你的备份工具的选择？备份计划是怎么样的？</strong></p>
<p>视库的大小来定，一般来说 100G 内的库，可以考虑使用 mysqldump 来做，因为 mysqldump 更加轻巧灵活，备份时间选在业务低峰期，可以每天进行都进行全量备份(mysqldump 备份出来的文件比较小，压缩之后更小)。</p>
<p>100G 以上的库，可以考虑用 xtrabackup 来做，备份速度明显要比 mysqldump 要快。一般是选择一周一个全备，其余每天进行增量备份，备份时间为业务低峰期。</p>
<blockquote>
<p>艿艿：一般情况下，选择每周备份 + 每天增量备份比较靠谱。</p>
</blockquote>
<p>🦅 <strong>备份恢复时间是多长？</strong></p>
<p>物理备份恢复快，逻辑备份恢复慢。</p>
<p>这里跟机器，尤其是硬盘的速率有关系，以下列举几个仅供参考：</p>
<ul>
<li>20G 的 2 分钟（mysqldump）</li>
<li>80G 的 30分钟（mysqldump)</li>
<li>111G 的 30分钟（mysqldump)</li>
<li>288G 的 3 小时（xtrabackup)</li>
<li>3T 的 4 小时（xtrabackup)</li>
</ul>
<p>逻辑导入时间一般是备份时间的 5 倍以上。</p>
<p>🦅 <strong>备份恢复失败如何处理？</strong></p>
<p>首先在恢复之前就应该做足准备工作，避免恢复的时候出错。比如说备份之后的有效性检查、权限检查、空间检查等。如果万一报错，再根据报错的提示来进行相应的调整。</p>
<p>🦅 <strong>mysqldump 和 xtrabackup 实现原理？</strong></p>
<p>1）mysqldump</p>
<p>mysqldump 是最简单的逻辑备份方式。</p>
<ul>
<li>在备份 MyISAM 表的时候，如果要得到一致的数据，就需要锁表，简单而粗暴。</li>
<li>在备份 InnoDB 表的时候，加上 <code>–master-data=1 –single-transaction</code> 选项，在事务开始时刻，记录下 binlog pos 点，然后利用 MVCC 来获取一致的数据，由于是一个长事务，在写入和更新量很大的数据库上，将产生非常多的 undo ，显著影响性能，所以要慎用。</li>
<li>优点：简单，可针对单表备份，在全量导出表结构的时候尤其有用。</li>
<li>缺点：简单粗暴，单线程，备份慢而且恢复慢，跨 IDC 有可能遇到时区问题</li>
</ul>
<p>2）xtrabackup</p>
<p>xtrabackup 实际上是物理备份+逻辑备份的组合。</p>
<ul>
<li>在备份 InnoDB 表的时候，它拷贝 ibd 文件，并一刻不停的监视 redo log 的变化，append 到自己的事务日志文件。在拷贝 ibd 文件过程中，ibd文件本身可能被写”花”，这都不是问题，因为在拷贝完成后的第一个 prepare 阶段，xtrabackup 采用类似于 Innodb 崩溃恢复的方法，把数据文件恢复到与日志文件一致的状态，并把未提交的事务回滚。</li>
<li>如果同时需要备份 MyISAM 表以及 InnoDB 表结构等文件，那么就需要用 <code>flush tables with lock</code> 来获得全局锁，开始拷贝这些不再变化的文件，同时获得 binlog 位置，拷贝结束后释放锁，也停止对 redo log 的监视。</li>
</ul>
<p>🦅 <strong>如何从 mysqldump 产生的全库备份中只恢复某一个库、某一张表？</strong></p>
<p>具体可见 <a target="_blank" rel="noopener" href="http://blog.51cto.com/wujianwei/1959473">《MySQL 全库备份中恢复某个库和某张表以及 mysqldump 参数 –ignore-table 介绍》</a> 文章。</p>
<h3 id="聊聊-MySQL-集群"><a href="#聊聊-MySQL-集群" class="headerlink" title="聊聊 MySQL 集群?"></a>聊聊 MySQL 集群?</h3><ul>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/25960208">《五大常见的 MySQL 高可用方案》</a></li>
<li><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/21307639">《高性能、高可用、可扩展的 MySQL 集群如何组建？》</a></li>
</ul>
<p>🦅 <strong>对于简历中写有熟悉 MySQL 高可用方案？</strong></p>
<p>我一般先问他现在管理的数据库架构是什么，如果他只说出了主从，而没有说任何 HA 的方案，那么我就可以判断出他没有实际的 HA 经验。</p>
<p>不过这时候也不能就是断定他不懂 MySQL 高可用，也许是没有实际机会去使用，那么我就要问 <a target="_blank" rel="noopener" href="http://www.cnblogs.com/gomysql/p/3671896.html">MMM</a> 以及 <a target="_blank" rel="noopener" href="http://svip.iocoder.cn/MySQL/Interview/MySQL%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84%E4%B9%8BMHA">MHA</a> 以及 <a target="_blank" rel="noopener" href="http://blog.51cto.com/sumongodb/1953244">MM + keepalived</a> 等的原理、实现方式以及它们之间的优势和不足了，一般这种情况下，能说出这个的基本没有。</p>
<ul>
<li>MMM 那东西好像不靠谱，据说不稳定，但是有人在用的，和 mysql-router 比较像，都是指定可写的机器和只读机器。</li>
<li>MHA 的话一句话说不完，可以搜索下相关博客。</li>
</ul>
<p>🦅 <strong>使用过其他分支版本的数据库吗？Percona、Mariadb 等。对Percona 的 pxc 集群了解吗？</strong></p>
<p>除了 Oracle 旗下的 MySQL 外，我还使用过 Percona Server 。</p>
<p>Percona 是在原生 MySQL 的基础上，进行了优化和改进，所以 Percona 的性能比 MySQL 更好。</p>
<ul>
<li>目前，我知道 Percona 提供免费的线程池功能，而社区版的 MySQL 没有线程池的功能（当然，企业版的mysql是有线程池的，但是需要收费）</li>
<li>另外 Percona 还支持 NUMA 等功能。</li>
</ul>
<p>我熟悉 pxc ，我曾经在测试环境搭建过 pxc ，但是没有在生产上使用，因为目前使用 pxc 的企业不是很多，目前我知道搜狐在用 pxc 。</p>
<ul>
<li>pxc 是摒弃 MySQL 主从的概念，即对于 pxc 来说，每个节点都可以读写，并且写一份数据，其他节点会同时拥有，这是一种同步的复制方案（区别于 MySQL 主从的异步复制）。</li>
</ul>
<h3 id="聊聊-MySQL-安全？"><a href="#聊聊-MySQL-安全？" class="headerlink" title="聊聊 MySQL 安全？"></a>聊聊 MySQL 安全？</h3><p>感兴趣的胖友，可以看看：</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://netsecurity.51cto.com/art/201311/418159.htm">《保障 MySQL 安全的14个最佳方法》</a></li>
<li><a target="_blank" rel="noopener" href="https://www.freebuf.com/articles/database/36777.html">《详解 MySQL 安全配置》</a></li>
</ul>
<h3 id="MySQL-有哪些日志？"><a href="#MySQL-有哪些日志？" class="headerlink" title="MySQL 有哪些日志？"></a>MySQL 有哪些日志？</h3><ul>
<li><p>错误日志：记录了当 mysqld 启动和停止时，以及服务器在运行过程中发生任何严重错误时的相关信息。</p>
</li>
<li><p>二进制文件：记录了所有的 DDL（数据定义语言）语句和 DML（数据操纵语言）语句，不包括数据查询语句。语句以“事件”的形式保存，它描述了数据的更改过程。（定期删除日志，默认关闭）。</p>
<blockquote>
<p>就是我们上面看到的 MySQL binlog 日志。</p>
</blockquote>
</li>
<li><p>查询日志：记录了客户端的所有语句，格式为纯文本格式，可以直接进行读取。（log 日志中记录了所有数据库的操作，对于访问频繁的系统，此日志对系统性能的影响较大，建议关闭，默认关闭）。</p>
</li>
<li><p>慢查询日志：慢查询日志记录了包含所有执行时间超过参数long_query_time（单位：秒）所设置值的 SQL 语句的日志。（纯文本格式）</p>
<blockquote>
<p>重要，一定要开启。</p>
</blockquote>
</li>
</ul>
<p>另外，错误日志和慢查询日志的详细解释，可以看看 <a target="_blank" rel="noopener" href="https://blog.csdn.net/xlgen157387/article/details/76019934">《MySQL 日志文件之错误日志和慢查询日志详解》</a> 文章。</p>
<h3 id="聊聊-MySQL-监控？"><a href="#聊聊-MySQL-监控？" class="headerlink" title="聊聊 MySQL 监控？"></a>聊聊 MySQL 监控？</h3><p><strong>你是如何监控你们的数据库的？</strong></p>
<p>监控的工具有很多，例如 Zabbix ，Lepus ，我这里用的是 <a target="_blank" rel="noopener" href="https://github.com/lijiapengsa/lepus">Lepus</a> 。</p>
<h3 id="对一个大表做在线-DDL-，怎么进行实施的才能尽可能降低影响？"><a href="#对一个大表做在线-DDL-，怎么进行实施的才能尽可能降低影响？" class="headerlink" title="对一个大表做在线 DDL ，怎么进行实施的才能尽可能降低影响？"></a>对一个大表做在线 DDL ，怎么进行实施的才能尽可能降低影响？</h3><p>使用 pt-online-schema-change ，具体可以看看 <a target="_blank" rel="noopener" href="https://blog.csdn.net/mchdba/article/details/76253016">《MySQL 大表在线 DML 神器–pt-online-schema-change》</a> 文章。</p>
<p>另外，还有一些其它的工具，可以自行搜索下。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Seif Zheng"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">Seif Zheng</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">22</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/fatefrank" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;fatefrank" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:astutenicol@gmail.com" title="E-Mail → mailto:astutenicol@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Seif Zheng</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
